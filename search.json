[
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "This publication list is will be (need to do some coding) based on my Zotero publication list. Most of the publications (and maybe some more) can also be found on Google scholar."
  },
  {
    "objectID": "material/software/setup-project-folder.html",
    "href": "material/software/setup-project-folder.html",
    "title": "Setup a project folder",
    "section": "",
    "text": "Warning\n\n\n\nThis page under active development.",
    "crumbs": [
      "Compendium",
      "Software",
      "Setup a project folder"
    ]
  },
  {
    "objectID": "material/software/setup-project-folder.html#what-is-version-control-and-why-should-you-use-it",
    "href": "material/software/setup-project-folder.html#what-is-version-control-and-why-should-you-use-it",
    "title": "Setup a project folder",
    "section": "What is version control and why should you use it?",
    "text": "What is version control and why should you use it?\nTracking and recording changes for all kind of files (within a project) over time\n\n\n\n\n\nBackup: Records the history of your project and allows for easy recovery of earlier versions\n\n\n\n\n\nCollaboration: It allows multiple people to work on the same project without overwriting each other’s work.\n\n\n\n\n\nUnderstanding & Traceability: It helps to track why changes were made, who made them, and when\n\n\n\n\n\n\n\n\nTime machine analogy1\n\n\n\n\n\n\n“Track Changes” features from Microsoft Word on steroids (https://happygitwithr.com/big-picture)",
    "crumbs": [
      "Compendium",
      "Software",
      "Setup a project folder"
    ]
  },
  {
    "objectID": "material/software/setup-project-folder.html#git-basics",
    "href": "material/software/setup-project-folder.html#git-basics",
    "title": "Setup a project folder",
    "section": "Git basics",
    "text": "Git basics\n\n\n\n\n\nRepository (Repo): The place where your project lives. It contains all the files and the entire revision history.\n\n\n\n\n\nCommit: Making a commit is making a snapshot of your repository at a specific time point. Each commit records the current state of your project and has a unique identifier.\n\n\n\n\n\nBranch: A branch may be a separate line of project development (e.g., to try out new ideas in a isolated area). The ‘main’ (or previous ‘master’) branch is usually considered the definitive branch.\n\n\n\n\n\n\n\n\nMerge: Merging means to incorporate changes from a different branch into the the main branch.\n\n\n\n\n\nPull Request: When collaborating, you make changes in your branch and then ask others to review and merge them. This request is called a pull request.\n\n\n\n\n\nClone: Making a local copy of a remote repository. \n\n\n\n\n\n\nFork: Copy a project from somebody else without affecting the original project.\n\n\n\n\n\n\nhttps://happygitwithr.com/git-intro",
    "crumbs": [
      "Compendium",
      "Software",
      "Setup a project folder"
    ]
  },
  {
    "objectID": "material/software/setup-project-folder.html#git-in-rstudio-i",
    "href": "material/software/setup-project-folder.html#git-in-rstudio-i",
    "title": "Setup a project folder",
    "section": "Git in RStudio I",
    "text": "Git in RStudio I\n\n\n\n\n\n\n\nDownload & install Git: https://git-scm.com/downloads\n\nGo to Tools &gt; Global Options\nClick Git/SVN\nClick Enable version control interface for RStudio projects\nIf necessary, enter the path for your Git where provided.",
    "crumbs": [
      "Compendium",
      "Software",
      "Setup a project folder"
    ]
  },
  {
    "objectID": "material/software/setup-project-folder.html#git-in-rstudio-ii",
    "href": "material/software/setup-project-folder.html#git-in-rstudio-ii",
    "title": "Setup a project folder",
    "section": "Git in RStudio II",
    "text": "Git in RStudio II\nEnable it when creating a R project: Click ‘Create a git repository’",
    "crumbs": [
      "Compendium",
      "Software",
      "Setup a project folder"
    ]
  },
  {
    "objectID": "material/software/setup-project-folder.html#combine-it-with-github",
    "href": "material/software/setup-project-folder.html#combine-it-with-github",
    "title": "Setup a project folder",
    "section": "Combine it with GitHub \n",
    "text": "Combine it with GitHub \n\nGitHub provides a home for Git-based projects and allows other people to see the project\n\n\nHappy Git and GitHub for the useR: https://happygitwithr.com/",
    "crumbs": [
      "Compendium",
      "Software",
      "Setup a project folder"
    ]
  },
  {
    "objectID": "material/software/setup-project-folder.html#renv-package-in-r-projects-within-r-studio-i",
    "href": "material/software/setup-project-folder.html#renv-package-in-r-projects-within-r-studio-i",
    "title": "Setup a project folder",
    "section": "\nrenv package in R projects (within R Studio) I",
    "text": "renv package in R projects (within R Studio) I\nUse it when creating a R project: Click ‘Use renv with this project’",
    "crumbs": [
      "Compendium",
      "Software",
      "Setup a project folder"
    ]
  },
  {
    "objectID": "material/software/setup-project-folder.html#renv-package-in-r-projects-within-r-studio-ii",
    "href": "material/software/setup-project-folder.html#renv-package-in-r-projects-within-r-studio-ii",
    "title": "Setup a project folder",
    "section": "\nrenv package in R projects (within R Studio) II",
    "text": "renv package in R projects (within R Studio) II\nOr use functions from the package to set up a project infrastructure:\n\nrenv::init()",
    "crumbs": [
      "Compendium",
      "Software",
      "Setup a project folder"
    ]
  },
  {
    "objectID": "material/software/setup-project-folder.html#footnotes",
    "href": "material/software/setup-project-folder.html#footnotes",
    "title": "Setup a project folder",
    "section": "Footnotes",
    "text": "Footnotes\n\nImage was created with ChatGPT↩︎",
    "crumbs": [
      "Compendium",
      "Software",
      "Setup a project folder"
    ]
  },
  {
    "objectID": "material/software/intro-quarto.html",
    "href": "material/software/intro-quarto.html",
    "title": "A not so short introduction to Quarto",
    "section": "",
    "text": "Tip for RMarkdown user\n\n\n\n\n\nIf you are familiar with RMarkdown (R-rmarkdown?) the FAQ for RMarkdown Users might be interesting for you.\n\n\n\n\n\n\n\n\nBut, what is Pandoc? Pandoc is a universal document converter. It converts files from one markup format into another (e.g., markdown → HTML).\nIn short, with Quarto you can create different types of (reproducible) documents1 including:\n\nHTML\nPDF\nMS Word\nMarkdown\n\nThe focus of this workshop is on HTML (and PDF) documents. For an overview about all formats see here.\n\n\nIt is basically the same2 as working in regular a R-script.\n\nOpen a new file: File &gt; New File &gt; Quarto Document...\n\n\n\n\n\n\n\n\n\n\nExercise: Create your first Quarto document!\n\n\n\n\n\n\nProvide a title (& author name)\n\n\n\nSave the document with a reasonable name and use the Render button\n\n\n\n\n\n\nA quarto document roughly consists of two parts:\n\nThe YAML header\n\nThe Body\n\n\n\nThe website quarto.org is a great resource to learn it (e.g., follow the guide). It is a daily companion and covers the topics in much greater detail than this page.\n\nThe YAML3 header is enclosed by three dashes (---):\n---\ntitle: \"my-first-quarto-document\"\nformat: html\n---\n\nThe basic syntax of YAML uses so-called key-value pairs in the format key: value. This is extremely powerful, because you can generate great documents like this Quarto book without knowing much about HTML, LATEX or programming in general.\nSome useful key-value pairs:\nsubtitle: \"my subtitle\"\nauthor:\n  - \"John Doe\"\n  - \"Jane Roe\"\n  - \"Norah Jones\"\ndate: today\ntoc: true\ntoc-title: \"Inhaltsverzeichnis\"\nnumber-sections: true\n\n\n\n\n\n\nExercise: Identify useful key-value pairs\n\n\n\n\n\n\nFor the next 5 minutes or so, check out https://quarto.org and identify potential useful key: value pairs. Note: There are different YAML options for the formats:\n\nHTML\nPDF\n\n\nAdd them to your YAML header.\n\n\n\n\n\nWith Quarto it is possible to automatically generate citations and bibliographies in many different ways.\nThe key: value pair to include citations in Quarto documents is:\nbibliography: r-refs.bib\nHere we use a so-called BibLaTex (.bib) file. These files can be generated with the most reference management software programs4 (e.g., Citavi, EndNote, zotero, …).\n\n\n\n\n\n\nRandom tip on maintenance of literature management\n\n\n\n\n\nIt is highly recommended to maintain your retrieved citations. This means, whenever you download a single (!) reference by means of the doi (Digital Object Identifier), check whether the reference information is correct. This saves a lot of time in the long run.\n\n\n\nA reference in the .bib-file looks like this:\n@Manual{R-base,\n  title = {R: A Language and Environment for Statistical Computing},\n  author = {{R Core Team}},\n  organization = {R Foundation for Statistical Computing},\n  address = {Vienna, Austria},\n  year = {2022},\n  url = {https://www.R-project.org/},\n}\n\n\n\n\n\n\nExercise: Create a .bib file for the R references\n\n\n\n\n\n\nCheck the path with the base::getwd function (should be the same folder as the Quarto document, otherwise you have to provide the path in the YAML bibliography argument).\n\n\ngetwd()\n\n\nSave (some of the) R packages in a character vector.\n\n\npkgList &lt;- c(\"knitr\", # tables\n             \"kableExtra\", # tables\n             \"lavaan\", # generate data\n             \"car\", # recoding\n             \"psych\") # descriptive\n\n\nUse the write_bib function from the kntir package (Xie, 2023).\n\n\nknitr::write_bib(x = pkgList,\n                 file = \"r-refs.bib\")\n\n\n\n\nTo change the citation style (e.g., APA, Chicago Manual of Style), we use the csl key5:\ncsl: apa.csl\nThe apa.csl file can be found on github.\nThe citation syntax (How to cite the references in the text?) is briefly explained in the The Body subsection Citation syntax.\n\nThere are many different options to customize the output of the (executed code).The options can be specified:\n\nglobally (see in the following)\nper code block (see the section on Chunk options)\n\nIn the following example, we set echo: false and warning: false.\nexecute:\n  echo: false\n  warning: false\nThis means that no code and no warnings are shown, except you state it otherwise in a specific code block.\nFor more (chunk) options see https://quarto.org/docs/computations/execution-options.html.\n\nAs explained in the section What is Quarto?:\n\nQuarto is based on Pandoc and uses its variation of markdown as its underlying document syntax (see https://quarto.org)\n\nThis means we can use Markdown syntax6 (together with the information in the YAML header) to generate the different types of documents (e.g., HTML, PDF, …).\n\n\n\n\n\n\nExercise: Work through the Markdown language section and the three subsections…\n\n\n\n\n\n\nText formatting\nHeadings\nLists\n\nThe information is very dense, so do not expect to remember everything.\n\n\n\n\nThere are plenty of different guides to get a quick overview about the language (see e.g., markdownguide, or Quarto-website). The following code snippets are copied and sometimes slightly adjusted from https://quarto.org.\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n*italics* and **bold**\n\nitalics and bold\n\n\n\nsuperscript^2^ / subscript~2~\nsuperscript2 / subscript2\n\n\n\n~~strikethrough~~\nstrikethrough\n\n\n`verbatim code`\nverbatim code\n\n\n\nTo create headings, add one (or more) # in front of the heading.\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n# Header 1\n\n\n\n## Header 2\n\n\n\n### Header 3\n\n\n\n\n\nThis goes up to level 6 (i.e., ######) which probably is not recommended to use though.\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n* unordered list\n    + sub-item 1\n    + sub-item 2\n        - sub-sub-item 1\n\n\nunordered list\n\nsub-item 1\n\nsub-item 2\n\nsub-sub-item 1\n\n\n\n\n\n\n\n1. ordered list\n2. item 2\n    i) sub-item 1\n         A.  sub-sub-item 1\n\nordered list\n\nitem 2\n\n\nsub-item 1\n\nsub-sub-item 1\n\n\n\n\n\n\n\n\nMore example can be found on https://quarto.org/docs/authoring/markdown-basics.html#lists.\n\nTo make a figure, table, equation, …, or section/heading referenceable, it is necessary to provide unique identifier. Identifiers must start with their type (e.g., #fig-, #tbl-, #eq-), except for headers (see in the following example):\nWhen we want to cross-reference the Images section, we have to provide unique identifier that is enclosed by braces {} (here: #include-images) after the heading:\n## Images {#include-images} \nAn example on how to reference figures is shown in the Images section.\nFor more on cross-referencing (e.g., how to make sub-figures) see again https://quarto.org/docs/authoring/cross-references.html.\n\nOne way to include images is as follows:\n![Here goes the caption](/path-to-file/myImage.png){#fig-myImage}\nThe caption [Here goes the caption] and label {#fig-myImage} make this figure referenceable. To reference it, use the following syntax:\nSee @fig-myImage for a graphical representation.\nIt renders to:\nSee Figure 1 for a graphical representation.\n\n\n\n\n\nFigure 1: Here goes the caption\n\n\n\n\n\n\n\n\nTip. There are a few other options to include images…\n\n\n\n\n\nOne of them is the include_graphics function from the knitr package (Xie, 2023):\n\n```{r}\n#| label: fig-demo-include\n#| eval: false\n#| code-fold: false\n\nknitr::include_graphics(\"path-to-file\")\n```\n\nIt is referenceable via the label: fig-demo-include. For now ignore the other so-called chunk options (i.e., eval, code-fold). These are explained in the Chunk options section.\nFor more (e.g., HTML way &lt;img&gt; &lt;/img&gt; or &lt;iframe&gt;&lt;/iframe&gt;) see again https://quarto.org/docs/authoring/figures.html.\n\n\n\n\nRecall a reference in the .bib-file looks like this:\n@Manual{R-base,\n  title = {R: A Language and Environment for Statistical Computing},\n  author = {{R Core Team}},\n  organization = {R Foundation for Statistical Computing},\n  address = {Vienna, Austria},\n  year = {2022},\n  url = {https://www.R-project.org/},\n}\nTo cite the R program, use @ before the so-called BibLaTex key R-base. Three example follow:\n\n\n[@R-base] renders as: (R Core Team, 2023)\n\n\n@R-base renders as: R Core Team (2023)\n\n\n[-@R-base] renders as: (2023)\n\n\nMultiple citations are separated by semicolons:\n\n\n[@R-base; @R-knitr] renders as: (R Core Team, 2023; Xie, 2023)\n\n\nFor more information on the citation syntax see the Pandoc Citations documentation.\n\n\nTechnical writing (e.g., Equations): Use $ delimiters for inline math and $$ delimiters for display math (see https://quarto.org)\n\nLinks:\n\n\n[This is a link to google.de](www.google.de) which appears as This is a link to google.de\n\n\n&lt;https://quarto.org&gt; which appears as https://quarto.org\n\n\n\nDiagrams (e.g., Mermaid,Graphviz)\nVideos\n…\n\n\n\n\n\n\n\nNote\n\n\n\nWhen using R, Quarto uses the Knitr engine7 to execute R code.\n\n\n\nWithin a Quarto document source code8 can be displayed by using ``` at the start and the end of the code.\nThe starting ``` are followed by braces around the programming language (e.g., ```{python})\nR code is included by using braces around the letter r (i.e., ```{r}; the Windows shortcut is Ctrl+Shift+I)\nThis looks like this:\n\n```{r}\n#| label: fig-example-ggplot\n#| fig-cap: \"My first ggplot\"\n#| results: hold\n\nlibrary(ggplot2)\n\nggplot(data = diamonds,\n       aes(y = carat, x = price, color = cut)) +\n  geom_point() +\n  labs(y = \"Carat\", x = \"Price\", color = \"Cut\") +\n  theme_classic()\n```\n\n\n\n\n\n\nFigure 2: My first ggplot\n\n\n\n\n\n\n\n\n\n\nExercise: Create your first R code block.\n\n\n\n\n\n\n\nWhat are chunk options? Chunk options customize the output of the code blocks. In Quarto it is recommended10 to include the chunk options as special comments (i.e., |#) at the top of the chunk.\nIn the following example, we set output: false…\n\n```{r}\n#| label: my-first-chunk\n#| output: false\n\nprint(\"hello world!\")\n```\n\n… and hence, no output is shown.\nThe most common chunk options are:\n\n\n\n\n\n\n\nChunk option\nDescription\nValue\n\n\n\necho\nInclude the source code in output\ntr ue/false/fenced\n\n\neval\nEvaluate the code chunk. If false the code of the chunk will not be executed, but depending on the echo value be displayed or not.\ntrue/false\n\n\ninclude\nInclude source code &(!) results in the output.\ntrue/false\n\n\nresults\nShould results be displayed in the output or not (false)? If yes how (markup vs. asis)?\n\nma rkup/asis/hold/ hide/false\n\n\n\nwarnings\nInclude warnings in output.\ntrue/false\n\n\n\nThere are a couple of ways to render a Quarto document:\n\nClicking the Render Button or using the keyboard shortcut (windows): Ctrl+Shift+K11\n\nUsing the terminal\n\nquarto render script.qmd --to html\nquarto render script.qmd --to pdf\n…\n\n\nUsing the quarto_render function from the quarto (R-quarto?) package\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen rendering a Quarto document, the R code chunks are executed (except you stated: eval: false).",
    "crumbs": [
      "Compendium",
      "Software",
      "A not so short introduction to Quarto"
    ]
  },
  {
    "objectID": "material/software/intro-quarto.html#what-is-quarto",
    "href": "material/software/intro-quarto.html#what-is-quarto",
    "title": "A not so short introduction to Quarto",
    "section": "",
    "text": "But, what is Pandoc? Pandoc is a universal document converter. It converts files from one markup format into another (e.g., markdown → HTML).\nIn short, with Quarto you can create different types of (reproducible) documents1 including:\n\nHTML\nPDF\nMS Word\nMarkdown\n\nThe focus of this workshop is on HTML (and PDF) documents. For an overview about all formats see here.",
    "crumbs": [
      "Compendium",
      "Software",
      "A not so short introduction to Quarto"
    ]
  },
  {
    "objectID": "material/software/intro-quarto.html#how-to-work-with-quarto",
    "href": "material/software/intro-quarto.html#how-to-work-with-quarto",
    "title": "A not so short introduction to Quarto",
    "section": "",
    "text": "It is basically the same2 as working in regular a R-script.\n\nOpen a new file: File &gt; New File &gt; Quarto Document...\n\n\n\n\n\n\n\n\n\n\nExercise: Create your first Quarto document!\n\n\n\n\n\n\nProvide a title (& author name)\n\n\n\nSave the document with a reasonable name and use the Render button\n\n\n\n\n\n\nA quarto document roughly consists of two parts:\n\nThe YAML header\n\nThe Body\n\n\n\nThe website quarto.org is a great resource to learn it (e.g., follow the guide). It is a daily companion and covers the topics in much greater detail than this page.",
    "crumbs": [
      "Compendium",
      "Software",
      "A not so short introduction to Quarto"
    ]
  },
  {
    "objectID": "material/software/intro-quarto.html#yaml-header",
    "href": "material/software/intro-quarto.html#yaml-header",
    "title": "A not so short introduction to Quarto",
    "section": "",
    "text": "The YAML3 header is enclosed by three dashes (---):\n---\ntitle: \"my-first-quarto-document\"\nformat: html\n---\n\nThe basic syntax of YAML uses so-called key-value pairs in the format key: value. This is extremely powerful, because you can generate great documents like this Quarto book without knowing much about HTML, LATEX or programming in general.\nSome useful key-value pairs:\nsubtitle: \"my subtitle\"\nauthor:\n  - \"John Doe\"\n  - \"Jane Roe\"\n  - \"Norah Jones\"\ndate: today\ntoc: true\ntoc-title: \"Inhaltsverzeichnis\"\nnumber-sections: true\n\n\n\n\n\n\nExercise: Identify useful key-value pairs\n\n\n\n\n\n\nFor the next 5 minutes or so, check out https://quarto.org and identify potential useful key: value pairs. Note: There are different YAML options for the formats:\n\nHTML\nPDF\n\n\nAdd them to your YAML header.\n\n\n\n\n\nWith Quarto it is possible to automatically generate citations and bibliographies in many different ways.\nThe key: value pair to include citations in Quarto documents is:\nbibliography: r-refs.bib\nHere we use a so-called BibLaTex (.bib) file. These files can be generated with the most reference management software programs4 (e.g., Citavi, EndNote, zotero, …).\n\n\n\n\n\n\nRandom tip on maintenance of literature management\n\n\n\n\n\nIt is highly recommended to maintain your retrieved citations. This means, whenever you download a single (!) reference by means of the doi (Digital Object Identifier), check whether the reference information is correct. This saves a lot of time in the long run.\n\n\n\nA reference in the .bib-file looks like this:\n@Manual{R-base,\n  title = {R: A Language and Environment for Statistical Computing},\n  author = {{R Core Team}},\n  organization = {R Foundation for Statistical Computing},\n  address = {Vienna, Austria},\n  year = {2022},\n  url = {https://www.R-project.org/},\n}\n\n\n\n\n\n\nExercise: Create a .bib file for the R references\n\n\n\n\n\n\nCheck the path with the base::getwd function (should be the same folder as the Quarto document, otherwise you have to provide the path in the YAML bibliography argument).\n\n\ngetwd()\n\n\nSave (some of the) R packages in a character vector.\n\n\npkgList &lt;- c(\"knitr\", # tables\n             \"kableExtra\", # tables\n             \"lavaan\", # generate data\n             \"car\", # recoding\n             \"psych\") # descriptive\n\n\nUse the write_bib function from the kntir package (Xie, 2023).\n\n\nknitr::write_bib(x = pkgList,\n                 file = \"r-refs.bib\")\n\n\n\n\nTo change the citation style (e.g., APA, Chicago Manual of Style), we use the csl key5:\ncsl: apa.csl\nThe apa.csl file can be found on github.\nThe citation syntax (How to cite the references in the text?) is briefly explained in the The Body subsection Citation syntax.\n\nThere are many different options to customize the output of the (executed code).The options can be specified:\n\nglobally (see in the following)\nper code block (see the section on Chunk options)\n\nIn the following example, we set echo: false and warning: false.\nexecute:\n  echo: false\n  warning: false\nThis means that no code and no warnings are shown, except you state it otherwise in a specific code block.\nFor more (chunk) options see https://quarto.org/docs/computations/execution-options.html.",
    "crumbs": [
      "Compendium",
      "Software",
      "A not so short introduction to Quarto"
    ]
  },
  {
    "objectID": "material/software/intro-quarto.html#quarto-body",
    "href": "material/software/intro-quarto.html#quarto-body",
    "title": "A not so short introduction to Quarto",
    "section": "",
    "text": "As explained in the section What is Quarto?:\n\nQuarto is based on Pandoc and uses its variation of markdown as its underlying document syntax (see https://quarto.org)\n\nThis means we can use Markdown syntax6 (together with the information in the YAML header) to generate the different types of documents (e.g., HTML, PDF, …).\n\n\n\n\n\n\nExercise: Work through the Markdown language section and the three subsections…\n\n\n\n\n\n\nText formatting\nHeadings\nLists\n\nThe information is very dense, so do not expect to remember everything.\n\n\n\n\nThere are plenty of different guides to get a quick overview about the language (see e.g., markdownguide, or Quarto-website). The following code snippets are copied and sometimes slightly adjusted from https://quarto.org.\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n*italics* and **bold**\n\nitalics and bold\n\n\n\nsuperscript^2^ / subscript~2~\nsuperscript2 / subscript2\n\n\n\n~~strikethrough~~\nstrikethrough\n\n\n`verbatim code`\nverbatim code\n\n\n\nTo create headings, add one (or more) # in front of the heading.\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n# Header 1\n\n\n\n## Header 2\n\n\n\n### Header 3\n\n\n\n\n\nThis goes up to level 6 (i.e., ######) which probably is not recommended to use though.\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n* unordered list\n    + sub-item 1\n    + sub-item 2\n        - sub-sub-item 1\n\n\nunordered list\n\nsub-item 1\n\nsub-item 2\n\nsub-sub-item 1\n\n\n\n\n\n\n\n1. ordered list\n2. item 2\n    i) sub-item 1\n         A.  sub-sub-item 1\n\nordered list\n\nitem 2\n\n\nsub-item 1\n\nsub-sub-item 1\n\n\n\n\n\n\n\n\nMore example can be found on https://quarto.org/docs/authoring/markdown-basics.html#lists.\n\nTo make a figure, table, equation, …, or section/heading referenceable, it is necessary to provide unique identifier. Identifiers must start with their type (e.g., #fig-, #tbl-, #eq-), except for headers (see in the following example):\nWhen we want to cross-reference the Images section, we have to provide unique identifier that is enclosed by braces {} (here: #include-images) after the heading:\n## Images {#include-images} \nAn example on how to reference figures is shown in the Images section.\nFor more on cross-referencing (e.g., how to make sub-figures) see again https://quarto.org/docs/authoring/cross-references.html.\n\nOne way to include images is as follows:\n![Here goes the caption](/path-to-file/myImage.png){#fig-myImage}\nThe caption [Here goes the caption] and label {#fig-myImage} make this figure referenceable. To reference it, use the following syntax:\nSee @fig-myImage for a graphical representation.\nIt renders to:\nSee Figure 1 for a graphical representation.\n\n\n\n\n\nFigure 1: Here goes the caption\n\n\n\n\n\n\n\n\nTip. There are a few other options to include images…\n\n\n\n\n\nOne of them is the include_graphics function from the knitr package (Xie, 2023):\n\n```{r}\n#| label: fig-demo-include\n#| eval: false\n#| code-fold: false\n\nknitr::include_graphics(\"path-to-file\")\n```\n\nIt is referenceable via the label: fig-demo-include. For now ignore the other so-called chunk options (i.e., eval, code-fold). These are explained in the Chunk options section.\nFor more (e.g., HTML way &lt;img&gt; &lt;/img&gt; or &lt;iframe&gt;&lt;/iframe&gt;) see again https://quarto.org/docs/authoring/figures.html.\n\n\n\n\nRecall a reference in the .bib-file looks like this:\n@Manual{R-base,\n  title = {R: A Language and Environment for Statistical Computing},\n  author = {{R Core Team}},\n  organization = {R Foundation for Statistical Computing},\n  address = {Vienna, Austria},\n  year = {2022},\n  url = {https://www.R-project.org/},\n}\nTo cite the R program, use @ before the so-called BibLaTex key R-base. Three example follow:\n\n\n[@R-base] renders as: (R Core Team, 2023)\n\n\n@R-base renders as: R Core Team (2023)\n\n\n[-@R-base] renders as: (2023)\n\n\nMultiple citations are separated by semicolons:\n\n\n[@R-base; @R-knitr] renders as: (R Core Team, 2023; Xie, 2023)\n\n\nFor more information on the citation syntax see the Pandoc Citations documentation.\n\n\nTechnical writing (e.g., Equations): Use $ delimiters for inline math and $$ delimiters for display math (see https://quarto.org)\n\nLinks:\n\n\n[This is a link to google.de](www.google.de) which appears as This is a link to google.de\n\n\n&lt;https://quarto.org&gt; which appears as https://quarto.org\n\n\n\nDiagrams (e.g., Mermaid,Graphviz)\nVideos\n…",
    "crumbs": [
      "Compendium",
      "Software",
      "A not so short introduction to Quarto"
    ]
  },
  {
    "objectID": "material/software/intro-quarto.html#computations",
    "href": "material/software/intro-quarto.html#computations",
    "title": "A not so short introduction to Quarto",
    "section": "",
    "text": "Note\n\n\n\nWhen using R, Quarto uses the Knitr engine7 to execute R code.\n\n\n\nWithin a Quarto document source code8 can be displayed by using ``` at the start and the end of the code.\nThe starting ``` are followed by braces around the programming language (e.g., ```{python})\nR code is included by using braces around the letter r (i.e., ```{r}; the Windows shortcut is Ctrl+Shift+I)\nThis looks like this:\n\n```{r}\n#| label: fig-example-ggplot\n#| fig-cap: \"My first ggplot\"\n#| results: hold\n\nlibrary(ggplot2)\n\nggplot(data = diamonds,\n       aes(y = carat, x = price, color = cut)) +\n  geom_point() +\n  labs(y = \"Carat\", x = \"Price\", color = \"Cut\") +\n  theme_classic()\n```\n\n\n\n\n\n\nFigure 2: My first ggplot\n\n\n\n\n\n\n\n\n\n\nExercise: Create your first R code block.\n\n\n\n\n\n\n\nWhat are chunk options? Chunk options customize the output of the code blocks. In Quarto it is recommended10 to include the chunk options as special comments (i.e., |#) at the top of the chunk.\nIn the following example, we set output: false…\n\n```{r}\n#| label: my-first-chunk\n#| output: false\n\nprint(\"hello world!\")\n```\n\n… and hence, no output is shown.\nThe most common chunk options are:\n\n\n\n\n\n\n\nChunk option\nDescription\nValue\n\n\n\necho\nInclude the source code in output\ntr ue/false/fenced\n\n\neval\nEvaluate the code chunk. If false the code of the chunk will not be executed, but depending on the echo value be displayed or not.\ntrue/false\n\n\ninclude\nInclude source code &(!) results in the output.\ntrue/false\n\n\nresults\nShould results be displayed in the output or not (false)? If yes how (markup vs. asis)?\n\nma rkup/asis/hold/ hide/false\n\n\n\nwarnings\nInclude warnings in output.\ntrue/false\n\n\n\nThere are a couple of ways to render a Quarto document:\n\nClicking the Render Button or using the keyboard shortcut (windows): Ctrl+Shift+K11\n\nUsing the terminal\n\nquarto render script.qmd --to html\nquarto render script.qmd --to pdf\n…\n\n\nUsing the quarto_render function from the quarto (R-quarto?) package\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen rendering a Quarto document, the R code chunks are executed (except you stated: eval: false).",
    "crumbs": [
      "Compendium",
      "Software",
      "A not so short introduction to Quarto"
    ]
  },
  {
    "objectID": "material/software/intro-quarto.html#footnotes",
    "href": "material/software/intro-quarto.html#footnotes",
    "title": "A not so short introduction to Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\nNote: It is also possible to generate, presentations (e.g., powerpoint, beamer), websites, books and even interactive components.↩︎\nNevertheless, it (probably) will take some time to get familiar with it↩︎\nYAML is an acronym for Yet Another Markup Language see https://en.wikipedia.org/wiki/YAML↩︎\nIf you do not use one, it is time now.↩︎\nCSL is the abbreviation for Citation Style Language (for more see https://en.wikipedia.org/wiki/Citation_Style_Language↩︎\nIt is also possible to use Latex or HTML syntax. However, you most likely run into problems when rendering into the respective other type.↩︎\nQuarto also supports the Jupyter engine.↩︎\nQuarto/Pandoc supports displaying (!) many different programming languages (see here)↩︎\nsee also here: https://yihui.org/knitr/options/↩︎\nThe rmarkdown syntax is different (e.g., {r my-label, echo = FALSE}), but it also works in Quarto.↩︎\nFor Mac it is: Cmd+Shift+K↩︎",
    "crumbs": [
      "Compendium",
      "Software",
      "A not so short introduction to Quarto"
    ]
  },
  {
    "objectID": "material/mlm/random-coeff.html",
    "href": "material/mlm/random-coeff.html",
    "title": "Random-Coefficient Model",
    "section": "",
    "text": "If you want to see the presentation in full screen go to Other Formats on the right."
  },
  {
    "objectID": "material/mlm/random-coeff.html#revealjs-presentation",
    "href": "material/mlm/random-coeff.html#revealjs-presentation",
    "title": "Random-Coefficient Model",
    "section": "",
    "text": "If you want to see the presentation in full screen go to Other Formats on the right."
  },
  {
    "objectID": "material/mlm/random-coeff.html#preface-software-i",
    "href": "material/mlm/random-coeff.html#preface-software-i",
    "title": "Random-Coefficient Model",
    "section": "Preface: Software I",
    "text": "Preface: Software I\n\nThe following packages are used:\n\n\nmlmRcPkg &lt;- c(\"merTools\",\n              \"lme4\",\n              \"flextable\",\n              \"ggplot2\")\n\n\n\nInstall packages when not already installed:\n\n\nlapply(mlmRcPkg,\n        function(x) \n          if(!x %in% rownames(installed.packages())) {\n            install.packages(x)\n            }\n      )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\nlibrary(lme4)\nlibrary(ggplot2)\nlibrary(flextable)"
  },
  {
    "objectID": "material/mlm/random-coeff.html#preface-software-ii",
    "href": "material/mlm/random-coeff.html#preface-software-ii",
    "title": "Random-Coefficient Model",
    "section": "Preface: Software II",
    "text": "Preface: Software II\nPrint list of packages and cite them via Pandoc citation.\n\n\nShow/hide fenced code\n```{r}\n#| label: write-mlmPkg\n#| code-fold: true\n#| code-summary: \"Show/hide fenced code\"\n#| output-location: fragment\n#| output: asis\n\nfor (i in 1:length(mlmRcPkg)) {\n  \n  cat(paste0(i, \". \",\n             mlmRcPkg[i],\n             \" [\", \"v\", utils::packageVersion(mlmRcPkg[i]),\", @R-\", mlmRcPkg[i],\n             \"]\\n\"))\n}\n```\n\n\nmerTools (v0.6.1, Knowles & Frederick, 2023)\nlme4 (v1.1.34, Bates et al., 2023)\nflextable (v0.9.2, Gohel & Skintzos, 2024)\nggplot2 (v3.4.3, Wickham et al., 2023)"
  },
  {
    "objectID": "material/mlm/random-coeff.html#preface-dataset",
    "href": "material/mlm/random-coeff.html#preface-dataset",
    "title": "Random-Coefficient Model",
    "section": "Preface: Dataset",
    "text": "Preface: Dataset\nRecall, we use the HSB dataset from the merTools package (Knowles & Frederick, 2023). For a more detailed description see :\n\ndat &lt;- merTools::hsb\nhead(dat, 6)\n\n  schid minority female    ses mathach size schtype meanses\n1  1224        0      1 -1.528   5.876  842       0  -0.428\n2  1224        0      1 -0.588  19.708  842       0  -0.428\n3  1224        0      0 -0.528  20.349  842       0  -0.428\n4  1224        0      0 -0.668   8.781  842       0  -0.428\n5  1224        0      0 -0.158  17.898  842       0  -0.428\n6  1224        0      0  0.022   4.583  842       0  -0.428"
  },
  {
    "objectID": "material/mlm/random-coeff.html#random-coefficient-model-i",
    "href": "material/mlm/random-coeff.html#random-coefficient-model-i",
    "title": "Random-Coefficient Model",
    "section": "Random-Coefficient Model I",
    "text": "Random-Coefficient Model I\nThe Random-Coefficient Model (also called Random-Intercept + Random-Slope Model) is a model cluster-varying level-1 predictor.\n\n\n\n\n\n\nLevel-specific equations\n\\[\n\\begin{aligned}\n\\text{Level 1: } & Y_{ij} = \\beta_{0j} + \\beta_{1j}X_{ij} + r_{ij} \\\\\n\\text{Level 2: } & \\beta_{0j} = \\gamma_{00} + u_{0j}  \\\\\n                 & \\beta_{1j} = \\gamma_{10} + u_{1j}\n\\end{aligned}\n\\]\n\nCombined equation: Substituting the level 2 equations into the level 1 equation yields the combined model equation:\n\n\\[\nY_{ij} = \\gamma_{00} + u_{0j} + \\gamma_{10}X_{ij} + u_{1j}X_{ij} + r_{ij}\n\\qquad(1)\\]"
  },
  {
    "objectID": "material/mlm/random-coeff.html#random-coefficient-model-ii",
    "href": "material/mlm/random-coeff.html#random-coefficient-model-ii",
    "title": "Random-Coefficient Model",
    "section": "Random-Coefficient Model II",
    "text": "Random-Coefficient Model II\n\nThe following parameters have to estimated:\n\nFixed effects: \\(\\gamma_{00}\\), \\(\\gamma_{10}\\)\nRandom effects: \\(VAR(u_{0j})\\), \\(VAR(u_{1j})\\), \\((RES)VAR(r_{ij})\\)\nCovariance: \\(COV(u_{0j}, u_{1j})\\)\n\nRepresent the level-2 random effects as a variance-covariance matrix:\n\n\\[T = \\Sigma_{u} = VAR\n\\begin{bmatrix}\nu_{0j} \\\\ u_{1j}\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\tau_{00} & \\tau_{01} \\\\ \\tau_{10} & \\tau_{11}\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "material/mlm/random-coeff.html#random-coefficient-model-iii",
    "href": "material/mlm/random-coeff.html#random-coefficient-model-iii",
    "title": "Random-Coefficient Model",
    "section": "Random-Coefficient Model III",
    "text": "Random-Coefficient Model III\n\n\n\n\n\n\nResearch question\n\n\n\nDoes school membership moderate the relationship between math achievement and SES?\n\n\n\nPrintTableParameter Extraction\n\n\n\n1rcMod &lt;- dat |&gt;\n2  lmer(formula = mathach ~ 1 + ses +\n                  (1 + ses | schid),\n3       REML = TRUE)\n\n\n1\n\nTake the dataset (here: dat which is the hsb dataset)…\n\n2\n\n…and then use the lmer() function. To allow the level-1 predictor to vary across cluster, we include the variable (here: ses) in the random-effects part of the formula (i.e., within the brackets (...))\n\n3\n\nSet REML estimation to TRUE.\n\n\n\n\n\n\n\nsummary(rcMod)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: mathach ~ 1 + ses + (1 + ses | schid)\n   Data: dat\n\nREML criterion at convergence: 46640.4\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-3.12272 -0.73046  0.02144  0.75610  2.94356 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n schid    (Intercept)  4.8287  2.1974        \n          ses          0.4129  0.6426   -0.11\n Residual             36.8301  6.0688        \nNumber of obs: 7185, groups:  schid, 160\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  12.6650     0.1898   66.71\nses           2.3938     0.1181   20.27\n\nCorrelation of Fixed Effects:\n    (Intr)\nses -0.045\n\n\n\n\n\n\n```{r}\n#| label: tbl-rc\n#| tbl-cap: \"Table generated by the flextable package [@R-flextable]\"\n#| code-line-numbers: 1|2-3|4\n#| output-location: column-fragment\ndat |&gt;\n  lmer(formula = mathach ~ 1 + ses +\n                  (1 + ses | schid),\n       REML = FALSE) |&gt;\n  as_flextable()\n```\n\n\n\nTable 1: Table generated by the flextable package (Gohel & Skintzos, 2024)\n\n\n\ngroupEstimateStandard ErrorstatisticFixed effects(Intercept)12.6660.18966.980ses2.3950.11820.351Random effectsschidsd__(Intercept)2.187schidcor__(Intercept).ses-0.113schidsd__ses0.631Residualsd__Observation6.069Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05square root of the estimated residual variance: 6.1data's log-likelihood under the model: -23,318.2Akaike Information Criterion: 46,648.5Bayesian Information Criterion: 46,689.7\n\n\n\n\n\n\n\n\nrcFixedEff &lt;- summary(rcMod) |&gt;\n  coefficients()\n\nrcFixedEff\n\n            Estimate Std. Error  t value\n(Intercept) 12.66502  0.1898466 66.71189\nses          2.39381  0.1181213 20.26569\n\n\n\nrcRandomEff &lt;- rcMod |&gt;\n  VarCorr() |&gt;\n  as.data.frame() |&gt;\n  subset(select = \"vcov\")\n  \nrcRandomEff\n\n        vcov\n1  4.8287337\n2  0.4129399\n3 -0.1542796\n4 36.8301467"
  },
  {
    "objectID": "material/mlm/random-coeff.html#mlm-rc-ref",
    "href": "material/mlm/random-coeff.html#mlm-rc-ref",
    "title": "Random-Coefficient Model",
    "section": "References",
    "text": "References\n\n\nBates, D., Maechler, M., Bolker, B., & Walker, S. (2023). lme4: Linear mixed-effects models using eigen and S4. https://github.com/lme4/lme4/\n\n\nGohel, D., & Skintzos, P. (2024). Flextable: Functions for tabular reporting. https://ardata-fr.github.io/flextable-book/\n\n\nKnowles, J. E., & Frederick, C. (2023). merTools: Tools for analyzing mixed effect regression models. https://CRAN.R-project.org/package=merTools\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org"
  },
  {
    "objectID": "material/mlm/random-coeff-model-reveal.html#preface-software-i",
    "href": "material/mlm/random-coeff-model-reveal.html#preface-software-i",
    "title": "Random-Coefficient Model",
    "section": "Preface: Software I",
    "text": "Preface: Software I\n\nThe following packages are used:\n\n\n\nmlmRcPkg &lt;- c(\"merTools\",\n              \"lme4\",\n              \"flextable\",\n              \"ggplot2\")\n\n\n\n\n\n\nInstall packages when not already installed:\n\n\nlapply(mlmRcPkg,\n        function(x) \n          if(!x %in% rownames(installed.packages())) {\n            install.packages(x)\n            }\n      )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\n\nlibrary(lme4)\nlibrary(ggplot2)\nlibrary(flextable)"
  },
  {
    "objectID": "material/mlm/random-coeff-model-reveal.html#preface-software-ii",
    "href": "material/mlm/random-coeff-model-reveal.html#preface-software-ii",
    "title": "Random-Coefficient Model",
    "section": "Preface: Software II",
    "text": "Preface: Software II\nPrint list of packages and cite them via Pandoc citation.\n\n\nShow/hide fenced code\n```{r}\n#| label: write-mlmPkg\n#| code-fold: true\n#| code-summary: \"Show/hide fenced code\"\n#| output-location: fragment\n#| output: asis\n\nfor (i in 1:length(mlmRcPkg)) {\n  \n  cat(paste0(i, \". \",\n             mlmRcPkg[i],\n             \" [\", \"v\", utils::packageVersion(mlmRcPkg[i]),\", @R-\", mlmRcPkg[i],\n             \"]\\n\"))\n}\n```\n\n\n\n\nmerTools (v0.6.1, Knowles & Frederick, 2023)\nlme4 (v1.1.34, Bates et al., 2023)\nflextable (v0.9.2, Gohel & Skintzos, 2024)\nggplot2 (v3.4.3, Wickham et al., 2023)"
  },
  {
    "objectID": "material/mlm/random-coeff-model-reveal.html#preface-dataset",
    "href": "material/mlm/random-coeff-model-reveal.html#preface-dataset",
    "title": "Random-Coefficient Model",
    "section": "Preface: Dataset",
    "text": "Preface: Dataset\nRecall, we use the HSB dataset from the merTools package (Knowles & Frederick, 2023). For a more detailed description see :\n\n\ndat &lt;- merTools::hsb\nhead(dat, 6)\n\n\n  schid minority female    ses mathach size schtype meanses\n1  1224        0      1 -1.528   5.876  842       0  -0.428\n2  1224        0      1 -0.588  19.708  842       0  -0.428\n3  1224        0      0 -0.528  20.349  842       0  -0.428\n4  1224        0      0 -0.668   8.781  842       0  -0.428\n5  1224        0      0 -0.158  17.898  842       0  -0.428\n6  1224        0      0  0.022   4.583  842       0  -0.428"
  },
  {
    "objectID": "material/mlm/random-coeff-model-reveal.html#random-coefficient-model-i",
    "href": "material/mlm/random-coeff-model-reveal.html#random-coefficient-model-i",
    "title": "Random-Coefficient Model",
    "section": "Random-Coefficient Model I",
    "text": "Random-Coefficient Model I\nThe Random-Coefficient Model (also called Random-Intercept + Random-Slope Model) is a model cluster-varying level-1 predictor.\n\n\n\nLevel-specific equations\n\\[\n\\begin{aligned}\n\\text{Level 1: } & Y_{ij} = \\beta_{0j} + \\beta_{1j}X_{ij} + r_{ij} \\\\\n\\text{Level 2: } & \\beta_{0j} = \\gamma_{00} + u_{0j}  \\\\\n                 & \\beta_{1j} = \\gamma_{10} + u_{1j}\n\\end{aligned}\n\\]\n\nCombined equation: Substituting the level 2 equations into the level 1 equation yields the combined model equation:\n\n\\[\nY_{ij} = \\gamma_{00} + u_{0j} + \\gamma_{10}X_{ij} + u_{1j}X_{ij} + r_{ij}\n\\qquad(1)\\]"
  },
  {
    "objectID": "material/mlm/random-coeff-model-reveal.html#random-coefficient-model-ii",
    "href": "material/mlm/random-coeff-model-reveal.html#random-coefficient-model-ii",
    "title": "Random-Coefficient Model",
    "section": "Random-Coefficient Model II",
    "text": "Random-Coefficient Model II\n\nThe following parameters have to estimated:\n\nFixed effects: \\(\\gamma_{00}\\), \\(\\gamma_{10}\\)\nRandom effects: \\(VAR(u_{0j})\\), \\(VAR(u_{1j})\\), \\((RES)VAR(r_{ij})\\)\nCovariance: \\(COV(u_{0j}, u_{1j})\\)\n\nRepresent the level-2 random effects as a variance-covariance matrix:\n\n\\[T = \\Sigma_{u} = VAR\n\\begin{bmatrix}\nu_{0j} \\\\ u_{1j}\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\tau_{00} & \\tau_{01} \\\\ \\tau_{10} & \\tau_{11}\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "material/mlm/random-coeff-model-reveal.html#random-coefficient-model-iii",
    "href": "material/mlm/random-coeff-model-reveal.html#random-coefficient-model-iii",
    "title": "Random-Coefficient Model",
    "section": "Random-Coefficient Model III",
    "text": "Random-Coefficient Model III\n\n\n\n\nResearch question\n\n\nDoes school membership moderate the relationship between math achievement and SES?\n\n\n\n\n\nPrintTableParameter Extraction\n\n\n\n\n1rcMod &lt;- dat |&gt;\n2  lmer(formula = mathach ~ 1 + ses +\n                  (1 + ses | schid),\n3       REML = TRUE)\n\n\n\n1\n\nTake the dataset (here: dat which is the hsb dataset)…\n\n2\n\n…and then use the lmer() function. To allow the level-1 predictor to vary across cluster, we include the variable (here: ses) in the random-effects part of the formula (i.e., within the brackets (...))\n\n3\n\nSet REML estimation to TRUE.\n\n\n\n\n\n\n\n\n\nsummary(rcMod)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: mathach ~ 1 + ses + (1 + ses | schid)\n   Data: dat\n\nREML criterion at convergence: 46640.4\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-3.12272 -0.73046  0.02144  0.75610  2.94356 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n schid    (Intercept)  4.8287  2.1974        \n          ses          0.4129  0.6426   -0.11\n Residual             36.8301  6.0688        \nNumber of obs: 7185, groups:  schid, 160\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  12.6650     0.1898   66.71\nses           2.3938     0.1181   20.27\n\nCorrelation of Fixed Effects:\n    (Intr)\nses -0.045\n\n\n\n\n\n\n\n\n```{r}\n#| label: tbl-rc\n#| tbl-cap: \"Table generated by the flextable package [@R-flextable]\"\n#| code-line-numbers: 1|2-3|4\n#| output-location: column-fragment\ndat |&gt;\n  lmer(formula = mathach ~ 1 + ses +\n                  (1 + ses | schid),\n       REML = FALSE) |&gt;\n  as_flextable()\n```\n\n\n\n\nTable 1: Table generated by the flextable package (Gohel & Skintzos, 2024)\n\n\n\ngroupEstimateStandard ErrorstatisticFixed effects(Intercept)12.6660.18966.980ses2.3950.11820.351Random effectsschidsd__(Intercept)2.187schidcor__(Intercept).ses-0.113schidsd__ses0.631Residualsd__Observation6.069Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05square root of the estimated residual variance: 6.1data's log-likelihood under the model: -23,318.2Akaike Information Criterion: 46,648.5Bayesian Information Criterion: 46,689.7\n\n\n\n\n\n\n\n\n\n\nrcFixedEff &lt;- summary(rcMod) |&gt;\n  coefficients()\n\nrcFixedEff\n\n\n            Estimate Std. Error  t value\n(Intercept) 12.66502  0.1898466 66.71189\nses          2.39381  0.1181213 20.26569\n\n\n\n\n\nrcRandomEff &lt;- rcMod |&gt;\n  VarCorr() |&gt;\n  as.data.frame() |&gt;\n  subset(select = \"vcov\")\n  \nrcRandomEff\n\n\n        vcov\n1  4.8287337\n2  0.4129399\n3 -0.1542796\n4 36.8301467"
  },
  {
    "objectID": "material/mlm/random-coeff-model-reveal.html#mlm-rc-ref",
    "href": "material/mlm/random-coeff-model-reveal.html#mlm-rc-ref",
    "title": "Random-Coefficient Model",
    "section": "References",
    "text": "References\n\n\nBates, D., Maechler, M., Bolker, B., & Walker, S. (2023). lme4: Linear mixed-effects models using eigen and S4. https://github.com/lme4/lme4/\n\n\nGohel, D., & Skintzos, P. (2024). Flextable: Functions for tabular reporting. https://ardata-fr.github.io/flextable-book/\n\n\nKnowles, J. E., & Frederick, C. (2023). merTools: Tools for analyzing mixed effect regression models. https://CRAN.R-project.org/package=merTools\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\n\n\n\n[Back to website]"
  },
  {
    "objectID": "material/mlm/intro-mlm.html",
    "href": "material/mlm/intro-mlm.html",
    "title": "Introduction to Multilevel Modeling",
    "section": "",
    "text": "If you want to see the presentation in full screen go to Other Formats on the right.",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#revealjs-presentation",
    "href": "material/mlm/intro-mlm.html#revealjs-presentation",
    "title": "Introduction to Multilevel Modeling",
    "section": "",
    "text": "If you want to see the presentation in full screen go to Other Formats on the right.",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#preface-software-i",
    "href": "material/mlm/intro-mlm.html#preface-software-i",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preface: Software I",
    "text": "Preface: Software I\n\nThe following packages are used:\n\n\nmlmPkg &lt;- c(\"merTools\",\n            \"lme4\",\n            \"flextable\",\n            \"psych\",\n            \"ggplot2\")\n\n\n\nInstall packages when not already installed:\n\n\nlapply(mlmPkg,\n        function(x) \n          if(!x %in% rownames(installed.packages())) {\n            install.packages(x)\n            }\n      )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\nlibrary(lme4)\nlibrary(ggplot2)\nlibrary(flextable)",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#preface-software-ii",
    "href": "material/mlm/intro-mlm.html#preface-software-ii",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preface: Software II",
    "text": "Preface: Software II\nPrint list of packages and cite them via Pandoc citation.\n\nShow/hide fenced code```{r}\n#| label: write-mlmPkg\n#| code-fold: true\n#| code-summary: \"Show/hide fenced code\"\n#| output-location: fragment\n#| output: asis\n\nfor (i in 1:length(mlmPkg)) {\n  \n  cat(paste0(i, \". \",\n             mlmPkg[i],\n             \" [\", \"v\", utils::packageVersion(mlmPkg[i]),\", @R-\", mlmPkg[i],\n             \"]\\n\"))\n}\n```\n\nmerTools (v0.6.1, Knowles & Frederick, 2023)\n\nlme4 (v1.1.34, Bates et al., 2023)\n\nflextable (v0.9.2, Gohel & Skintzos, 2024)\n\npsych (v2.3.6, Revelle, 2024)\n\nggplot2 (v3.4.3, Wickham et al., 2023)",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#preface-dataset",
    "href": "material/mlm/intro-mlm.html#preface-dataset",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preface: Dataset",
    "text": "Preface: Dataset\nWe use the HSB dataset from the merTools package (Knowles & Frederick, 2023):\n\ndat &lt;- merTools::hsb\nhead(dat, 6)\n\n  schid minority female    ses mathach size schtype meanses\n1  1224        0      1 -1.528   5.876  842       0  -0.428\n2  1224        0      1 -0.588  19.708  842       0  -0.428\n3  1224        0      0 -0.528  20.349  842       0  -0.428\n4  1224        0      0 -0.668   8.781  842       0  -0.428\n5  1224        0      0 -0.158  17.898  842       0  -0.428\n6  1224        0      0  0.022   4.583  842       0  -0.428",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#why-multilevel-modelling",
    "href": "material/mlm/intro-mlm.html#why-multilevel-modelling",
    "title": "Introduction to Multilevel Modeling",
    "section": "Why multilevel modelling?",
    "text": "Why multilevel modelling?\n\nEnvironment (often) shows natural hierarchical structures (e.g., students nested within classes/schools, time points within persons)\n\nThe hierarchical structures may (!) lead to dependency in data\n\nignoring the hierarchical data structure leads to underestimation of standard errors and biased test statistics/p-values\nviolation of the independent and identically distributed residuals (i.d.d) assumption\n\n\n\nHierarchical structures as a research object/topic\n\nexamining relations on the different level (e.g., BFLPE or ecological fallacy)\neffects/relations vary between clusters\n\n\n\n\n\nfor a graphical introduction see http://mfviz.com/hierarchical-models/",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#preliminaries-logic-of-hierarchical-linear-models-i",
    "href": "material/mlm/intro-mlm.html#preliminaries-logic-of-hierarchical-linear-models-i",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preliminaries: Logic of hierarchical linear models I",
    "text": "Preliminaries: Logic of hierarchical linear models I\nExample: The relation between socio-economic status and achievement across all (actually a subsample) schools\n\n\nFigure\nModel\n\n\n\n\nCodedat |&gt;\n  (\\(d) d[1:550,])() |&gt;\n  ggplot(aes(x = ses, y = mathach)) + \n    geom_point(shape=21,\n              fill=\"white\",\n               color=\"black\",\n               size=2) + \n    geom_smooth(method='lm',\n                formula=y~x,\n                color = \"blue\",\n                se = F,\n                linewidth = 1.5) +\n    geom_smooth(method='loess',\n                formula=y~x,\n                color = \"red\",\n                se = F,\n                linewidth = 1.5) +\n    labs(x = \"SES\",\n         y = \"Math Achievemenet\") +\n    theme_classic() \n\n\n\n\n\n\n\n\n\n\nCodedat |&gt;\n  (\\(d) d[1:550,])() |&gt;\n  lm(formula = mathach ~ ses) |&gt;\n  summary()\n\n\nCall:\nlm(formula = mathach ~ ses, data = (function(d) d[1:550, ])(dat))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.0224  -4.5656   0.1607   4.8815  17.8936 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  12.3956     0.2806   44.17   &lt;2e-16 ***\nses           4.1711     0.3551   11.74   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.58 on 548 degrees of freedom\nMultiple R-squared:  0.2011,    Adjusted R-squared:  0.1996 \nF-statistic: 137.9 on 1 and 548 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#preliminaries-logic-of-hierarchical-linear-models-ii",
    "href": "material/mlm/intro-mlm.html#preliminaries-logic-of-hierarchical-linear-models-ii",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preliminaries: Logic of hierarchical linear models II",
    "text": "Preliminaries: Logic of hierarchical linear models II\nExample: The relation between socio-economic status and achievement in two selected schools\n\nCodedat |&gt;\n  subset(subset = schid == 1224 | schid == 1462) |&gt;\n  ggplot(aes(x = ses, y = mathach)) +\n    geom_point(shape=21,\n               fill=\"white\",\n               color=\"black\",\n               size=2) +\n    geom_smooth(method='lm',\n               formula=y~x, color = \"blue\", se = F) +\n    geom_smooth(method='loess',\n               formula=y~x, color = \"red\", se = F) +\n    facet_wrap(~schid, nrow = 1) +\n    labs(x = \"SES\",\n         y = \"Math Achievemenet\") +\n    theme_classic() \n\n\n\n\n\n\n\n\n\n\\(𝐸(Y│X)= 10.81 + 2.51X\\)\n\n\n\n\\(E(Y│X)=9.994−0.82X\\)",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#preliminaries-logic-of-hierarchical-linear-models-iii",
    "href": "material/mlm/intro-mlm.html#preliminaries-logic-of-hierarchical-linear-models-iii",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preliminaries: Logic of hierarchical linear models III",
    "text": "Preliminaries: Logic of hierarchical linear models III\nExample: The relation between socio-economic status and achievement separated in J (14) schools\n\nCodeggplot(dat[1:550,],\n       aes(x = ses, y = mathach)) + \n  geom_point(shape=21,\n             fill=\"white\",\n             color=\"black\",\n             size=2) +\n  geom_smooth(method='lm',\n              formula=y~x, \n              se = F, \n              color = \"blue\") +\n  geom_smooth(method='loess',\n              formula=y~x, \n              se = F,\n              color = \"red\") +\n  facet_wrap(~schid, nrow = 2) +\n  labs(x = \"SES\",\n       y = \"Math Achievemenet\") +\n  theme_classic()",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#excursion-fixed-effects-approach-i",
    "href": "material/mlm/intro-mlm.html#excursion-fixed-effects-approach-i",
    "title": "Introduction to Multilevel Modeling",
    "section": "Excursion: Fixed effects approach I",
    "text": "Excursion: Fixed effects approach I\n\nOne way to address the hierarchical data structure is to include indicator variables (i.e., dummy variables) for the clusters in the model → fixed effects approach\nUsing reference coding we build \\((k-1)\\) indicator variables \\(I_c\\)\nModel equation (see Equation 1):\n\n\\[\nY = \\beta_0 + \\beta_1X + \\beta_2I_2 + \\beta_3I_3 + \\dots + \\beta_kI_k\n\\qquad(1)\\]",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#excursion-fixed-effects-approach-ii",
    "href": "material/mlm/intro-mlm.html#excursion-fixed-effects-approach-ii",
    "title": "Introduction to Multilevel Modeling",
    "section": "Excursion: Fixed effects approach II",
    "text": "Excursion: Fixed effects approach II\n\nExample: The relation between socio-economic status \\((X)\\) and achievement \\((Y)\\) in J (160!) schools\nModel equation (see Equation 2):\n\n\\[\nY = \\beta_0 + \\beta_1X + \\sum\\limits_{2}^{160} \\beta_kI_k\n\\qquad(2)\\]\n\nThe regression has already 162 parameters!\n\nAssumption: same relation between \\(Y\\) and \\(X\\) within all schools\n“Solution”: to include 159 interaction terms between SES and indicator variables\n\n\n“Problem”: Overfitting & number of parameters → random effects approach (see next slides)",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#rand-eff",
    "href": "material/mlm/intro-mlm.html#rand-eff",
    "title": "Introduction to Multilevel Modeling",
    "section": "Random effects approach",
    "text": "Random effects approach\nInstead of estimating a huge number of regression coefficients, it is possible to estimate only the distribution parameters (i.e., expected value and variance) of these parameters across clusters\nIn doing so, there are additional assumptions:\n\nLevel 1 residuals within all clusters follow a (multivariate) normal distribution (when the outcome is continuous): \\(r_{ij} \\sim N(0,\\sigma^2)\\)\n\nLevel 2 residuals (i.e., random effects) follow a multivariate normal distribution\n\nlet vector \\(\\mathbf{u} = (u_{0j}, u_{1j}, \\dots, u_{kj})\\) of level-2 residuals in a two-level model with \\(k\\) predictors \\(X_{ij1}, X_{ij2}, \\dots, X_{ijk}\\), then \\(u \\sim N(0,\\Sigma_u)\\)\n\nFrom the example above (i.e., a two-level model with one level-1 predictor (\\(X_{ij}\\)) with random effects)\n\n\n\n\\[\n\\left( \\begin{matrix}u_{0j} \\\\ u_{1j}\\end{matrix}\\right) \\sim N\\left(\\begin{bmatrix} 0 \\\\ 0\\end{bmatrix}, \\begin{bmatrix} VAR(u_{0j}) & COV(u_{0j}, u_{1j}) \\\\ COV(u_{1j}, u_{0j}) & VAR(u_{1j})\\end{bmatrix}\\right)\n\\]",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#model-equation",
    "href": "material/mlm/intro-mlm.html#model-equation",
    "title": "Introduction to Multilevel Modeling",
    "section": "Model Equation",
    "text": "Model Equation\n\n\n\n\n\n\nDescription of this relationship within any school \\(j\\) by the equations\n\n\n\nLevel-specific equations: \\[\n\\text{Level 1: } Y_{ij} = \\beta_{0j} + \\beta_{1j}X_{ij} + r_{ij}\n\\qquad(3)\\]\n\\[\n\\begin{aligned}\n\\text{Level 2 (intercept): }& \\beta_{0j} = \\gamma_{00} + u_{0j}\n\\end{aligned}\n\\qquad(4)\\]\n\\[\n\\begin{aligned}\n\\text{Level 2 (slope): } &\\beta_{1j} = \\gamma_{01} + u_{1j}\n\\end{aligned}\n\\qquad(5)\\]\nCombined equation: Substituting Equation 4 and Equation 5 into Equation 3 yields the combined model equation (see Equation 6):\n\\[\nY_{ij} = \\gamma_{00} + u_{0j} + (\\gamma_{01} + u_{1j})X_{ij} + r_{ij}\n\\qquad(6)\\]",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#meaning-of-the-parameters",
    "href": "material/mlm/intro-mlm.html#meaning-of-the-parameters",
    "title": "Introduction to Multilevel Modeling",
    "section": "Meaning of the parameters",
    "text": "Meaning of the parameters\n\n\nRandom intercept: \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\n\n\n\\(E(\\beta_{0j}) = \\gamma_{00}\\) → average cluster intercept across the cluster\n\n\\(VAR(\\beta_{0j}) = \\tau_{00}\\) → variance of cluster intercepts\n\n\n\nRandom slope: \\(\\beta_{1j} = \\gamma_{01} + u_{1j}\\)\n\n\n\\(E(\\beta_{1j}) = \\gamma_{01}\\) → average slope across the cluster\n\n\\(VAR(\\beta_{1j}) = \\tau_{11}\\) → variance of slopes\n\n\nCovariance between slopes and intercepts: \\(COV(\\beta_{0j}, \\beta_{1j}) = \\tau_{01}\\)\nFixed effects: \\(\\gamma_{00}, \\gamma_{01}\\)\nRandom effects/residuals: \\(u_{0j}, u_{1j}, r_{ij}\\)",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#a-closer-look-at-the-random-effects-and-residuals-i",
    "href": "material/mlm/intro-mlm.html#a-closer-look-at-the-random-effects-and-residuals-i",
    "title": "Introduction to Multilevel Modeling",
    "section": "A closer look at the random effects and residuals I",
    "text": "A closer look at the random effects and residuals I\nRandom effects/ level 2 residuals:\n\nIntercept\n\n\\[\n\\begin{aligned}\n& \\beta_{0j} = \\gamma_{00} + u_{0j} \\text{(rearrange equation)} \\\\\n& $u_{0j} = \\beta_{0j} - \\gamma_{00}\n\\end{aligned}\n\\]\n→ deviation of the cluster specific intercept (\\(\\beta_{0j}\\)) from the average intercept across cluster (\\(\\gamma_{00}\\))\n\nSlope\n\n\\(\\beta_{1j} = \\gamma_{01} + u_{1j}\\) (rearrange equation)\n\\(u_{1j} = \\beta_{1j} - \\gamma_{01}\\) → deviation of the cluster specific slope (\\(\\beta_{1j}\\)) from the average slope across cluster (\\(\\gamma_{01}\\))",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#a-closer-look-at-the-random-effects-and-residuals-ii",
    "href": "material/mlm/intro-mlm.html#a-closer-look-at-the-random-effects-and-residuals-ii",
    "title": "Introduction to Multilevel Modeling",
    "section": "A closer look at the random effects and residuals II",
    "text": "A closer look at the random effects and residuals II\nRandom effects/ level 1 residual:\nRecall EQ@ref(eq:comb-eq):\n\\(Y_{ij} = \\gamma_{00} + u_{0j} + (\\gamma_{01} + u_{1j})X_{ij} + r_{ij}\\) (rearrange equation)\n\\(r_{ij} = Y_{ij} - \\gamma_{00} - u_{0j} - \\gamma_{01}X_{ij} - u_{1j}X_{ij}\\) → deviation of the observed value (\\(Y_{ij}\\)) from the conditional expected value, given the predictor (\\(X_{ij}\\)) in cluster \\(j\\)",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#overview-of-multilevel-models",
    "href": "material/mlm/intro-mlm.html#overview-of-multilevel-models",
    "title": "Introduction to Multilevel Modeling",
    "section": "Overview of Multilevel Models",
    "text": "Overview of Multilevel Models\n\nOne-Way ANOVA with Random Effects\nModel with level-2 predictors: Means-as-Outcomes Regression\nRandom-ANCOVA (only Random-Intercept Model)\nRandom-Coefficient Modell (Random-Intercept + Random-Slope Model)\nModel with level-2 predictors + cross-level interaction\n… there are more!",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm.html#mlm-intro-ref",
    "href": "material/mlm/intro-mlm.html#mlm-intro-ref",
    "title": "Introduction to Multilevel Modeling",
    "section": "References",
    "text": "References\n\n\nBates, D., Maechler, M., Bolker, B., & Walker, S. (2023). lme4: Linear mixed-effects models using eigen and S4. https://github.com/lme4/lme4/\n\n\nGohel, D., & Skintzos, P. (2024). Flextable: Functions for tabular reporting. https://ardata-fr.github.io/flextable-book/\n\n\nKnowles, J. E., & Frederick, C. (2023). merTools: Tools for analyzing mixed effect regression models. https://CRAN.R-project.org/package=merTools\n\n\nRevelle, W. (2024). Psych: Procedures for psychological, psychometric, and personality research. https://personality-project.org/r/psych/ https://personality-project.org/r/psych-manual.pdf\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org",
    "crumbs": [
      "Compendium",
      "Multilevel Modeling",
      "Introduction to Multilevel Modeling"
    ]
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#preface-software-i",
    "href": "material/mlm/intro-mlm-reveal.html#preface-software-i",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preface: Software I",
    "text": "Preface: Software I\n\nThe following packages are used:\n\n\n\nmlmPkg &lt;- c(\"merTools\",\n            \"lme4\",\n            \"flextable\",\n            \"psych\",\n            \"ggplot2\")\n\n\n\n\n\n\nInstall packages when not already installed:\n\n\nlapply(mlmPkg,\n        function(x) \n          if(!x %in% rownames(installed.packages())) {\n            install.packages(x)\n            }\n      )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\n\nlibrary(lme4)\nlibrary(ggplot2)\nlibrary(flextable)"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#preface-software-ii",
    "href": "material/mlm/intro-mlm-reveal.html#preface-software-ii",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preface: Software II",
    "text": "Preface: Software II\nPrint list of packages and cite them via Pandoc citation.\n\nShow/hide fenced code```{r}\n#| label: write-mlmPkg\n#| code-fold: true\n#| code-summary: \"Show/hide fenced code\"\n#| output-location: fragment\n#| output: asis\n\nfor (i in 1:length(mlmPkg)) {\n  \n  cat(paste0(i, \". \",\n             mlmPkg[i],\n             \" [\", \"v\", utils::packageVersion(mlmPkg[i]),\", @R-\", mlmPkg[i],\n             \"]\\n\"))\n}\n```\n\n\n\n\nmerTools (v0.6.1, Knowles & Frederick, 2023)\n\nlme4 (v1.1.34, Bates et al., 2023)\n\nflextable (v0.9.2, Gohel & Skintzos, 2024)\n\npsych (v2.3.6, Revelle, 2024)\n\nggplot2 (v3.4.3, Wickham et al., 2023)"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#preface-dataset",
    "href": "material/mlm/intro-mlm-reveal.html#preface-dataset",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preface: Dataset",
    "text": "Preface: Dataset\nWe use the HSB dataset from the merTools package (Knowles & Frederick, 2023):\n\n\ndat &lt;- merTools::hsb\nhead(dat, 6)\n\n\n\n  schid minority female    ses mathach size schtype meanses\n1  1224        0      1 -1.528   5.876  842       0  -0.428\n2  1224        0      1 -0.588  19.708  842       0  -0.428\n3  1224        0      0 -0.528  20.349  842       0  -0.428\n4  1224        0      0 -0.668   8.781  842       0  -0.428\n5  1224        0      0 -0.158  17.898  842       0  -0.428\n6  1224        0      0  0.022   4.583  842       0  -0.428"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#why-multilevel-modelling",
    "href": "material/mlm/intro-mlm-reveal.html#why-multilevel-modelling",
    "title": "Introduction to Multilevel Modeling",
    "section": "Why multilevel modelling?",
    "text": "Why multilevel modelling?\n\nEnvironment (often) shows natural hierarchical structures (e.g., students nested within classes/schools, time points within persons)\n\nThe hierarchical structures may (!) lead to dependency in data\n\nignoring the hierarchical data structure leads to underestimation of standard errors and biased test statistics/p-values\nviolation of the independent and identically distributed residuals (i.d.d) assumption\n\n\n\nHierarchical structures as a research object/topic\n\nexamining relations on the different level (e.g., BFLPE or ecological fallacy)\neffects/relations vary between clusters\n\n\n\n\n\nfor a graphical introduction see http://mfviz.com/hierarchical-models/"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#preliminaries-logic-of-hierarchical-linear-models-i",
    "href": "material/mlm/intro-mlm-reveal.html#preliminaries-logic-of-hierarchical-linear-models-i",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preliminaries: Logic of hierarchical linear models I",
    "text": "Preliminaries: Logic of hierarchical linear models I\nExample: The relation between socio-economic status and achievement across all (actually a subsample) schools\n\n\nFigure\nModel\n\n\n\n\nCodedat |&gt;\n  (\\(d) d[1:550,])() |&gt;\n  ggplot(aes(x = ses, y = mathach)) + \n    geom_point(shape=21,\n              fill=\"white\",\n               color=\"black\",\n               size=2) + \n    geom_smooth(method='lm',\n                formula=y~x,\n                color = \"blue\",\n                se = F,\n                linewidth = 1.5) +\n    geom_smooth(method='loess',\n                formula=y~x,\n                color = \"red\",\n                se = F,\n                linewidth = 1.5) +\n    labs(x = \"SES\",\n         y = \"Math Achievemenet\") +\n    theme_classic() \n\n\n\n\n\n\n\n\n\n\nCodedat |&gt;\n  (\\(d) d[1:550,])() |&gt;\n  lm(formula = mathach ~ ses) |&gt;\n  summary()\n\n\nCall:\nlm(formula = mathach ~ ses, data = (function(d) d[1:550, ])(dat))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.0224  -4.5656   0.1607   4.8815  17.8936 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  12.3956     0.2806   44.17   &lt;2e-16 ***\nses           4.1711     0.3551   11.74   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.58 on 548 degrees of freedom\nMultiple R-squared:  0.2011,    Adjusted R-squared:  0.1996 \nF-statistic: 137.9 on 1 and 548 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#preliminaries-logic-of-hierarchical-linear-models-ii",
    "href": "material/mlm/intro-mlm-reveal.html#preliminaries-logic-of-hierarchical-linear-models-ii",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preliminaries: Logic of hierarchical linear models II",
    "text": "Preliminaries: Logic of hierarchical linear models II\nExample: The relation between socio-economic status and achievement in two selected schools\n\nCodedat |&gt;\n  subset(subset = schid == 1224 | schid == 1462) |&gt;\n  ggplot(aes(x = ses, y = mathach)) +\n    geom_point(shape=21,\n               fill=\"white\",\n               color=\"black\",\n               size=2) +\n    geom_smooth(method='lm',\n               formula=y~x, color = \"blue\", se = F) +\n    geom_smooth(method='loess',\n               formula=y~x, color = \"red\", se = F) +\n    facet_wrap(~schid, nrow = 1) +\n    labs(x = \"SES\",\n         y = \"Math Achievemenet\") +\n    theme_classic() \n\n\n\n\n\\(𝐸(Y│X)= 10.81 + 2.51X\\)\n\n\n\n\\(E(Y│X)=9.994−0.82X\\)"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#preliminaries-logic-of-hierarchical-linear-models-iii",
    "href": "material/mlm/intro-mlm-reveal.html#preliminaries-logic-of-hierarchical-linear-models-iii",
    "title": "Introduction to Multilevel Modeling",
    "section": "Preliminaries: Logic of hierarchical linear models III",
    "text": "Preliminaries: Logic of hierarchical linear models III\nExample: The relation between socio-economic status and achievement separated in J (14) schools\n\nCodeggplot(dat[1:550,],\n       aes(x = ses, y = mathach)) + \n  geom_point(shape=21,\n             fill=\"white\",\n             color=\"black\",\n             size=2) +\n  geom_smooth(method='lm',\n              formula=y~x, \n              se = F, \n              color = \"blue\") +\n  geom_smooth(method='loess',\n              formula=y~x, \n              se = F,\n              color = \"red\") +\n  facet_wrap(~schid, nrow = 2) +\n  labs(x = \"SES\",\n       y = \"Math Achievemenet\") +\n  theme_classic()"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#excursion-fixed-effects-approach-i",
    "href": "material/mlm/intro-mlm-reveal.html#excursion-fixed-effects-approach-i",
    "title": "Introduction to Multilevel Modeling",
    "section": "Excursion: Fixed effects approach I",
    "text": "Excursion: Fixed effects approach I\n\nOne way to address the hierarchical data structure is to include indicator variables (i.e., dummy variables) for the clusters in the model → fixed effects approach\nUsing reference coding we build \\((k-1)\\) indicator variables \\(I_c\\)\nModel equation (see Equation 1):\n\n\\[\nY = \\beta_0 + \\beta_1X + \\beta_2I_2 + \\beta_3I_3 + \\dots + \\beta_kI_k\n\\qquad(1)\\]"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#excursion-fixed-effects-approach-ii",
    "href": "material/mlm/intro-mlm-reveal.html#excursion-fixed-effects-approach-ii",
    "title": "Introduction to Multilevel Modeling",
    "section": "Excursion: Fixed effects approach II",
    "text": "Excursion: Fixed effects approach II\n\nExample: The relation between socio-economic status \\((X)\\) and achievement \\((Y)\\) in J (160!) schools\nModel equation (see Equation 2):\n\n\\[\nY = \\beta_0 + \\beta_1X + \\sum\\limits_{2}^{160} \\beta_kI_k\n\\qquad(2)\\]\n\nThe regression has already 162 parameters!\n\nAssumption: same relation between \\(Y\\) and \\(X\\) within all schools\n“Solution”: to include 159 interaction terms between SES and indicator variables\n\n\n“Problem”: Overfitting & number of parameters → random effects approach (see next slides)"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#rand-eff",
    "href": "material/mlm/intro-mlm-reveal.html#rand-eff",
    "title": "Introduction to Multilevel Modeling",
    "section": "Random effects approach",
    "text": "Random effects approach\nInstead of estimating a huge number of regression coefficients, it is possible to estimate only the distribution parameters (i.e., expected value and variance) of these parameters across clusters\nIn doing so, there are additional assumptions:\n\nLevel 1 residuals within all clusters follow a (multivariate) normal distribution (when the outcome is continuous): \\(r_{ij} \\sim N(0,\\sigma^2)\\)\n\nLevel 2 residuals (i.e., random effects) follow a multivariate normal distribution\n\nlet vector \\(\\mathbf{u} = (u_{0j}, u_{1j}, \\dots, u_{kj})\\) of level-2 residuals in a two-level model with \\(k\\) predictors \\(X_{ij1}, X_{ij2}, \\dots, X_{ijk}\\), then \\(u \\sim N(0,\\Sigma_u)\\)\n\nFrom the example above (i.e., a two-level model with one level-1 predictor (\\(X_{ij}\\)) with random effects)\n\n\n\n\\[\n\\left( \\begin{matrix}u_{0j} \\\\ u_{1j}\\end{matrix}\\right) \\sim N\\left(\\begin{bmatrix} 0 \\\\ 0\\end{bmatrix}, \\begin{bmatrix} VAR(u_{0j}) & COV(u_{0j}, u_{1j}) \\\\ COV(u_{1j}, u_{0j}) & VAR(u_{1j})\\end{bmatrix}\\right)\n\\]"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#model-equation",
    "href": "material/mlm/intro-mlm-reveal.html#model-equation",
    "title": "Introduction to Multilevel Modeling",
    "section": "Model Equation",
    "text": "Model Equation\n\n\n\n\nDescription of this relationship within any school \\(j\\) by the equations\n\n\nLevel-specific equations: \\[\n\\text{Level 1: } Y_{ij} = \\beta_{0j} + \\beta_{1j}X_{ij} + r_{ij}\n\\qquad(3)\\]\n\\[\n\\begin{aligned}\n\\text{Level 2 (intercept): }& \\beta_{0j} = \\gamma_{00} + u_{0j}\n\\end{aligned}\n\\qquad(4)\\]\n\\[\n\\begin{aligned}\n\\text{Level 2 (slope): } &\\beta_{1j} = \\gamma_{01} + u_{1j}\n\\end{aligned}\n\\qquad(5)\\]\nCombined equation: Substituting Equation 4 and Equation 5 into Equation 3 yields the combined model equation (see Equation 6):\n\\[\nY_{ij} = \\gamma_{00} + u_{0j} + (\\gamma_{01} + u_{1j})X_{ij} + r_{ij}\n\\qquad(6)\\]"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#meaning-of-the-parameters",
    "href": "material/mlm/intro-mlm-reveal.html#meaning-of-the-parameters",
    "title": "Introduction to Multilevel Modeling",
    "section": "Meaning of the parameters",
    "text": "Meaning of the parameters\n\n\nRandom intercept: \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\n\n\n\\(E(\\beta_{0j}) = \\gamma_{00}\\) → average cluster intercept across the cluster\n\n\\(VAR(\\beta_{0j}) = \\tau_{00}\\) → variance of cluster intercepts\n\n\n\nRandom slope: \\(\\beta_{1j} = \\gamma_{01} + u_{1j}\\)\n\n\n\\(E(\\beta_{1j}) = \\gamma_{01}\\) → average slope across the cluster\n\n\\(VAR(\\beta_{1j}) = \\tau_{11}\\) → variance of slopes\n\n\nCovariance between slopes and intercepts: \\(COV(\\beta_{0j}, \\beta_{1j}) = \\tau_{01}\\)\nFixed effects: \\(\\gamma_{00}, \\gamma_{01}\\)\nRandom effects/residuals: \\(u_{0j}, u_{1j}, r_{ij}\\)"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#a-closer-look-at-the-random-effects-and-residuals-i",
    "href": "material/mlm/intro-mlm-reveal.html#a-closer-look-at-the-random-effects-and-residuals-i",
    "title": "Introduction to Multilevel Modeling",
    "section": "A closer look at the random effects and residuals I",
    "text": "A closer look at the random effects and residuals I\nRandom effects/ level 2 residuals:\n\nIntercept\n\n\\[\n\\begin{aligned}\n& \\beta_{0j} = \\gamma_{00} + u_{0j} \\text{(rearrange equation)} \\\\\n& $u_{0j} = \\beta_{0j} - \\gamma_{00}\n\\end{aligned}\n\\]\n→ deviation of the cluster specific intercept (\\(\\beta_{0j}\\)) from the average intercept across cluster (\\(\\gamma_{00}\\))\n\nSlope\n\n\\(\\beta_{1j} = \\gamma_{01} + u_{1j}\\) (rearrange equation)\n\\(u_{1j} = \\beta_{1j} - \\gamma_{01}\\) → deviation of the cluster specific slope (\\(\\beta_{1j}\\)) from the average slope across cluster (\\(\\gamma_{01}\\))"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#a-closer-look-at-the-random-effects-and-residuals-ii",
    "href": "material/mlm/intro-mlm-reveal.html#a-closer-look-at-the-random-effects-and-residuals-ii",
    "title": "Introduction to Multilevel Modeling",
    "section": "A closer look at the random effects and residuals II",
    "text": "A closer look at the random effects and residuals II\nRandom effects/ level 1 residual:\nRecall EQ@ref(eq:comb-eq):\n\\(Y_{ij} = \\gamma_{00} + u_{0j} + (\\gamma_{01} + u_{1j})X_{ij} + r_{ij}\\) (rearrange equation)\n\\(r_{ij} = Y_{ij} - \\gamma_{00} - u_{0j} - \\gamma_{01}X_{ij} - u_{1j}X_{ij}\\) → deviation of the observed value (\\(Y_{ij}\\)) from the conditional expected value, given the predictor (\\(X_{ij}\\)) in cluster \\(j\\)"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#overview-of-multilevel-models",
    "href": "material/mlm/intro-mlm-reveal.html#overview-of-multilevel-models",
    "title": "Introduction to Multilevel Modeling",
    "section": "Overview of Multilevel Models",
    "text": "Overview of Multilevel Models\n\nOne-Way ANOVA with Random Effects\nModel with level-2 predictors: Means-as-Outcomes Regression\nRandom-ANCOVA (only Random-Intercept Model)\nRandom-Coefficient Modell (Random-Intercept + Random-Slope Model)\nModel with level-2 predictors + cross-level interaction\n… there are more!"
  },
  {
    "objectID": "material/mlm/intro-mlm-reveal.html#mlm-intro-ref",
    "href": "material/mlm/intro-mlm-reveal.html#mlm-intro-ref",
    "title": "Introduction to Multilevel Modeling",
    "section": "References",
    "text": "References\n\n\nBates, D., Maechler, M., Bolker, B., & Walker, S. (2023). lme4: Linear mixed-effects models using eigen and S4. https://github.com/lme4/lme4/\n\n\nGohel, D., & Skintzos, P. (2024). Flextable: Functions for tabular reporting. https://ardata-fr.github.io/flextable-book/\n\n\nKnowles, J. E., & Frederick, C. (2023). merTools: Tools for analyzing mixed effect regression models. https://CRAN.R-project.org/package=merTools\n\n\nRevelle, W. (2024). Psych: Procedures for psychological, psychometric, and personality research. https://personality-project.org/r/psych/ https://personality-project.org/r/psych-manual.pdf\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\n\n\n\nThis is a test"
  },
  {
    "objectID": "material/example-data/data-latent-state.html",
    "href": "material/example-data/data-latent-state.html",
    "title": "Simulated Data based on 3-dimensional CFA Multiple Group Model",
    "section": "",
    "text": "A simulated dataset used for examples in Structural Equation Modeling. The data generating model is a 3-dimensional CFA multiple group model with correlated error variables of the item indicators (sometimes called Latent state model).\n\n\n1popLsModel &lt;- '\n2eta1 =~ .6*Y11 + .6*Y21 + .6*Y31\neta2 =~ .6*Y12 + .6*Y22 + .6*Y32\neta3 =~ .6*Y13 + .6*Y23 + .6*Y33\n3Y11 + Y12 + Y13 ~ i1*1\nY21 + Y22 + Y23 ~ i2*1\nY31 + Y32 + Y33 ~ i3*1\n4Y11 ~~ .15*Y12 + .1*Y13\nY12 ~~ .15*Y13\nY21 ~~ .15*Y22 + .1*Y23\nY22 ~~ .15*Y23\nY31 ~~ .15*Y32 + .1*Y33\nY32 ~~ .15*Y33\n5eta1 ~~ .5*eta2 + .35*eta3\neta2 ~~ .5*eta3\n6eta1 ~ c(0,0)*1\neta2 ~ c(0.25, 0.25)*1\neta3 ~ c(0.5, 0.75)*1\n7eta1 ~~ c(1,1)*eta1\neta2 ~~ c(1,1)*eta2\neta3 ~~ c(1,1.5)*eta3\n'\n\n\n1\n\nDefine the population model within a literal string (i.e., surrounded by ' ')\n\n2\n\nSpecifiy measurement models (=~) and factor loadings (*)\n\n3\n\nSpecify intercepts of item indicators (~ 1)\n\n4\n\nSpecify error covariances (~~)\n\n5\n\nSpecify covariances between latent variables (~~)\n\n6\n\nSpecify means of latent variables (~ 1)\n\n7\n\nSpecify variances of latent variables (~ 1)",
    "crumbs": [
      "Compendium",
      "Example Data",
      "Simulated Data based on 3-dimensional CFA Multiple Group Model"
    ]
  },
  {
    "objectID": "material/example-data/data-latent-state.html#cfa-pre-dat-1",
    "href": "material/example-data/data-latent-state.html#cfa-pre-dat-1",
    "title": "Simulated Data based on 3-dimensional CFA Multiple Group Model",
    "section": "",
    "text": "A simulated dataset used for examples in Structural Equation Modeling. The data generating model is a 3-dimensional CFA multiple group model with correlated error variables of the item indicators (sometimes called Latent state model).\n\n\n1popLsModel &lt;- '\n2eta1 =~ .6*Y11 + .6*Y21 + .6*Y31\neta2 =~ .6*Y12 + .6*Y22 + .6*Y32\neta3 =~ .6*Y13 + .6*Y23 + .6*Y33\n3Y11 + Y12 + Y13 ~ i1*1\nY21 + Y22 + Y23 ~ i2*1\nY31 + Y32 + Y33 ~ i3*1\n4Y11 ~~ .15*Y12 + .1*Y13\nY12 ~~ .15*Y13\nY21 ~~ .15*Y22 + .1*Y23\nY22 ~~ .15*Y23\nY31 ~~ .15*Y32 + .1*Y33\nY32 ~~ .15*Y33\n5eta1 ~~ .5*eta2 + .35*eta3\neta2 ~~ .5*eta3\n6eta1 ~ c(0,0)*1\neta2 ~ c(0.25, 0.25)*1\neta3 ~ c(0.5, 0.75)*1\n7eta1 ~~ c(1,1)*eta1\neta2 ~~ c(1,1)*eta2\neta3 ~~ c(1,1.5)*eta3\n'\n\n\n1\n\nDefine the population model within a literal string (i.e., surrounded by ' ')\n\n2\n\nSpecifiy measurement models (=~) and factor loadings (*)\n\n3\n\nSpecify intercepts of item indicators (~ 1)\n\n4\n\nSpecify error covariances (~~)\n\n5\n\nSpecify covariances between latent variables (~~)\n\n6\n\nSpecify means of latent variables (~ 1)\n\n7\n\nSpecify variances of latent variables (~ 1)",
    "crumbs": [
      "Compendium",
      "Example Data",
      "Simulated Data based on 3-dimensional CFA Multiple Group Model"
    ]
  },
  {
    "objectID": "material/example-data/data-latent-state.html#simulating-the-data",
    "href": "material/example-data/data-latent-state.html#simulating-the-data",
    "title": "Simulated Data based on 3-dimensional CFA Multiple Group Model",
    "section": "Simulating the Data",
    "text": "Simulating the Data\n\n\n\n1wideLSdat &lt;- lavaan::simulateData(\n2    model = popLsModel,\n3    meanstructure = TRUE,\n4    sample.nobs = c(500, 500),\n5    seed = 987)\n\nwideLSdat$group &lt;- wideLSdat$group-1\n\n\n1\n\nTo generate the dataset with the name wideLSdat, we use the simulateData function from the lavaan package.\n\n2\n\nIn the model argument, we state the generated string (popLsModel) from above (the previous slide).\n\n3\n\n(Optional) Setting the meanstructure argument to TRUE.\n\n4\n\nThe sample.nobs argument controls the number of observation (per group). Here 2 groups with \\(n\\) = 500.\n\n5\n\nDefining seed for reproducible results.\n\n\n\n\n\nsaveRDS(wideLSdat, \"material/example-data/wideLSdat.RDS\")",
    "crumbs": [
      "Compendium",
      "Example Data",
      "Simulated Data based on 3-dimensional CFA Multiple Group Model"
    ]
  },
  {
    "objectID": "material/data-proc/data-proc-nam-lists.html",
    "href": "material/data-proc/data-proc-nam-lists.html",
    "title": "(Named) Lists & character vectors",
    "section": "",
    "text": "During the last years, I heavily rely on using (named) lists and/or character vectors. What is a character or a character vector? A character is a string It is created using single quotes or double quotes.\nmyChr &lt;- \"Hi I am string\"\nIt is possible to combine (c(...)) multiple characters into a vector or a list.\nmyChr1 &lt;- \"Hi I am string\"\nmyChr2 &lt;- \"Hi I am string, too\"\n\nmyChr &lt;- c(myChr1, myChr2)",
    "crumbs": [
      "Compendium",
      "Data (Pre-)Processing",
      "(Named) Lists & character vectors"
    ]
  },
  {
    "objectID": "material/data-proc/data-proc-nam-lists.html#named-lists",
    "href": "material/data-proc/data-proc-nam-lists.html#named-lists",
    "title": "(Named) Lists & character vectors",
    "section": "(Named) Lists",
    "text": "(Named) Lists\nWhat is a list in R? Lists are objects which contain any type of other R objects (e.g., characters, numeric inputs).\n\nmyList &lt;- list(myChr,\n               \"Hi Iam another string\",\n               3)\n\nSometimes1 it is advisable to name the list elements.\n\nmyNamedList &lt;- list(MyChr = myChr,\n                    String3 = \"Hi Iam another string\",\n                    \"Number 3\" = 3)\n\nnames(myNamedList) &lt;- c(\"MyChr\", \"String3\", \"Number 3\")\n\nOr alternatively.\n\nnames(myList) &lt;- c(\"MyChr\", \"String3\", \"Number 3\")",
    "crumbs": [
      "Compendium",
      "Data (Pre-)Processing",
      "(Named) Lists & character vectors"
    ]
  },
  {
    "objectID": "material/data-proc/data-proc-nam-lists.html#create-chr-vec",
    "href": "material/data-proc/data-proc-nam-lists.html#create-chr-vec",
    "title": "(Named) Lists & character vectors",
    "section": "Creating character vectors",
    "text": "Creating character vectors\nThe paste and paste0 functions are extremely powerful functions. They convert R objects to character vectors. With the sep= and collapse= arguments, it is possible to select specific character strings which separates/collapse the objects. It is important to note that the functions behave slightly different (see here). The focus here is on paste0 which sets sep=\"\".\nmyName &lt;- \"John Doe\"\n\npaste0(c(\"hello, my name is \", myName), collapse = \" &lt;3 \")\n[1] “hello, my name is &lt;3 John Doe”\nWe can use the paste0 function to create the names of the variables (of a measure)2. The variable names should follow a precise structure3 see Table 1.\n\n\nTable 1: Overview of the Structure of Variable Names\n\n\n\n\n\n\n\n\nAbbreviation of measure\nItem Number\nMeasurement occasion\n\n\n\nSelf-concept &gt; sc\n1\nT1\n\n\nSelf-concept &gt; sc\n2\nT1\n\n\nSelf-concept &gt; sc\n3\nT1\n\n\nSelf-concept &gt; sc\n1\nT2\n\n\nSelf-concept &gt; sc\n2\nT2\n\n\n…\n…\n…\n\n\n\n\n\n\npaste0 function\n\nlist(\"ScT1\" = paste0(\"sc\", 1:3, \"T1\"),\n     \"ScT2\" = paste0(\"sc\", 1:3, \"T2\"))\n\n$ScT1\n[1] \"sc1T1\" \"sc2T1\" \"sc3T1\"\n\n$ScT2\n[1] \"sc1T2\" \"sc2T2\" \"sc3T2\"\n\n\nIf you are really laze you could also write.\n\npaste0(\"sc\", 1:3, rep(paste0(\"T\", 1:2), each = 3))\n\n[1] \"sc1T1\" \"sc2T1\" \"sc3T1\" \"sc1T2\" \"sc2T2\" \"sc3T2\"",
    "crumbs": [
      "Compendium",
      "Data (Pre-)Processing",
      "(Named) Lists & character vectors"
    ]
  },
  {
    "objectID": "material/data-proc/data-proc-nam-lists.html#footnotes",
    "href": "material/data-proc/data-proc-nam-lists.html#footnotes",
    "title": "(Named) Lists & character vectors",
    "section": "Footnotes",
    "text": "Footnotes\n\nIt is especially advisable when you want to automate table or plot generation see e.g., here↩︎\nIt is important to point out, that it might be reasonable to import the codebook instead of creating the variable names by yourself↩︎\nOn how to create codebooks see e.g. DataWiz Knowledge Base.↩︎",
    "crumbs": [
      "Compendium",
      "Data (Pre-)Processing",
      "(Named) Lists & character vectors"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html",
    "href": "material/basic-calculations/descriptive-statistics.html",
    "title": "Descriptive statistics",
    "section": "",
    "text": "Warning\n\n\n\nThis page is work in progress and under active development.",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#revealjs-presentation",
    "href": "material/basic-calculations/descriptive-statistics.html#revealjs-presentation",
    "title": "Descriptive statistics",
    "section": "Revealjs Presentation",
    "text": "Revealjs Presentation\nIf you want to see the presentation in full screen go to Other Formats on the right.",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#preface-used-packages",
    "href": "material/basic-calculations/descriptive-statistics.html#preface-used-packages",
    "title": "Descriptive statistics",
    "section": "Preface: Used packages",
    "text": "Preface: Used packages\n\nThe following packages are used:\n\n\ndescrPkg &lt;- c(\"merTools\",\n              \"sn\",\n              \"knitr\",\n              \"flextable\",\n              \"psych\",\n              \"lavaan\",\n              \"ggplot2\")\n\n\n\nInstall packages when not already installed:\n\n\nlapply(X = descrPkg,\n       FUN = function(x) {\n          if( !x %in% rownames(installed.packages()) ) { \n            install.packages(x) }\n            }\n       )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\nlibrary(ggplot2)\nlibrary(flextable)",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#preface-cite-the-packages",
    "href": "material/basic-calculations/descriptive-statistics.html#preface-cite-the-packages",
    "title": "Descriptive statistics",
    "section": "Preface: Cite the packages",
    "text": "Preface: Cite the packages\nPrint list of packages and cite them via Pandoc citation.\n\n\nShow/hide fenced code\n```{r}\n#| label: write-pkgs\n#| code-fold: true\n#| code-summary: \"Show/hide fenced code\"\n#| output-location: fragment\n#| output: asis\n\nfor (i in 1:length(descrPkg)) {\n  \n  cat(paste0(i, \". \",\n             descrPkg[i],\n             \" [\", \"v\", utils::packageVersion(descrPkg[i]),\", @R-\", descrPkg[i],\n             \"]\\n\"))\n}\n```\n\n\nmerTools (v0.6.1, Knowles & Frederick, 2023)\nsn (v2.1.1, Azzalini, 2023)\nknitr (v1.44, Xie, 2023)\nflextable (v0.9.4, Gohel & Skintzos, 2024)\npsych (v2.3.9, Revelle, 2024)\nlavaan (v0.6.16, Rosseel et al., 2023)\nggplot2 (v3.5.0, Wickham et al., 2023)",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#preface-data-matrix",
    "href": "material/basic-calculations/descriptive-statistics.html#preface-data-matrix",
    "title": "Descriptive statistics",
    "section": "Preface: Data matrix",
    "text": "Preface: Data matrix\nVariables (e.g., characterisics), units (e.g., persons) and data (e.g., measurements) are often presented in matrix form. A matrix is a system of \\(n \\cdot p\\) quantities and looks like in the following:\n\n\\[\n\\begin{bmatrix}\nX_{11} & X_{12} & \\cdots & X_{1p} \\\\\nX_{21} & X_{22} & \\cdots & X_{2p} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\nX_{n1} & X_{n2} & \\cdots & X_{np}\n\\end{bmatrix}\n\\]\n\n\n\n\\(n\\) rows; 1 row is also known as a vector or row matrix\n\\(p\\) columns; 1 column is also known as a vector or column matrix\n\n\n\n\nsee Eid et al. (2013)",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#overview",
    "href": "material/basic-calculations/descriptive-statistics.html#overview",
    "title": "Descriptive statistics",
    "section": "Overview",
    "text": "Overview\n\n\n\n\nFrequencies\n\nAbsolute\nRelative\n\n\n\n\n\nQuantiles (not covered)\n\n\n\n\nMeasures of central tendency\n\nMean\nWeighted mean (not covered)\nWeighted geometric mean (not covered)\nMedian\nMode (not covered)\n…\n\n\n\n\n\n\n\n\nMeasures of variability\n\nStandard deviation\nVariance\nRange (Minimum, Maximum)\nInterquartile range (not covered)\nSemi-interquartile range (not covered)\n…\n\n\n\n\n\nMeasures of shape\n\nSkewness (not covered)\nKurtosis (not covered)",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#example-data-set",
    "href": "material/basic-calculations/descriptive-statistics.html#example-data-set",
    "title": "Descriptive statistics",
    "section": "Example data set",
    "text": "Example data set\nConsider the following 2 vectors within the example data set\n\nexDat &lt;- data.frame(\n  numVec = c(1, 2, 5, 3, 8),\n  chrVec = c(\"low\", \"med\", \"low\", \"high\", \"high\")\n)",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#abs-freq",
    "href": "material/basic-calculations/descriptive-statistics.html#abs-freq",
    "title": "Descriptive statistics",
    "section": "Absolute Frequencies",
    "text": "Absolute Frequencies\n\n\n\n\n\n\nAbsolute frequencies refer to the numbers of a particular value or category appearing in a variable. It may be abbreviated with \\(n_j\\) where \\(n\\) is the number of a specific value/category \\(j\\).\n\n\nExample Frequency table\n\n\n\n\n\n\n\nCategory \\(j\\)\nAbsolute Frequency (\\(n_j\\))\n\n\n\n\n\nlow (\\(j=1\\))\n2\n\n\n\nmed (\\(j=2\\))\n1\n\n\n\nhigh (\\(j=3\\))\n2\n\n\n\n\\(\\sum\\)\n\\(\\sum_{j=1}^3n_j=n=5\\)",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#abs-freq-r",
    "href": "material/basic-calculations/descriptive-statistics.html#abs-freq-r",
    "title": "Descriptive statistics",
    "section": "Absolute Frequencies in R",
    "text": "Absolute Frequencies in R\n\nbasedplyr\n\n\n\nwith(exDat,\n     table(chrVec)) \n\nchrVec\nhigh  low  med \n   2    2    1 \n\n\n\nAn important argument (useNA) and another useful function (addmargins())…\n\nwith(exDat,\n     table(chrVec, useNA = \"always\")) |&gt;\n  addmargins() \n\nchrVec\nhigh  low  med &lt;NA&gt;  Sum \n   2    2    1    0    5 \n\n\n\n\n\n\nexDat |&gt;\n  dplyr::group_by(chrVec) |&gt;\n  dplyr::summarise(absFreq = dplyr::n())\n\n# A tibble: 3 × 2\n  chrVec absFreq\n  &lt;chr&gt;    &lt;int&gt;\n1 high         2\n2 low          2\n3 med          1",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#rel-freq",
    "href": "material/basic-calculations/descriptive-statistics.html#rel-freq",
    "title": "Descriptive statistics",
    "section": "Relative Frequencies",
    "text": "Relative Frequencies\n\n\n\n\n\n\nRelative frequencies refer to the proportion of a specific value or category relative to the total number of observations (\\(n\\)).\n\\[\nh_j=\\frac{n_j}{n}\n\\]\n\n\nExample Frequency table\n\n\n\n\n\n\n\nCategory \\(j\\)\nAbsolute Frequency (\\(n_j\\))\nRelative Frequency (\\(h_j\\))\n\n\n\n\nlow (\\(j=1\\))\n2\n0.40\n\n\nmed (\\(j=2\\))\n1\n0.20\n\n\nhigh (\\(j=3\\))\n2\n0.40\n\n\n\\(\\sum\\)\n\\(\\sum_{j=1}^3n_j=n=5\\)\n\\(\\sum_{j=1}^3h_j=1\\)",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#rel-freq-r",
    "href": "material/basic-calculations/descriptive-statistics.html#rel-freq-r",
    "title": "Descriptive statistics",
    "section": "Relative Frequencies in R",
    "text": "Relative Frequencies in R\n\nbasedplyr\n\n\n\nwith(exDat,\n     table(chrVec)/sum(table(exDat$chrVec))) \n\nchrVec\nhigh  low  med \n 0.4  0.4  0.2 \n\n\n\nAnother useful function (sprintf()) to force 2 decimal and add %…\n\nwith(exDat,\n     table(chrVec)/sum(table(chrVec))) |&gt;\n     (function(x) sprintf(\"%.2f%%\", x*100))()\n\n[1] \"40.00%\" \"40.00%\" \"20.00%\"\n\n\n\n\n\n\nexDat |&gt;\n  dplyr::select(chrVec) |&gt;\n  dplyr::group_by(chrVec) |&gt;\n  dplyr::summarise(absFreq= dplyr::n()) |&gt;\n  dplyr::mutate(relFreq = absFreq/sum(absFreq)) \n\n# A tibble: 3 × 3\n  chrVec absFreq relFreq\n  &lt;chr&gt;    &lt;int&gt;   &lt;dbl&gt;\n1 high         2     0.4\n2 low          2     0.4\n3 med          1     0.2",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#descr-mean",
    "href": "material/basic-calculations/descriptive-statistics.html#descr-mean",
    "title": "Descriptive statistics",
    "section": "Mean",
    "text": "Mean\n\n\n\n\n\n\nThe mean (or arithmetic mean, average) is the sum of a collection of numbers divided by the count of numbers in the collection. The formula is given in Equation 1.\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i=\\frac{x_1+x_2+\\dots+x_n}{n}\n\\qquad(1)\\]\nFor example, consider a vector of numbers: \\(x = 1, 2, 5, 3, 8\\)\n\\[\n\\bar{x} = \\frac{(1+2+5+3+8)}{5}=3.8\n\\]\nIf the underlying data is a sample (i.e., a subset of a population), it is called the sample mean.\n\n\n\n\nHow to calculate the mean in R?\n\nwith(exDat,\n     mean(numVec))\n\n[1] 3.8",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#a-brief-note-on-missing-data",
    "href": "material/basic-calculations/descriptive-statistics.html#a-brief-note-on-missing-data",
    "title": "Descriptive statistics",
    "section": "A brief note on missing data",
    "text": "A brief note on missing data\nIn R missing values/data are represented by the symbol NA. Most of the basic functions cannot deal appropriately with missing data.\n\n\n\n\nTo demonstrate this we create another example vector (exVec2).\n\nnumVec2 &lt;- c(1, 2, 5, 3, 8, NA)\nmean(numVec2)\n\n[1] NA\n\n\n\n\n\n\n\nIf there is missing data, we are required to set the argument na.rm to TRUE.\n\nmean(numVec2, na.rm = TRUE)\n\n[1] 3.8\n\n\n\n\n\n\n\n\n\n\n\n\nOmitting or deleting missing values should–in most scenarios–be avoided altogether (Enders, 2023; Schafer & Graham, 2002)",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#descr-median",
    "href": "material/basic-calculations/descriptive-statistics.html#descr-median",
    "title": "Descriptive statistics",
    "section": "Median",
    "text": "Median\n\n\n\n\n\n\nThe median is the value separating the higher half from the lower half of a data sample, a population, or a probability distribution. For a data set, it may be thought of as “the middle” value. The formulas are given in Equation 2.\n\\[\nMdn = \\widetilde{x} =\n\\begin{cases}\nx_{(n+1)/2}                 & \\:\\: \\text{if } n  \\text{ is odd} \\\\\n(x_{n/2} + x_{(n/2)+1}) / 2 & \\:\\: \\text{if } n  \\text{ is even}\n\\end{cases}\n\\qquad(2)\\]\nConsider again the vector of numbers: \\(x = 1, 2, 5, 3, 8\\) with length \\(n = 5\\). To calculate the median you need to first, order the the vector: \\(x = 1, 2, 3, 5, 8\\) and then apply the corresponding formula (odd vs. even; here odd):\n\\[\n\\widetilde{x}=x_{\\frac{(5+1)}{2}}=x_3 = 3\n\\]\n\n\n\n\nHow to calculate the median in R?\n\nwith(exDat,\n     median(numVec))\n\n[1] 3",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#descr-var",
    "href": "material/basic-calculations/descriptive-statistics.html#descr-var",
    "title": "Descriptive statistics",
    "section": "Variance",
    "text": "Variance\n\n\n\n\n\n\nThe variance is the expectation of the squared deviation of a random variable from its mean. Usually it is distinguished between the population and the sample variance. The formula of the population variance is given in Equation 3.\n\\[VAR(X) = \\sigma^2 = \\frac{1}{N} \\sum\\limits_{i=1}^N (x_i - \\mu)^2 \\qquad(3)\\]\nThe formula of the sample variance is given in Equation 4.\n\\[\nVAR(X) = s^2 = \\frac{1}{n-1} \\sum\\limits_{i=1}^n (x_i - \\bar{x})^2\n\\qquad(4)\\]\nUsing again the vector \\(x = 1, 2, 5, 3, 8\\), the sample variance is calculated as follows:\n\\[\nVar(X) =\\frac{1}{4}((1-3.8)^2 + (2-3.8)^2 + (5-3.8)^2 + (3-3.8)^2 + (8-3.8)^2) = 7.7\n\\]\n\n\n\n\nHow to calculate the variance in R?\n\nwith(exDat,\n     var(numVec))\n\n[1] 7.7",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#descr-sd",
    "href": "material/basic-calculations/descriptive-statistics.html#descr-sd",
    "title": "Descriptive statistics",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\n\n\n\n\n\nThe standard deviation is defined as the square root of the variance. Again, it is distinguished between the population and the sample variance. The formula of the population standard deviation is given in Equation 5.\n\\[\nSD(X) = \\sigma = \\sqrt{\\sigma^2}\n\\qquad(5)\\]\nThe formula of the population standard deviation is given in Equation 6.\n\\[\nSD(X) = s = \\sqrt{s^2}\n\\qquad(6)\\]\nRecall the variance calculation from the previous slide, the (sample) variance of the vector is \\(7.7\\).\n\\[\nSD(X) = \\sqrt{7.7}=2.774887\n\\]\n\n\n\n\nHow to calculate the standard deviation in R?\n\nwith(exDat,\n     sd(numVec))\n\n[1] 2.774887",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#descr-range",
    "href": "material/basic-calculations/descriptive-statistics.html#descr-range",
    "title": "Descriptive statistics",
    "section": "Range",
    "text": "Range\n\n\n\n\n\n\nThe range of a vector is the difference between the largest (maximum) and the smallest (minimum) values/observations.\n\\[\nRange(x) = R =  x_{max}-x_{min}\n\\qquad(7)\\]\n\n\n\n\nHow to calculate the range in R?\n\nwith(exDat,\n     range(numVec))\n\n[1] 1 8\n\n\n\n\nAlternatively, calculate minimum and maximum separately…\n\nwith(exDat,{\n     c(min(numVec),\n       max(numVec))})\n\n[1] 1 8\n\n\nTo compute the range apply Equation 7.\n\nwith(exDat,\n     max(numVec)-min(numVec))\n\n[1] 7",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#put-everything-together-0-1",
    "href": "material/basic-calculations/descriptive-statistics.html#put-everything-together-0-1",
    "title": "Descriptive statistics",
    "section": "Put everything together 0",
    "text": "Put everything together 0\n\n\n\n\n\n\nExercise\n\n\n\nLet us calculate several descriptive statistics (e.g., mean, standard deviation, minimum and maximum) for multiple variables. For this exercise, we use a subset of the HSB dataset which is provided in the merTools package (Knowles & Frederick, 2023) (for some details see here):\n\ndat &lt;- merTools::hsb\nhead(dat, 10)\n\n   schid minority female    ses mathach size schtype meanses\n1   1224        0      1 -1.528   5.876  842       0  -0.428\n2   1224        0      1 -0.588  19.708  842       0  -0.428\n3   1224        0      0 -0.528  20.349  842       0  -0.428\n4   1224        0      0 -0.668   8.781  842       0  -0.428\n5   1224        0      0 -0.158  17.898  842       0  -0.428\n6   1224        0      0  0.022   4.583  842       0  -0.428\n7   1224        0      1 -0.618  -2.832  842       0  -0.428\n8   1224        0      0 -0.998   0.523  842       0  -0.428\n9   1224        0      1 -0.888   1.527  842       0  -0.428\n10  1224        0      0 -0.458  21.521  842       0  -0.428",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#put-everything-together-i",
    "href": "material/basic-calculations/descriptive-statistics.html#put-everything-together-i",
    "title": "Descriptive statistics",
    "section": "Put everything together I",
    "text": "Put everything together I\nA flexible approach would be…\n\n1myVar &lt;- c(\"Math achievement\" = \"mathach\",\n           \"Gender\" = \"female\",\n           \"Socioeconomic status\" = \"ses\",\n           \"Class size\" = \"size\")\n\n2exDescr &lt;- apply(\n3  X = dat[,myVar],\n4  MARGIN = 2,\n5  FUN = function(x) {\n6    ret &lt;- c(\n             mean(x, na.rm = T),\n             sd(x, na.rm = T),\n             min(x, na.rm = T),\n             max(x, na.rm = T)\n             )\n7    return(ret)\n    })\n\n\n1\n\nCreate a (named) character vector of the variables by using the c() function.\n\n2\n\nUse the apply function to apply a or multiple function(s) on data (here: 4 columns).\n\n3\n\nThe input is the dataset with the selected columns of interest (see 1.).\n\n4\n\nMARGIN = 2 indicates that the function should be applied over columns.\n\n5\n\nCreate the function that should be applied. Here we calculate the mean(), sd(), min() and max().\n\n6\n\nCreate a temporary R object, which should be later returned (here: the vector ret)\n\n7\n\nReturn the temporary object and close functions.\n\n\n\n\n\n\n\nThere are also functions such as colMeans(), colSums(), rowMeans() and rowSums().",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#put-everything-together-ii",
    "href": "material/basic-calculations/descriptive-statistics.html#put-everything-together-ii",
    "title": "Descriptive statistics",
    "section": "Put everything together II",
    "text": "Put everything together II\nPrint the results…\n\nexDescr |&gt;\n  print()\n\n       mathach    female           ses      size\n[1,] 12.747853 0.5281837  0.0001433542 1056.8618\n[2,]  6.878246 0.4992398  0.7793551951  604.1725\n[3,] -2.832000 0.0000000 -3.7580000000  100.0000\n[4,] 24.993000 1.0000000  2.6920000000 2713.0000\n\n\n\n This is a weird format; variables should be in rows not columns. Transpose…\n\n\n\nexDescr |&gt;\n  t() |&gt;\n  print()\n\n                [,1]        [,2]    [,3]     [,4]\nmathach 1.274785e+01   6.8782457  -2.832   24.993\nfemale  5.281837e-01   0.4992398   0.000    1.000\nses     1.433542e-04   0.7793552  -3.758    2.692\nsize    1.056862e+03 604.1724993 100.000 2713.000\n\n\n\n\n\nBetter, but still not really convincing…",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#making-a-table-i",
    "href": "material/basic-calculations/descriptive-statistics.html#making-a-table-i",
    "title": "Descriptive statistics",
    "section": "Making a table I",
    "text": "Making a table I\n\n1exDescrTab &lt;- exDescr |&gt;\n2    t() |&gt;\n    as.data.frame() |&gt;\n3    (\\(d) cbind(names(myVar), d))() |&gt;\n4    flextable() |&gt;\n5    theme_apa() |&gt;\n6    set_header_labels(\n      \"names(myVar)\" = \"Variables\",\n      V1 = \"Mean\",\n      V2 = \"SD\",\n      V3 = \"Min\",\n      V4 = \"Max\") |&gt;\n7    align(part = \"body\", align = \"c\") |&gt;\n    align(j = 1, part = \"all\", align = \"l\") |&gt;\n8    add_footer_lines(\n      as_paragraph(as_i(\"Note. \"),\n                   \"This is a footnote.\")\n      ) |&gt;\n    align(align = \"left\", part = \"footer\") |&gt;\n9    width(j = 1, width = 2, unit = \"in\") |&gt;\n    width(j = 2:5, width = 1, unit = \"in\")\n\n\n1\n\nTake the results (here: exDescr object)…\n\n2\n\n…and transpose (i.e., using the t() function) and coerce it to a data.frame object (as.data.frame())\n\n3\n\nUse the so-called lambda (or anonymous) function to bind (using the cbind() function) the variable names as the first column to the dataset.\n\n4\n\nApply the flextable() function.\n\n5\n\nUse the APA theme (theme_apa()).\n\n6\n\nRename the column names (set_header_labels()).\n\n7\n\nCenter body part of the table (align()).\n\n8\n\nAdd a footnote (add_footer_lines) and align it to the left.\n\n9\n\nChange column width (width) to 2 resp. 1 inch.",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#make-tab-ii",
    "href": "material/basic-calculations/descriptive-statistics.html#make-tab-ii",
    "title": "Descriptive statistics",
    "section": "Making a table II",
    "text": "Making a table II\nPrint the table.\n\n\nCode\nexDescrTab\n\n\n\n\nTable 1: Descriptive statistics\n\n\n\nVariablesMeanSDMinMaxMath achievement12.756.88-2.8324.99Gender0.530.500.001.00Socioeconomic status0.000.78-3.762.69Class size1,056.86604.17100.002,713.00Note. This is a footnote.",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#table-export",
    "href": "material/basic-calculations/descriptive-statistics.html#table-export",
    "title": "Descriptive statistics",
    "section": "Table export",
    "text": "Table export\nIf you want to export the table…\n\nexDescrTab |&gt;\n  set_caption(caption = \"Table X.\\nDescriptive statistics\") |&gt;\n  save_as_docx(path = \"descr-tab.docx\")",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#descr-R",
    "href": "material/basic-calculations/descriptive-statistics.html#descr-R",
    "title": "Descriptive statistics",
    "section": "Descriptive statistics with the psych package",
    "text": "Descriptive statistics with the psych package\n\nAlternatively, it is convenient to use additional R packages such as the psych package (Revelle, 2024) to calculate descriptive statistics\nHere we use the describe function (with the fast argument set to TRUE) to calculate the descriptive statistics of all variables within the example data set\n\n\ndat |&gt;\n  subset(select = -c(1)) |&gt;\n  psych::describe(fast = TRUE) |&gt;\n  flextable() |&gt;\n  colformat_double(digits = 2)\n\n\n\nTable 2: Descriptive statistics with the psych package\n\n\n\nvarsnmeansdminmaxrangese17,185.000.270.450.001.001.000.0127,185.000.530.500.001.001.000.0137,185.000.000.78-3.762.696.450.0147,185.0012.756.88-2.8324.9927.820.0857,185.001,056.86604.17100.002,713.002,613.007.1367,185.000.490.500.001.001.000.0177,185.000.010.41-1.190.832.020.00",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#exercise",
    "href": "material/basic-calculations/descriptive-statistics.html#exercise",
    "title": "Descriptive statistics",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nStyle the table according to your ideas/demands and export it to Word.",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descriptive-statistics.html#descr-ref",
    "href": "material/basic-calculations/descriptive-statistics.html#descr-ref",
    "title": "Descriptive statistics",
    "section": "References",
    "text": "References\n\n\nAzzalini, A. (2023). Sn: The skew-normal and related distributions such as the skew-t and the SUN. http://azzalini.stat.unipd.it/SN/\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und Forschungsmethoden: Lehrbuch ; mit Online-Materialien (3., korrigierte Auflage). Beltz.\n\n\nEnders, C. K. (2023). Missing data: An update on the state of the art. Psychological Methods. https://doi.org/10.1037/met0000563\n\n\nGohel, D., & Skintzos, P. (2024). Flextable: Functions for tabular reporting. https://ardata-fr.github.io/flextable-book/\n\n\nKnowles, J. E., & Frederick, C. (2023). merTools: Tools for analyzing mixed effect regression models. https://CRAN.R-project.org/package=merTools\n\n\nRevelle, W. (2024). Psych: Procedures for psychological, psychometric, and personality research. https://personality-project.org/r/psych/ https://personality-project.org/r/psych-manual.pdf\n\n\nRosseel, Y., Jorgensen, T. D., & De Wilde, L. (2023). Lavaan: Latent variable analysis. https://lavaan.ugent.be\n\n\nSchafer, J. L., & Graham, J. W. (2002). Missing data: Our view of the state of the art. Psychological Methods, 7(2), 147–177. https://doi.org/10.1037/1082-989X.7.2.147\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\nXie, Y. (2023). Knitr: A general-purpose package for dynamic report generation in r. https://yihui.org/knitr/",
    "crumbs": [
      "Compendium",
      "Basic Calculations",
      "Descriptive statistics"
    ]
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#preface-used-packages",
    "href": "material/basic-calculations/descr-reveal.html#preface-used-packages",
    "title": "Descriptive statistics",
    "section": "Preface: Used packages",
    "text": "Preface: Used packages\n\nThe following packages are used:\n\n\n\ndescrPkg &lt;- c(\"merTools\",\n              \"sn\",\n              \"knitr\",\n              \"flextable\",\n              \"psych\",\n              \"lavaan\",\n              \"ggplot2\")\n\n\n\n\n\n\nInstall packages when not already installed:\n\n\nlapply(X = descrPkg,\n       FUN = function(x) {\n          if( !x %in% rownames(installed.packages()) ) { \n            install.packages(x) }\n            }\n       )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\n\nlibrary(ggplot2)\nlibrary(flextable)"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#preface-cite-the-packages",
    "href": "material/basic-calculations/descr-reveal.html#preface-cite-the-packages",
    "title": "Descriptive statistics",
    "section": "Preface: Cite the packages",
    "text": "Preface: Cite the packages\nPrint list of packages and cite them via Pandoc citation.\n\n\nShow/hide fenced code\n```{r}\n#| label: write-pkgs\n#| code-fold: true\n#| code-summary: \"Show/hide fenced code\"\n#| output-location: fragment\n#| output: asis\n\nfor (i in 1:length(descrPkg)) {\n  \n  cat(paste0(i, \". \",\n             descrPkg[i],\n             \" [\", \"v\", utils::packageVersion(descrPkg[i]),\", @R-\", descrPkg[i],\n             \"]\\n\"))\n}\n```\n\n\n\n\nmerTools (v0.6.1, Knowles & Frederick, 2023)\nsn (v2.1.1, Azzalini, 2023)\nknitr (v1.44, Xie, 2023)\nflextable (v0.9.4, Gohel & Skintzos, 2024)\npsych (v2.3.9, Revelle, 2024)\nlavaan (v0.6.16, Rosseel et al., 2023)\nggplot2 (v3.5.0, Wickham et al., 2023)"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#preface-data-matrix",
    "href": "material/basic-calculations/descr-reveal.html#preface-data-matrix",
    "title": "Descriptive statistics",
    "section": "Preface: Data matrix",
    "text": "Preface: Data matrix\nVariables (e.g., characterisics), units (e.g., persons) and data (e.g., measurements) are often presented in matrix form. A matrix is a system of \\(n \\cdot p\\) quantities and looks like in the following:\n\n\\[\n\\begin{bmatrix}\nX_{11} & X_{12} & \\cdots & X_{1p} \\\\\nX_{21} & X_{22} & \\cdots & X_{2p} \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\nX_{n1} & X_{n2} & \\cdots & X_{np}\n\\end{bmatrix}\n\\]\n\n\n\n\\(n\\) rows; 1 row is also known as a vector or row matrix\n\\(p\\) columns; 1 column is also known as a vector or column matrix\n\n\n\n\nsee Eid et al. (2013)"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#overview",
    "href": "material/basic-calculations/descr-reveal.html#overview",
    "title": "Descriptive statistics",
    "section": "Overview",
    "text": "Overview\n\n\n\n\nFrequencies\n\nAbsolute\nRelative\n\n\n\n\n\nQuantiles (not covered)\n\n\n\n\nMeasures of central tendency\n\nMean\nWeighted mean (not covered)\nWeighted geometric mean (not covered)\nMedian\nMode (not covered)\n…\n\n\n\n\n\n\n\n\nMeasures of variability\n\nStandard deviation\nVariance\nRange (Minimum, Maximum)\nInterquartile range (not covered)\nSemi-interquartile range (not covered)\n…\n\n\n\n\n\nMeasures of shape\n\nSkewness (not covered)\nKurtosis (not covered)"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#example-data-set",
    "href": "material/basic-calculations/descr-reveal.html#example-data-set",
    "title": "Descriptive statistics",
    "section": "Example data set",
    "text": "Example data set\nConsider the following 2 vectors within the example data set\n\nexDat &lt;- data.frame(\n  numVec = c(1, 2, 5, 3, 8),\n  chrVec = c(\"low\", \"med\", \"low\", \"high\", \"high\")\n)"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#abs-freq",
    "href": "material/basic-calculations/descr-reveal.html#abs-freq",
    "title": "Descriptive statistics",
    "section": "Absolute Frequencies",
    "text": "Absolute Frequencies\n\n\n\nAbsolute frequencies refer to the numbers of a particular value or category appearing in a variable. It may be abbreviated with \\(n_j\\) where \\(n\\) is the number of a specific value/category \\(j\\).\n\n\nExample Frequency table\n\n\n\n\n\n\n\nCategory \\(j\\)\nAbsolute Frequency (\\(n_j\\))\n\n\n\n\n\nlow (\\(j=1\\))\n2\n\n\n\nmed (\\(j=2\\))\n1\n\n\n\nhigh (\\(j=3\\))\n2\n\n\n\n\\(\\sum\\)\n\\(\\sum_{j=1}^3n_j=n=5\\)"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#abs-freq-r",
    "href": "material/basic-calculations/descr-reveal.html#abs-freq-r",
    "title": "Descriptive statistics",
    "section": "Absolute Frequencies in R",
    "text": "Absolute Frequencies in R\n\nbasedplyr\n\n\n\n\nwith(exDat,\n     table(chrVec)) \n\n\nchrVec\nhigh  low  med \n   2    2    1 \n\n\n\n\nAn important argument (useNA) and another useful function (addmargins())…\n\n\nwith(exDat,\n     table(chrVec, useNA = \"always\")) |&gt;\n  addmargins() \n\n\nchrVec\nhigh  low  med &lt;NA&gt;  Sum \n   2    2    1    0    5 \n\n\n\n\n\n\n\n\nexDat |&gt;\n  dplyr::group_by(chrVec) |&gt;\n  dplyr::summarise(absFreq = dplyr::n())\n\n\n# A tibble: 3 × 2\n  chrVec absFreq\n  &lt;chr&gt;    &lt;int&gt;\n1 high         2\n2 low          2\n3 med          1"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#rel-freq",
    "href": "material/basic-calculations/descr-reveal.html#rel-freq",
    "title": "Descriptive statistics",
    "section": "Relative Frequencies",
    "text": "Relative Frequencies\n\n\n\nRelative frequencies refer to the proportion of a specific value or category relative to the total number of observations (\\(n\\)).\n\\[\nh_j=\\frac{n_j}{n}\n\\]\n\n\nExample Frequency table\n\n\n\n\n\n\n\nCategory \\(j\\)\nAbsolute Frequency (\\(n_j\\))\nRelative Frequency (\\(h_j\\))\n\n\n\n\nlow (\\(j=1\\))\n2\n0.40\n\n\nmed (\\(j=2\\))\n1\n0.20\n\n\nhigh (\\(j=3\\))\n2\n0.40\n\n\n\\(\\sum\\)\n\\(\\sum_{j=1}^3n_j=n=5\\)\n\\(\\sum_{j=1}^3h_j=1\\)"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#rel-freq-r",
    "href": "material/basic-calculations/descr-reveal.html#rel-freq-r",
    "title": "Descriptive statistics",
    "section": "Relative Frequencies in R",
    "text": "Relative Frequencies in R\n\nbasedplyr\n\n\n\n\nwith(exDat,\n     table(chrVec)/sum(table(exDat$chrVec))) \n\n\nchrVec\nhigh  low  med \n 0.4  0.4  0.2 \n\n\n\n\nAnother useful function (sprintf()) to force 2 decimal and add %…\n\n\nwith(exDat,\n     table(chrVec)/sum(table(chrVec))) |&gt;\n     (function(x) sprintf(\"%.2f%%\", x*100))()\n\n\n[1] \"40.00%\" \"40.00%\" \"20.00%\"\n\n\n\n\n\n\n\n\nexDat |&gt;\n  dplyr::select(chrVec) |&gt;\n  dplyr::group_by(chrVec) |&gt;\n  dplyr::summarise(absFreq= dplyr::n()) |&gt;\n  dplyr::mutate(relFreq = absFreq/sum(absFreq)) \n\n\n# A tibble: 3 × 3\n  chrVec absFreq relFreq\n  &lt;chr&gt;    &lt;int&gt;   &lt;dbl&gt;\n1 high         2     0.4\n2 low          2     0.4\n3 med          1     0.2"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#descr-mean",
    "href": "material/basic-calculations/descr-reveal.html#descr-mean",
    "title": "Descriptive statistics",
    "section": "Mean",
    "text": "Mean\n\n\n\nThe mean (or arithmetic mean, average) is the sum of a collection of numbers divided by the count of numbers in the collection. The formula is given in Equation 1.\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i=\\frac{x_1+x_2+\\dots+x_n}{n}\n\\qquad(1)\\]\nFor example, consider a vector of numbers: \\(x = 1, 2, 5, 3, 8\\)\n\\[\n\\bar{x} = \\frac{(1+2+5+3+8)}{5}=3.8\n\\]\nIf the underlying data is a sample (i.e., a subset of a population), it is called the sample mean.\n\n\n\n\nHow to calculate the mean in R?\n\n\nwith(exDat,\n     mean(numVec))\n\n\n[1] 3.8"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#a-brief-note-on-missing-data",
    "href": "material/basic-calculations/descr-reveal.html#a-brief-note-on-missing-data",
    "title": "Descriptive statistics",
    "section": "A brief note on missing data",
    "text": "A brief note on missing data\nIn R missing values/data are represented by the symbol NA. Most of the basic functions cannot deal appropriately with missing data.\n\n\n\n\nTo demonstrate this we create another example vector (exVec2).\n\nnumVec2 &lt;- c(1, 2, 5, 3, 8, NA)\nmean(numVec2)\n\n\n\n[1] NA\n\n\n\n\n\n\n\nIf there is missing data, we are required to set the argument na.rm to TRUE.\n\nmean(numVec2, na.rm = TRUE)\n\n\n\n[1] 3.8\n\n\n\n\n\n\n\n\n\n\n\n\n\nOmitting or deleting missing values should–in most scenarios–be avoided altogether (Enders, 2023; Schafer & Graham, 2002)\n\n\n\n\n\nMore on missing data in R"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#descr-median",
    "href": "material/basic-calculations/descr-reveal.html#descr-median",
    "title": "Descriptive statistics",
    "section": "Median",
    "text": "Median\n\n\n\nThe median is the value separating the higher half from the lower half of a data sample, a population, or a probability distribution. For a data set, it may be thought of as “the middle” value. The formulas are given in Equation 2.\n\\[\nMdn = \\widetilde{x} =\n\\begin{cases}\nx_{(n+1)/2}                 & \\:\\: \\text{if } n  \\text{ is odd} \\\\\n(x_{n/2} + x_{(n/2)+1}) / 2 & \\:\\: \\text{if } n  \\text{ is even}\n\\end{cases}\n\\qquad(2)\\]\nConsider again the vector of numbers: \\(x = 1, 2, 5, 3, 8\\) with length \\(n = 5\\). To calculate the median you need to first, order the the vector: \\(x = 1, 2, 3, 5, 8\\) and then apply the corresponding formula (odd vs. even; here odd):\n\\[\n\\widetilde{x}=x_{\\frac{(5+1)}{2}}=x_3 = 3\n\\]\n\n\n\n\nHow to calculate the median in R?\n\n\nwith(exDat,\n     median(numVec))\n\n\n[1] 3"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#descr-var",
    "href": "material/basic-calculations/descr-reveal.html#descr-var",
    "title": "Descriptive statistics",
    "section": "Variance",
    "text": "Variance\n\n\n\nThe variance is the expectation of the squared deviation of a random variable from its mean. Usually it is distinguished between the population and the sample variance. The formula of the population variance is given in Equation 3.\n\\[VAR(X) = \\sigma^2 = \\frac{1}{N} \\sum\\limits_{i=1}^N (x_i - \\mu)^2 \\qquad(3)\\]\nThe formula of the sample variance is given in Equation 4.\n\\[\nVAR(X) = s^2 = \\frac{1}{n-1} \\sum\\limits_{i=1}^n (x_i - \\bar{x})^2\n\\qquad(4)\\]\nUsing again the vector \\(x = 1, 2, 5, 3, 8\\), the sample variance is calculated as follows:\n\\[\nVar(X) =\\frac{1}{4}((1-3.8)^2 + (2-3.8)^2 + (5-3.8)^2 + (3-3.8)^2 + (8-3.8)^2) = 7.7\n\\]\n\n\n\n\nHow to calculate the variance in R?\n\n\nwith(exDat,\n     var(numVec))\n\n\n[1] 7.7"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#descr-sd",
    "href": "material/basic-calculations/descr-reveal.html#descr-sd",
    "title": "Descriptive statistics",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\n\n\nThe standard deviation is defined as the square root of the variance. Again, it is distinguished between the population and the sample variance. The formula of the population standard deviation is given in Equation 5.\n\\[\nSD(X) = \\sigma = \\sqrt{\\sigma^2}\n\\qquad(5)\\]\nThe formula of the population standard deviation is given in Equation 6.\n\\[\nSD(X) = s = \\sqrt{s^2}\n\\qquad(6)\\]\nRecall the variance calculation from the previous slide, the (sample) variance of the vector is \\(7.7\\).\n\\[\nSD(X) = \\sqrt{7.7}=2.774887\n\\]\n\n\n\n\nHow to calculate the standard deviation in R?\n\n\nwith(exDat,\n     sd(numVec))\n\n\n[1] 2.774887"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#descr-range",
    "href": "material/basic-calculations/descr-reveal.html#descr-range",
    "title": "Descriptive statistics",
    "section": "Range",
    "text": "Range\n\n\n\nThe range of a vector is the difference between the largest (maximum) and the smallest (minimum) values/observations.\n\\[\nRange(x) = R =  x_{max}-x_{min}\n\\qquad(7)\\]\n\n\n\n\nHow to calculate the range in R?\n\n\nwith(exDat,\n     range(numVec))\n\n\n[1] 1 8\n\n\n\n\n\nAlternatively, calculate minimum and maximum separately…\n\n\nwith(exDat,{\n     c(min(numVec),\n       max(numVec))})\n\n\n[1] 1 8\n\n\n\nTo compute the range apply Equation 7.\n\n\nwith(exDat,\n     max(numVec)-min(numVec))\n\n\n[1] 7"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#put-everything-together-0",
    "href": "material/basic-calculations/descr-reveal.html#put-everything-together-0",
    "title": "Descriptive statistics",
    "section": "Put everything together 0",
    "text": "Put everything together 0\n\n\n\n\n\n\n\nExercise\n\n\nLet us calculate several descriptive statistics (e.g., mean, standard deviation, minimum and maximum) for multiple variables. For this exercise, we use a subset of the HSB dataset which is provided in the merTools package (Knowles & Frederick, 2023) (for some details see here):"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#put-everything-together-0-1",
    "href": "material/basic-calculations/descr-reveal.html#put-everything-together-0-1",
    "title": "Descriptive statistics",
    "section": "Put everything together 0",
    "text": "Put everything together 0\n\n\n\n\n\n\n\nExercise\n\n\nLet us calculate several descriptive statistics (e.g., mean, standard deviation, minimum and maximum) for multiple variables. For this exercise, we use a subset of the HSB dataset which is provided in the merTools package (Knowles & Frederick, 2023) (for some details see here):\n\n\ndat &lt;- merTools::hsb\nhead(dat, 10)\n\n\n   schid minority female    ses mathach size schtype meanses\n1   1224        0      1 -1.528   5.876  842       0  -0.428\n2   1224        0      1 -0.588  19.708  842       0  -0.428\n3   1224        0      0 -0.528  20.349  842       0  -0.428\n4   1224        0      0 -0.668   8.781  842       0  -0.428\n5   1224        0      0 -0.158  17.898  842       0  -0.428\n6   1224        0      0  0.022   4.583  842       0  -0.428\n7   1224        0      1 -0.618  -2.832  842       0  -0.428\n8   1224        0      0 -0.998   0.523  842       0  -0.428\n9   1224        0      1 -0.888   1.527  842       0  -0.428\n10  1224        0      0 -0.458  21.521  842       0  -0.428"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#put-everything-together-i",
    "href": "material/basic-calculations/descr-reveal.html#put-everything-together-i",
    "title": "Descriptive statistics",
    "section": "Put everything together I",
    "text": "Put everything together I\nA flexible approach would be…\n\n\n1myVar &lt;- c(\"Math achievement\" = \"mathach\",\n           \"Gender\" = \"female\",\n           \"Socioeconomic status\" = \"ses\",\n           \"Class size\" = \"size\")\n\n2exDescr &lt;- apply(\n3  X = dat[,myVar],\n4  MARGIN = 2,\n5  FUN = function(x) {\n6    ret &lt;- c(\n             mean(x, na.rm = T),\n             sd(x, na.rm = T),\n             min(x, na.rm = T),\n             max(x, na.rm = T)\n             )\n7    return(ret)\n    })\n\n\n\n1\n\nCreate a (named) character vector of the variables by using the c() function.\n\n2\n\nUse the apply function to apply a or multiple function(s) on data (here: 4 columns).\n\n3\n\nThe input is the dataset with the selected columns of interest (see 1.).\n\n4\n\nMARGIN = 2 indicates that the function should be applied over columns.\n\n5\n\nCreate the function that should be applied. Here we calculate the mean(), sd(), min() and max().\n\n6\n\nCreate a temporary R object, which should be later returned (here: the vector ret)\n\n7\n\nReturn the temporary object and close functions.\n\n\n\n\n\n\n\n\nThere are also functions such as colMeans(), colSums(), rowMeans() and rowSums()."
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#put-everything-together-ii",
    "href": "material/basic-calculations/descr-reveal.html#put-everything-together-ii",
    "title": "Descriptive statistics",
    "section": "Put everything together II",
    "text": "Put everything together II\nPrint the results…\n\n\nexDescr |&gt;\n  print()\n\n\n       mathach    female           ses      size\n[1,] 12.747853 0.5281837  0.0001433542 1056.8618\n[2,]  6.878246 0.4992398  0.7793551951  604.1725\n[3,] -2.832000 0.0000000 -3.7580000000  100.0000\n[4,] 24.993000 1.0000000  2.6920000000 2713.0000\n\n\n\n\n This is a weird format; variables should be in rows not columns. Transpose…\n\n\n\n\nexDescr |&gt;\n  t() |&gt;\n  print()\n\n\n                [,1]        [,2]    [,3]     [,4]\nmathach 1.274785e+01   6.8782457  -2.832   24.993\nfemale  5.281837e-01   0.4992398   0.000    1.000\nses     1.433542e-04   0.7793552  -3.758    2.692\nsize    1.056862e+03 604.1724993 100.000 2713.000\n\n\n\n\n\n\nBetter, but still not really convincing…"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#making-a-table-i",
    "href": "material/basic-calculations/descr-reveal.html#making-a-table-i",
    "title": "Descriptive statistics",
    "section": "Making a table I",
    "text": "Making a table I\n\n\n1exDescrTab &lt;- exDescr |&gt;\n2    t() |&gt;\n    as.data.frame() |&gt;\n3    (\\(d) cbind(names(myVar), d))() |&gt;\n4    flextable() |&gt;\n5    theme_apa() |&gt;\n6    set_header_labels(\n      \"names(myVar)\" = \"Variables\",\n      V1 = \"Mean\",\n      V2 = \"SD\",\n      V3 = \"Min\",\n      V4 = \"Max\") |&gt;\n7    align(part = \"body\", align = \"c\") |&gt;\n    align(j = 1, part = \"all\", align = \"l\") |&gt;\n8    add_footer_lines(\n      as_paragraph(as_i(\"Note. \"),\n                   \"This is a footnote.\")\n      ) |&gt;\n    align(align = \"left\", part = \"footer\") |&gt;\n9    width(j = 1, width = 2, unit = \"in\") |&gt;\n    width(j = 2:5, width = 1, unit = \"in\")\n\n\n\n1\n\nTake the results (here: exDescr object)…\n\n2\n\n…and transpose (i.e., using the t() function) and coerce it to a data.frame object (as.data.frame())\n\n3\n\nUse the so-called lambda (or anonymous) function to bind (using the cbind() function) the variable names as the first column to the dataset.\n\n4\n\nApply the flextable() function.\n\n5\n\nUse the APA theme (theme_apa()).\n\n6\n\nRename the column names (set_header_labels()).\n\n7\n\nCenter body part of the table (align()).\n\n8\n\nAdd a footnote (add_footer_lines) and align it to the left.\n\n9\n\nChange column width (width) to 2 resp. 1 inch.\n\n\n\n\n\n\nLambda functions, also known as anonymous functions, are a feature in many programming languages, including R. In R, a lambda function is a function that is not bound to a name. This means that it can be created and used on the fly without defining it in the standard way with a name. Lambda functions are particularly useful for short, one-off functions that are used as arguments to other functions, like in apply family functions or in operations that involve the pipe operator (|&gt;)."
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#make-tab-ii",
    "href": "material/basic-calculations/descr-reveal.html#make-tab-ii",
    "title": "Descriptive statistics",
    "section": "Making a table II",
    "text": "Making a table II\nPrint the table.\n\n\nCode\nexDescrTab\n\n\n\n\nTable 1: Descriptive statistics\n\n\n\nVariablesMeanSDMinMaxMath achievement12.756.88-2.8324.99Gender0.530.500.001.00Socioeconomic status0.000.78-3.762.69Class size1,056.86604.17100.002,713.00Note. This is a footnote."
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#table-export",
    "href": "material/basic-calculations/descr-reveal.html#table-export",
    "title": "Descriptive statistics",
    "section": "Table export",
    "text": "Table export\nIf you want to export the table…\n\nexDescrTab |&gt;\n  set_caption(caption = \"Table X.\\nDescriptive statistics\") |&gt;\n  save_as_docx(path = \"descr-tab.docx\")"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#descr-R",
    "href": "material/basic-calculations/descr-reveal.html#descr-R",
    "title": "Descriptive statistics",
    "section": "Descriptive statistics with the psych package",
    "text": "Descriptive statistics with the psych package\n\nAlternatively, it is convenient to use additional R packages such as the psych package (Revelle, 2024) to calculate descriptive statistics\nHere we use the describe function (with the fast argument set to TRUE) to calculate the descriptive statistics of all variables within the example data set\n\n\ndat |&gt;\n  subset(select = -c(1)) |&gt;\n  psych::describe(fast = TRUE) |&gt;\n  flextable() |&gt;\n  colformat_double(digits = 2)\n\n\n\nTable 2: Descriptive statistics with the psych package\n\n\n\nvarsnmeansdminmaxrangese17,185.000.270.450.001.001.000.0127,185.000.530.500.001.001.000.0137,185.000.000.78-3.762.696.450.0147,185.0012.756.88-2.8324.9927.820.0857,185.001,056.86604.17100.002,713.002,613.007.1367,185.000.490.500.001.001.000.0177,185.000.010.41-1.190.832.020.00"
  },
  {
    "objectID": "material/basic-calculations/descr-reveal.html#exercise",
    "href": "material/basic-calculations/descr-reveal.html#exercise",
    "title": "Descriptive statistics",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nStyle the table according to your ideas/demands and export it to Word."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sven Rieger",
    "section": "",
    "text": "I am a postdoctoral researcher in educational research at the University of Tübingen in Germany."
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "Sven Rieger",
    "section": "Interests",
    "text": "Interests\nMy research interests encompass:\n\nlatent variable modeling (focus on longitudinal analyses)\ncausal inference\nautomation of data analyses with R and Quarto\nmotivation & personality development"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Sven Rieger",
    "section": "Education",
    "text": "Education\n\nPhD in Psychology (Dr.rer.nat), 2014 - 2018, University of Tübingen\nStudies of Education Sciences and Psychology (M.Sc.), 2012 - 2014, University of Tübingen\nStudies of Education (B.A.), 2009 - 2012, University of Tübingen"
  },
  {
    "objectID": "material/data-proc/data-proc-func-loops.html",
    "href": "material/data-proc/data-proc-func-loops.html",
    "title": "Functions and Loops",
    "section": "",
    "text": "Writing functions is the best way to enhance your data processing skills. Functions allow you to automate tasks that are needed to be repeated more than 2-times. This sections gives a brief introduction in writing your own functions. There are other sources that cover this topic in much more detail (see R for Data Science by Hadley Wickham & Garrett Grolemund).\nExample: We want to calculate the mean, standard deviation and range of two variables.\nThe copy/paste way.\n\nset.seed(999)\n\nx &lt;- rnorm(50)\ny &lt;- rnorm(50)\n\nmean(x)\nsd(x)\nrange(x)\n\nmean(y)\nsd(y)\nrange(y)\n\nLets put it a function.\n\nPick a name for the function (here: myFirstFunction)\nDefine the inputs and arguments of the function. These are written within the regular brackets (...) (here the input is: variable)\nWrite the code in the body of the function which is between the curly brackets { }.\n\nCalculate the mean, the standard deviation and the range\nStore it in a named list (for what a named list is useful see below)\n\nreturn the named list\n\n\n\n\nmyFirstFunction &lt;- function ( variable ) {\n  \n  fMEAN &lt;- mean(variable)\n  fSD &lt;- sd(variable)\n  fRANGE &lt;- range(variable)\n  \n  fOut &lt;- c(\"Mean\" = fMEAN,\n            \"SD\" = fSD,\n            \"Min\" = fRANGE[1],\n            \"Max\" = fRANGE[2])\n  \n  return(fOut)\n  \n}\n\n\nmyFirstFunction(variable = x)\n\n      Mean         SD        Min        Max \n-0.2576685  0.9897502 -2.1137370  2.3826642",
    "crumbs": [
      "Compendium",
      "Data (Pre-)Processing",
      "Functions and Loops"
    ]
  },
  {
    "objectID": "material/data-proc/data-proc-func-loops.html#writing-functions",
    "href": "material/data-proc/data-proc-func-loops.html#writing-functions",
    "title": "Functions and Loops",
    "section": "",
    "text": "Writing functions is the best way to enhance your data processing skills. Functions allow you to automate tasks that are needed to be repeated more than 2-times. This sections gives a brief introduction in writing your own functions. There are other sources that cover this topic in much more detail (see R for Data Science by Hadley Wickham & Garrett Grolemund).\nExample: We want to calculate the mean, standard deviation and range of two variables.\nThe copy/paste way.\n\nset.seed(999)\n\nx &lt;- rnorm(50)\ny &lt;- rnorm(50)\n\nmean(x)\nsd(x)\nrange(x)\n\nmean(y)\nsd(y)\nrange(y)\n\nLets put it a function.\n\nPick a name for the function (here: myFirstFunction)\nDefine the inputs and arguments of the function. These are written within the regular brackets (...) (here the input is: variable)\nWrite the code in the body of the function which is between the curly brackets { }.\n\nCalculate the mean, the standard deviation and the range\nStore it in a named list (for what a named list is useful see below)\n\nreturn the named list\n\n\n\n\nmyFirstFunction &lt;- function ( variable ) {\n  \n  fMEAN &lt;- mean(variable)\n  fSD &lt;- sd(variable)\n  fRANGE &lt;- range(variable)\n  \n  fOut &lt;- c(\"Mean\" = fMEAN,\n            \"SD\" = fSD,\n            \"Min\" = fRANGE[1],\n            \"Max\" = fRANGE[2])\n  \n  return(fOut)\n  \n}\n\n\nmyFirstFunction(variable = x)\n\n      Mean         SD        Min        Max \n-0.2576685  0.9897502 -2.1137370  2.3826642",
    "crumbs": [
      "Compendium",
      "Data (Pre-)Processing",
      "Functions and Loops"
    ]
  },
  {
    "objectID": "material/data-proc/data-proc-func-loops.html#loops",
    "href": "material/data-proc/data-proc-func-loops.html#loops",
    "title": "Functions and Loops",
    "section": "Loops",
    "text": "Loops\nsome text about loops\nTo execute the function on both variables…\n\n\nApproach 1: apply family\nApproach 2: for loop\n\n\n\n\nsapply(list(x, y),\n       function(myVar) myFirstFunction(variable = myVar),\n       simplify = F)\n\n[[1]]\n      Mean         SD        Min        Max \n-0.2576685  0.9897502 -2.1137370  2.3826642 \n\n[[2]]\n       Mean          SD         Min         Max \n 0.04328125  0.87849494 -2.06482325  1.74441160 \n\n\n\n\n\nfor (myvar in list(x,y)) {\n  print(\n    myFirstFunction(variable = myvar)\n  )\n}\n\n      Mean         SD        Min        Max \n-0.2576685  0.9897502 -2.1137370  2.3826642 \n       Mean          SD         Min         Max \n 0.04328125  0.87849494 -2.06482325  1.74441160",
    "crumbs": [
      "Compendium",
      "Data (Pre-)Processing",
      "Functions and Loops"
    ]
  },
  {
    "objectID": "material/example-data/data-hsb.html",
    "href": "material/example-data/data-hsb.html",
    "title": "High School and Beyond (HSB)",
    "section": "",
    "text": "A subset of data from the 1982 High School and Beyond (HSB) survey used as examples for HLM software.\n\n?merTools::hsb\n\nA data frame with 7,185 observations on the following 8 variables.\n\n\n\n\nschid: a numeric vector, 160 unique values\n\nmathach: a numeric vector for the performance on a standardized math assessment\n\nfemale: a numeric vector coded 0 for male and 1 for female\n\nses: a numeric measure of student socio-economic status\n\n\n\n\n\n\nminority: a numeric vector coded 0 for white and 1 for non-white students\n\nschtype: a numeric vector coded 0 for public and 1 for private schools\n\nmeanses: anumeric, the average SES for each school in the data set\n\nsize: a numeric for the number of students in the school",
    "crumbs": [
      "Compendium",
      "Example Data",
      "High School and Beyond (HSB)"
    ]
  },
  {
    "objectID": "material/example-data/data-hsb.html#dataset-description",
    "href": "material/example-data/data-hsb.html#dataset-description",
    "title": "High School and Beyond (HSB)",
    "section": "",
    "text": "A subset of data from the 1982 High School and Beyond (HSB) survey used as examples for HLM software.\n\n?merTools::hsb\n\nA data frame with 7,185 observations on the following 8 variables.\n\n\n\n\nschid: a numeric vector, 160 unique values\n\nmathach: a numeric vector for the performance on a standardized math assessment\n\nfemale: a numeric vector coded 0 for male and 1 for female\n\nses: a numeric measure of student socio-economic status\n\n\n\n\n\n\nminority: a numeric vector coded 0 for white and 1 for non-white students\n\nschtype: a numeric vector coded 0 for public and 1 for private schools\n\nmeanses: anumeric, the average SES for each school in the data set\n\nsize: a numeric for the number of students in the school",
    "crumbs": [
      "Compendium",
      "Example Data",
      "High School and Beyond (HSB)"
    ]
  },
  {
    "objectID": "material/example-data/data-hsb.html#import-hsb",
    "href": "material/example-data/data-hsb.html#import-hsb",
    "title": "High School and Beyond (HSB)",
    "section": "Import HSB dataset",
    "text": "Import HSB dataset\n\ndat &lt;- merTools::hsb\nhead(dat, 10)\n\n   schid minority female    ses mathach size schtype meanses\n1   1224        0      1 -1.528   5.876  842       0  -0.428\n2   1224        0      1 -0.588  19.708  842       0  -0.428\n3   1224        0      0 -0.528  20.349  842       0  -0.428\n4   1224        0      0 -0.668   8.781  842       0  -0.428\n5   1224        0      0 -0.158  17.898  842       0  -0.428\n6   1224        0      0  0.022   4.583  842       0  -0.428\n7   1224        0      1 -0.618  -2.832  842       0  -0.428\n8   1224        0      0 -0.998   0.523  842       0  -0.428\n9   1224        0      1 -0.888   1.527  842       0  -0.428\n10  1224        0      0 -0.458  21.521  842       0  -0.428",
    "crumbs": [
      "Compendium",
      "Example Data",
      "High School and Beyond (HSB)"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#preface-software",
    "href": "material/measurement-models/cfa-reveal.html#preface-software",
    "title": "Confirmatory Factor Analyses",
    "section": "Preface: Software",
    "text": "Preface: Software\n\nThe following packages are used:\n\n\n\ncfaPkg &lt;- c(\"lavaan\",\n            \"flextable\")\n\n\n\n\n\n\nInstall packages when not already installed:\n\n\nlapply(cfaPkg,\n       function(x)\n        if(!x %in% rownames(installed.packages())) {\n          install.packages(x) \n          }\n      )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\n\nlibrary(lavaan)\nlibrary(flextable)"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#preface-data",
    "href": "material/measurement-models/cfa-reveal.html#preface-data",
    "title": "Confirmatory Factor Analyses",
    "section": "Preface: Data",
    "text": "Preface: Data\nTo demonstrate, we use the first measurement time point of a simulated data set. The data simulation is described in the Example Data section. Alternatively, you can download the wideLSdat.RDS file here.\n\nwideLSdat &lt;- readRDS(\"../example-data/wideLSdat.RDS\")"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#confirmatory-factor-analysis-cfa-overview",
    "href": "material/measurement-models/cfa-reveal.html#confirmatory-factor-analysis-cfa-overview",
    "title": "Confirmatory Factor Analyses",
    "section": "Confirmatory Factor Analysis (CFA): Overview",
    "text": "Confirmatory Factor Analysis (CFA): Overview\n\nIntroduction & Purposes of CFA\nParameters & graphical visualization\nEstimation of parameters\nModel identification\nModel evaluation\nImplementation in the R package lavaan (Rosseel et al., 2023)"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#cfa-intro",
    "href": "material/measurement-models/cfa-reveal.html#cfa-intro",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: Introduction",
    "text": "CFA: Introduction\n\nConfirmatory factor analysis” (CFA) is a type of structural equation modeling that deals specifically with measurement models, that is, the relationships between observed measures or “indicators” (e.g., items, test scores, behavioral observation ratings) and latent variables or “factors. (Brown & Moore, 2012, p. 361)\n\nGoal: to establish the number and nature of factors (i.e., latent variables) that account for the variation and covariation among a set of indicators\n\nthe indicators (i.e., observed measures) are intercorrelated because they share a common cause (or with other words: are influenced by the same underlying construct)"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#purp-cfa",
    "href": "material/measurement-models/cfa-reveal.html#purp-cfa",
    "title": "Confirmatory Factor Analyses",
    "section": "Purposes of CFA",
    "text": "Purposes of CFA\n\nPsychometric evaluation (e.g., Reliability; for scale reliability see here)\nDetection of method effects (e.g., covariation among indicators, after the latent variable was partialed out)\nConstruct validation (e.g., convergent and discriminant validity); see also multi-trait-multi-method approaches (Campbell & Fiske, 1959)\nEvaluation of measurement invariance (see here)\nScale development"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#cfa-param",
    "href": "material/measurement-models/cfa-reveal.html#cfa-param",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA parameters & graphical visualization",
    "text": "CFA parameters & graphical visualization\n\n\n\n\nVariance of the latent variable: \\(\\Psi\\)\nIntercepts: \\(\\nu\\)\nFactor loadings: \\(\\lambda\\)\nError variances: \\(\\theta\\)\n\n\n\n\n\n\\[Y_i = \\nu_i + \\lambda_i\\eta + \\theta_i\\]\n\n\n\n\n\\(\\Psi\\): Psi\n\\(\\nu\\): Nu\n\\(\\lambda\\): Lambda\n\\(\\theta\\): Theta"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#scale-rel",
    "href": "material/measurement-models/cfa-reveal.html#scale-rel",
    "title": "Confirmatory Factor Analyses",
    "section": "Scale Reliability",
    "text": "Scale Reliability\n\nThere is some debate about Cronbach’s Alpha Reliability Coefficient (Revelle & Zinbarg, 2009; Sijtsma, 2009)\n\n\nEven though the pages of Psychometrika have been filled over the years with critiques and cautions about coefficient α and have seen elegant solutions for more appropriate estimates, few of these suggested coefficient are used.” (p.2)\n\n\nAn alternative: Scale reliability\n\n[…] “reliability“ as the ratio of true variance to observed variance […]” (Raykov & Marcoulides, 2015)\n\nScale reliability: \\(\\rho = \\frac{(\\lambda_1+\\dots+\\lambda_k)^2}{(\\lambda_1+\\dots+\\lambda_k)^2+\\theta_1+\\dots+\\theta_k}\\)\n\n\n\nsee also McNeish (2017); Savalei & Reise (2019)"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#cfa-param-est",
    "href": "material/measurement-models/cfa-reveal.html#cfa-param-est",
    "title": "Confirmatory Factor Analyses",
    "section": "Estimation of (CFA-) Model Parameters",
    "text": "Estimation of (CFA-) Model Parameters\n\nModel parameters are estimated on the basis of the empirical variances, covariances, and means\nThis is done by minimizing the discrepancy between a sample variance-covariance matrix \\(S\\) and a model-implied variance-covariance matrix \\(\\Sigma(\\theta)\\)\nFit function for ML (without means): \\[F_{ML}=log|\\Sigma(\\theta)|+tr(S\\Sigma^{-1}(\\theta))-log|S|-p\\]\n\n\\(\\theta\\) = Model parameters\n\\(p\\) = number of parameters of observed variables\n\\(tr\\) = trace (spur)"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#model-ident-1",
    "href": "material/measurement-models/cfa-reveal.html#model-ident-1",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification I",
    "text": "Model identification I\nGoing from the known to the unknown (Kenny & Milan, 2012)\n\nKnown information: number of elements in the variance-covariance matrix and the mean vector\n\nIn general with \\(k\\) measured variables, there are…\n\nk(k+1)/2 knowns (without meanstructure)\nk(k+3)/2 knowns (with meanstructure)\n\n\nUnknown information: all parameters that need to be estimated\nCorrespondence of known and unknown information determines whether a model is\n\nunderidentified\njust-identified\noveridentified"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#model-ident-2",
    "href": "material/measurement-models/cfa-reveal.html#model-ident-2",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification II",
    "text": "Model identification II\n\nUnderidentified\n\n\\(10 = 2x + y\\)\nOne piece of information; no unique solution (i.e., infinite solutions) for x and y\n\njust-identified (also referred as a saturated model)\n\n\\(10 = 2x + y2 = x – y\\)\nTwo pieces of knowns; number of unknowns and knowns is equal\n\nOveridentified\n\n\\(10 = 2x +y2 = x – y5 = x + 2y\\)\nMore known than unknown information\n\n\nGoal of model testing: Overidentification (i.e., Falsifiability; degree of wrongness → Fit indices)"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#model-ident-3",
    "href": "material/measurement-models/cfa-reveal.html#model-ident-3",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification III",
    "text": "Model identification III\n\nCommon SEM (!) situation\n\nconstructs have multiple indicators,\nmost indicators load only on one construct (i.e., “simple structure”),\neach indicator has the same possible response scale (i.e., range)\n\nLittle et al. (2006) describe 3 methods\n\nReference-Group Method: fixing the latent mean and the latent variance\nMarker-Variable Method: fixing intercept to zero and loading of one indicator to 1\nEffects-Coding Method: indicator intercepts sum to 0 the set of loadings sum to average 1"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#model-ident-4",
    "href": "material/measurement-models/cfa-reveal.html#model-ident-4",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification IV",
    "text": "Model identification IV\nEffects-Coding Method: indicator intercepts sum to 0 the set of loadings sum to average 1\n\n\n\nloadings: \\[\\sum_{k=1}^{K} \\lambda_{k} = K\\]\nintercepts: \\[\\sum_{k=1}^{K} \\tau_{k} = 0\\]\n\n\n\n\n\n\n'\n# a measurement model with 3 items\n...\n# constraints\nlam1 == 3-lam2-lam3\nnu1 == 0-nu2-nu3\n'"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#model-ident-5",
    "href": "material/measurement-models/cfa-reveal.html#model-ident-5",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification V",
    "text": "Model identification V\n\nThis method uses the effects constraints to provide an optimal balance across the possible indicators to establish the scale for the estimated parameters, where the average intercept is zero, but no individual manifest intercept is fixed to be zero. Similarly, the loading parameters are estimated as an optimal balance around 1.0, but no individual loading is necessarily constrained to be 1.0. This method results in estimates of the latent variances that are the average of the indicators’ variances accounted for by the construct, and the latent means are estimated as optimally weighted averages of the set of indicator means for a given construct. In other words, the estimated latent variances and latent means reflect the observed metric of the indictors, optimally weighted by the degree to which each indicator represents the underlying latent construct. (Little et al., 2006, p. 63)"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#model-eval",
    "href": "material/measurement-models/cfa-reveal.html#model-eval",
    "title": "Confirmatory Factor Analyses",
    "section": "Model evaluation",
    "text": "Model evaluation\nCommon fit indices (Hu & Bentler, 1998, 1999) are …\n\n\\(\\chi^2\\) (Chi-square test statistic; cutoff: p &lt; .05)\nCFI (Comparative Fit Index; cutoff: &gt; .95)\nTLI (Tucker-Lewis Index; cutoff: &gt; .95)\nRMSEA (Root Mean Square Error of Approximation; cutoff: &lt; .06)\nSRMR (Standardized Root Mean Square Residual; cutoff: &lt; .08)\nSometimes: AIC (Akaike Information Criterion) & BIC (Bayesian Information Criterion); no cutoffs\n\n\n\nfor a critique see McNeish & Wolf (2021)"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#lavaan-mplus-syntax-overview",
    "href": "material/measurement-models/cfa-reveal.html#lavaan-mplus-syntax-overview",
    "title": "Confirmatory Factor Analyses",
    "section": "Lavaan & Mplus syntax overview",
    "text": "Lavaan & Mplus syntax overview\n\n\n\nFormula type\nLavaan Operator\nMplus statement\nMnemonic\n\n\n\n\nlatent variable definition\n=~\nby\nis measured by\n\n\nregression\n~\non\nis regressed on\n\n\n(residual) (co)variance\n~~\nwith\nis correlated with\n\n\nintercept\n~ 1\n[ ]\nintercept\n\n\n\n\n\n\n\n\n–\n:=\n=\ndefine functions\n\n\n–\n==\n==\nconstraints\n\n\n\n\n\nlavaan syntax see here\nMplus syntax see here"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#lavaan-cfa-1",
    "href": "material/measurement-models/cfa-reveal.html#lavaan-cfa-1",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation I",
    "text": "CFA: lavaan implementation I\n\n\n\n1CfaMod &lt;- '\n2eta1 =~ lam1*Y11 + lam2*Y21 + lam3*Y31\n\n3Y11 ~ nu1*1\nY21 ~ nu2*1\nY31 ~ nu3*1\n\n4Y11 ~~ theta1*Y11\nY21 ~~ theta2*Y21\nY31 ~~ theta3*Y31\n \n5eta1 ~ 0*1\n6eta1 ~~ 1*eta1 #psi\n\n7rel := (lam1+lam2+lam3)^2 /\n       ( (lam1+lam2+lam3)^2 +\n         theta1+theta2+theta3 )\n'\n\n\n\n1\n\nUse a string (i.e., ' ') to specify the model; provide a recognizable and meanigful name (here: CfaMod)\n\n2\n\nSpecifiy the measurement model using the is measured by operator: =~\n\n3\n\n(Optional) Specify the intercept of the item indicators using the intercept operatior: ~ 1\n\n4\n\n(Optional) Specify the residual variances of the item indicators using the is correlated with operator: ~~\n\n5\n\n(Optional) Specify the latent mean of the latent variable using the intercept operator: ~ 1\n\n6\n\n(Optional) Specify the variance of the latent variable using the is correlated with operator: ~~\n\n7\n\n(Optional) Use the model constraint option, to calculate the scale reliability (Raykov & Marcoulides, 2015)"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#lavaan-cfa-2",
    "href": "material/measurement-models/cfa-reveal.html#lavaan-cfa-2",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation II",
    "text": "CFA: lavaan implementation II\n\n\n1fitCfaMod &lt;- sem(\n2    model = CfaMod,\n3    data = wideLSdat,\n4    estimator = \"ML\",\n5    std.lv = TRUE\n    )\n\n\n\n1\n\nTo fit the model, you may want to use the sem (or cfa) function\n\n2\n\nIn the model argument, you need to provide the specified model as a string (here: CfaMod).\n\n3\n\nThe dataset is provided in the data argument.\n\n4\n\nChoose an estimator (default for continuous variable is ML); in realworld scenarios you may want to choose a robust variant (e.g., MLR).\n\n5\n\nTo fix the variance of the latent variabe to 1, we set the std.lv argument to TRUE."
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#lavaan-cfa-3-1",
    "href": "material/measurement-models/cfa-reveal.html#lavaan-cfa-3-1",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation III-I",
    "text": "CFA: lavaan implementation III-I\n\n\n1summary(\n    fitCfaMod,\n2    fit = TRUE,\n3    standardized = TRUE,\n4    rsq = TRUE\n    )\n\n\n\n1\n\nTo retrieve the results via the summary function (display only), you need to provide the object of the fitted model (here: fitCfaMod)\n\n2\n\nThe fit argument: Whether the typical fit indices should be printed.\n\n\n3\n\nThe standardized argument: Whether standardized solutions should be printed.\n\n4\n\nThe rsq argument: Whether \\(R^2\\) should be printed.\n\n\n\n\n\n\nThe results are printed on the next slide."
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#lavaan-cfa-3-2",
    "href": "material/measurement-models/cfa-reveal.html#lavaan-cfa-3-2",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation III-II",
    "text": "CFA: lavaan implementation III-II\n\n\nlavaan 0.6.15 ended normally after 17 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         9\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nModel Test Baseline Model:\n\n  Test statistic                               157.517\n  Degrees of freedom                                 3\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4604.807\n  Loglikelihood unrestricted model (H1)      -4604.807\n                                                      \n  Akaike (AIC)                                9227.615\n  Bayesian (BIC)                              9271.785\n  Sample-size adjusted Bayesian (SABIC)       9243.200\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  eta1 =~                                                               \n    Y11     (lam1)    0.563    0.059    9.460    0.000    0.563    0.488\n    Y21     (lam2)    0.576    0.061    9.500    0.000    0.576    0.494\n    Y31     (lam3)    0.558    0.059    9.470    0.000    0.558    0.490\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Y11      (nu1)   -0.048    0.036   -1.324    0.185   -0.048   -0.042\n   .Y21      (nu2)   -0.017    0.037   -0.461    0.644   -0.017   -0.015\n   .Y31      (nu3)   -0.011    0.036   -0.297    0.766   -0.011   -0.009\n    eta1              0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Y11     (tht1)    1.012    0.071   14.246    0.000    1.012    0.762\n   .Y21     (tht2)    1.029    0.073   13.995    0.000    1.029    0.756\n   .Y31     (tht3)    0.988    0.070   14.183    0.000    0.988    0.760\n    eta1              1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    Y11               0.238\n    Y21               0.244\n    Y31               0.240\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    rel               0.487    0.028   17.345    0.000    0.487    0.487"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#cfa-lavaan-implementation-iv",
    "href": "material/measurement-models/cfa-reveal.html#cfa-lavaan-implementation-iv",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation IV",
    "text": "CFA: lavaan implementation IV\nThere are other ways to inspect or extract the results of the fitted model object\n\nFit indices: fitMeasures function\nParameter: parameterEstimates function\nInspect/extraction function: lavInspect\n\nlavInspect(object, what = \"coef\")\nlavInspect(object, what = \"fit\")\nlavInspect(object, what = \"sampstat\")\nlavInspect(object, what = \"implied\")\n…"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#cfa-lavaan-implementation-parameterestimates",
    "href": "material/measurement-models/cfa-reveal.html#cfa-lavaan-implementation-parameterestimates",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation: parameterEstimates",
    "text": "CFA: lavaan implementation: parameterEstimates\nThe parameterEstimates is designed to extract the estimated parameters of the model.\n\ncfaParm &lt;- parameterEstimates(fitCfaMod,\n                              se = TRUE,\n                              zstat = TRUE,\n                              pvalue = TRUE,\n                              ci = TRUE,\n                              standardized = FALSE,\n                              rsquare = TRUE)\ncfaParm[cfaParm$label == \"rel\",\"rhs\"] &lt;- \"\" # just cosmetic\ncfaParm\n\n\n\n    lhs op  rhs  label    est    se      z pvalue ci.lower ci.upper\n1  eta1 =~  Y11   lam1  0.563 0.059  9.460  0.000    0.446    0.679\n2  eta1 =~  Y21   lam2  0.576 0.061  9.500  0.000    0.457    0.694\n3  eta1 =~  Y31   lam3  0.558 0.059  9.470  0.000    0.442    0.673\n4   Y11 ~1         nu1 -0.048 0.036 -1.324  0.185   -0.120    0.023\n5   Y21 ~1         nu2 -0.017 0.037 -0.461  0.644   -0.089    0.055\n6   Y31 ~1         nu3 -0.011 0.036 -0.297  0.766   -0.081    0.060\n7   Y11 ~~  Y11 theta1  1.012 0.071 14.246  0.000    0.873    1.152\n8   Y21 ~~  Y21 theta2  1.029 0.073 13.995  0.000    0.884    1.173\n9   Y31 ~~  Y31 theta3  0.988 0.070 14.183  0.000    0.851    1.124\n10 eta1 ~1              0.000 0.000     NA     NA    0.000    0.000\n11 eta1 ~~ eta1         1.000 0.000     NA     NA    1.000    1.000\n12  rel :=         rel  0.487 0.028 17.345  0.000    0.432    0.542\n13  Y11 r2  Y11         0.238    NA     NA     NA       NA       NA\n14  Y21 r2  Y21         0.244    NA     NA     NA       NA       NA\n15  Y31 r2  Y31         0.240    NA     NA     NA       NA       NA"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#cfa-lavaan-implementation-v-fit-indices",
    "href": "material/measurement-models/cfa-reveal.html#cfa-lavaan-implementation-v-fit-indices",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation V: Fit indices",
    "text": "CFA: lavaan implementation V: Fit indices\nThe fitMeasures is designed to extract the fit indices of the model.\n\ncfaFit &lt;- fitMeasures(fitCfaMod)\n#names(cfaFit) get names\ncfaFit[c(\"npar\", \"chisq\", \"df\", \"pvalue\", \"cfi\", \"rmsea\")]\n\n\n\n        npar        chisq           df       pvalue          cfi        rmsea \n9.000000e+00 1.776357e-12 0.000000e+00           NA 1.000000e+00 0.000000e+00"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#make-a-cfa-table",
    "href": "material/measurement-models/cfa-reveal.html#make-a-cfa-table",
    "title": "Confirmatory Factor Analyses",
    "section": "Make a CFA Table",
    "text": "Make a CFA Table\n\n\ncfaResults &lt;- cfaParm |&gt;\n  subset(select = c(\"label\", \"est\", \"se\", \"pvalue\")) |&gt;\n  subset(subset = grepl(\"lam\", label) |\n                  grepl(\"rel\", label)) |&gt;  \n  within(label &lt;- c(paste0(\"\\\\lambda_\", 1:3),\n                    \"Rel.\")) |&gt;\n  within(pvalue &lt;- sprintf(\"%.3f\", pvalue)) |&gt;  \n  print()\n\n\n        label   est    se pvalue\n1  \\\\lambda_1 0.563 0.059  0.000\n2  \\\\lambda_2 0.576 0.061  0.000\n3  \\\\lambda_3 0.558 0.059  0.000\n12       Rel. 0.487 0.028  0.000\n\ncfaFN &lt;- paste0(c(\"CFI = \", \"TLI = \", \"RMSEA = \", \"SRMR = \"),\n                  sprintf(\"%.3f\",cfaFit[c(\"cfi\", \"tli\", \"rmsea\", \"srmr\")]),\n                  collapse = \", \")\ncfaFN\n\n[1] \"CFI = 1.000, TLI = 1.000, RMSEA = 0.000, SRMR = 0.000\""
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#print-the-cfa-table",
    "href": "material/measurement-models/cfa-reveal.html#print-the-cfa-table",
    "title": "Confirmatory Factor Analyses",
    "section": "Print the CFA Table",
    "text": "Print the CFA Table\ncfaResults |&gt;\n  flextable() |&gt;\n  theme_apa() |&gt;\n  set_header_labels(\n    \"label\" = \"Parameter\",\n    \"est\" = \"Estimate\",\n    \"se\" = \"SE\",\n    \"pvalue\" = \"p\") |&gt;\n  compose(j = \"label\", i = 1:3,\n          value = as_paragraph((as_equation(label)))) |&gt; \n  add_footer_lines(\n    as_paragraph(as_i(\"Note. \"),\n                 cfaFN)\n      ) |&gt;\n  align(align = \"left\", part = \"footer\")\n\n\n\nTable 1: Results of Confirmatory Factor Analyses\n\n\nParameterEstimateSEpNA0.560.060.000NA0.580.060.000NA0.560.060.000Rel.0.490.030.000Note. CFI = 1.000, TLI = 1.000, RMSEA = 0.000, SRMR = 0.000\n\n\n\n\n\n\n\nCode\ninstall.packages(\"equatags\")"
  },
  {
    "objectID": "material/measurement-models/cfa-reveal.html#cfa-ref",
    "href": "material/measurement-models/cfa-reveal.html#cfa-ref",
    "title": "Confirmatory Factor Analyses",
    "section": "References",
    "text": "References\n\n\nBrown, T. A., & Moore, M. T. (2012). Confirmatory factor analysis. In R. H. Hoyle (Ed.), Handbook of structural equation modeling. Guilford Press.\n\n\nCampbell, D. T., & Fiske, D. W. (1959). Convergent and discriminant validation by the multitrait-multimethod matrix. Psychological Bulletin, 56(2), 81–105. https://doi.org/10.1037/h0046016\n\n\nHoyle, R. H. (Ed.). (2012). Handbook of structural equation modeling. Guilford Press.\n\n\nHu, L., & Bentler, P. M. (1998). Fit indices in covariance structure modeling: Sensitivity to underparameterized model misspecification. Psychological Methods, 3(4), 424–453. https://doi.org/10.1037//1082-989X.3.4.424\n\n\nHu, L., & Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives. Structural Equation Modeling: A Multidisciplinary Journal, 6(1), 1–55. https://doi.org/10.1080/10705519909540118\n\n\nKenny, D. A., & Milan, S. (2012). Identification: A non-technical discussion of a technical issue. In R. H. Hoyle (Ed.), Handbook of structural equation modeling. Guilford Press.\n\n\nLittle, T. D., Slegers, D. W., & Card, N. A. (2006). A non-arbitrary method of identifying and scaling latent bariables in SEM and MACS models. Structural Equation Modeling: A Multidisciplinary Journal, 13(1), 59–72. https://doi.org/10.1207/s15328007sem1301‗ 3\n\n\nMcNeish, D. (2017). Thanks Coefficient Alpha, We’ll Take It From Here. Psychological Methods. https://doi.org/10.1037/met0000144\n\n\nMcNeish, D., & Wolf, M. G. (2021). Dynamic fit index cutoffs for confirmatory factor analysis models. Psychological Methods. https://doi.org/10.1037/met0000425\n\n\nRaykov, T., & Marcoulides, G. A. (2015). Scale reliability evaluation under multiple assumption violations. Structural Equation Modeling: A Multidisciplinary Journal, 23(2), 302–313. https://doi.org/10.1080/10705511.2014.938597\n\n\nRevelle, W., & Zinbarg, R. E. (2009). Coefficients Alpha, Beta, Omega, and the glb: Comments on Sijtsma. Psychometrika, 74(1), 145–154. https://doi.org/10.1007/s11336-008-9102-z\n\n\nRosseel, Y., Jorgensen, T. D., & De Wilde, L. (2023). Lavaan: Latent variable analysis. https://lavaan.ugent.be\n\n\nSavalei, V., & Reise, S. P. (2019). Don’t forget the model in your model-based reliability coefficients: A reply to McNeish (2018). Collabra: Psychology, 5(1), 36. https://doi.org/10.1525/collabra.247\n\n\nSijtsma, K. (2009). On the Use, the Misuse, and the Very Limited Usefulness of Cronbach’s Alpha. Psychometrika, 74(1), 107–120. https://doi.org/10.1007/s11336-008-9101-0\n\n\n\n\n\nBack to website"
  },
  {
    "objectID": "material/measurement-models/cfa.html",
    "href": "material/measurement-models/cfa.html",
    "title": "Confirmatory Factor Analyses",
    "section": "",
    "text": "If you want to see the presentation in full screen go to Other Formats on the right. The presentation can be downloaded here.",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#revealjs-presentation",
    "href": "material/measurement-models/cfa.html#revealjs-presentation",
    "title": "Confirmatory Factor Analyses",
    "section": "",
    "text": "If you want to see the presentation in full screen go to Other Formats on the right. The presentation can be downloaded here.",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#preface-software",
    "href": "material/measurement-models/cfa.html#preface-software",
    "title": "Confirmatory Factor Analyses",
    "section": "Preface: Software",
    "text": "Preface: Software\n\nThe following packages are used:\n\n\ncfaPkg &lt;- c(\"lavaan\",\n            \"flextable\")\n\n\n\nInstall packages when not already installed:\n\n\nlapply(cfaPkg,\n       function(x)\n        if(!x %in% rownames(installed.packages())) {\n          install.packages(x) \n          }\n      )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\nlibrary(lavaan)\nlibrary(flextable)",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#preface-data",
    "href": "material/measurement-models/cfa.html#preface-data",
    "title": "Confirmatory Factor Analyses",
    "section": "Preface: Data",
    "text": "Preface: Data\nTo demonstrate, we use the first measurement time point of a simulated data set. The data simulation is described in the Example Data section. Alternatively, you can download the wideLSdat.RDS file here.\n\nwideLSdat &lt;- readRDS(\"../example-data/wideLSdat.RDS\")",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#confirmatory-factor-analysis-cfa-overview",
    "href": "material/measurement-models/cfa.html#confirmatory-factor-analysis-cfa-overview",
    "title": "Confirmatory Factor Analyses",
    "section": "Confirmatory Factor Analysis (CFA): Overview",
    "text": "Confirmatory Factor Analysis (CFA): Overview\n\nIntroduction & Purposes of CFA\nParameters & graphical visualization\nEstimation of parameters\nModel identification\nModel evaluation\nImplementation in the R package lavaan (Rosseel et al., 2023)",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#cfa-intro",
    "href": "material/measurement-models/cfa.html#cfa-intro",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: Introduction",
    "text": "CFA: Introduction\n\nConfirmatory factor analysis” (CFA) is a type of structural equation modeling that deals specifically with measurement models, that is, the relationships between observed measures or “indicators” (e.g., items, test scores, behavioral observation ratings) and latent variables or “factors. (Brown & Moore, 2012, p. 361)\n\nGoal: to establish the number and nature of factors (i.e., latent variables) that account for the variation and covariation among a set of indicators\n\nthe indicators (i.e., observed measures) are intercorrelated because they share a common cause (or with other words: are influenced by the same underlying construct)",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#purp-cfa",
    "href": "material/measurement-models/cfa.html#purp-cfa",
    "title": "Confirmatory Factor Analyses",
    "section": "Purposes of CFA",
    "text": "Purposes of CFA\n\nPsychometric evaluation (e.g., Reliability; for scale reliability see here)\nDetection of method effects (e.g., covariation among indicators, after the latent variable was partialed out)\nConstruct validation (e.g., convergent and discriminant validity); see also multi-trait-multi-method approaches (Campbell & Fiske, 1959)\nEvaluation of measurement invariance (see here)\nScale development",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#cfa-param",
    "href": "material/measurement-models/cfa.html#cfa-param",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA parameters & graphical visualization",
    "text": "CFA parameters & graphical visualization\n\n\n\n\nVariance of the latent variable: \\(\\Psi\\)\nIntercepts: \\(\\nu\\)\nFactor loadings: \\(\\lambda\\)\nError variances: \\(\\theta\\)\n\n\n\n\n\n\\[Y_i = \\nu_i + \\lambda_i\\eta + \\theta_i\\]\n\n\n\n\n\\(\\Psi\\): Psi\n\\(\\nu\\): Nu\n\\(\\lambda\\): Lambda\n\\(\\theta\\): Theta",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#scale-rel",
    "href": "material/measurement-models/cfa.html#scale-rel",
    "title": "Confirmatory Factor Analyses",
    "section": "Scale Reliability",
    "text": "Scale Reliability\n\nThere is some debate about Cronbach’s Alpha Reliability Coefficient (Revelle & Zinbarg, 2009; Sijtsma, 2009)\n\n\nEven though the pages of Psychometrika have been filled over the years with critiques and cautions about coefficient α and have seen elegant solutions for more appropriate estimates, few of these suggested coefficient are used.” (p.2)\n\n\nAn alternative: Scale reliability\n\n[…] “reliability“ as the ratio of true variance to observed variance […]” (Raykov & Marcoulides, 2015)\n\nScale reliability: \\(\\rho = \\frac{(\\lambda_1+\\dots+\\lambda_k)^2}{(\\lambda_1+\\dots+\\lambda_k)^2+\\theta_1+\\dots+\\theta_k}\\)\n\n\n\nsee also McNeish (2017); Savalei & Reise (2019)",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#cfa-param-est",
    "href": "material/measurement-models/cfa.html#cfa-param-est",
    "title": "Confirmatory Factor Analyses",
    "section": "Estimation of (CFA-) Model Parameters",
    "text": "Estimation of (CFA-) Model Parameters\n\nModel parameters are estimated on the basis of the empirical variances, covariances, and means\nThis is done by minimizing the discrepancy between a sample variance-covariance matrix \\(S\\) and a model-implied variance-covariance matrix \\(\\Sigma(\\theta)\\)\nFit function for ML (without means): \\[F_{ML}=log|\\Sigma(\\theta)|+tr(S\\Sigma^{-1}(\\theta))-log|S|-p\\]\n\n\\(\\theta\\) = Model parameters\n\\(p\\) = number of parameters of observed variables\n\\(tr\\) = trace (spur)",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#model-ident-1",
    "href": "material/measurement-models/cfa.html#model-ident-1",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification I",
    "text": "Model identification I\nGoing from the known to the unknown (Kenny & Milan, 2012)\n\nKnown information: number of elements in the variance-covariance matrix and the mean vector\n\nIn general with \\(k\\) measured variables, there are…\n\nk(k+1)/2 knowns (without meanstructure)\nk(k+3)/2 knowns (with meanstructure)\n\n\nUnknown information: all parameters that need to be estimated\nCorrespondence of known and unknown information determines whether a model is\n\nunderidentified\njust-identified\noveridentified",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#model-ident-2",
    "href": "material/measurement-models/cfa.html#model-ident-2",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification II",
    "text": "Model identification II\n\nUnderidentified\n\n\\(10 = 2x + y\\)\nOne piece of information; no unique solution (i.e., infinite solutions) for x and y\n\njust-identified (also referred as a saturated model)\n\n\\(10 = 2x + y2 = x – y\\)\nTwo pieces of knowns; number of unknowns and knowns is equal\n\nOveridentified\n\n\\(10 = 2x +y2 = x – y5 = x + 2y\\)\nMore known than unknown information\n\n\nGoal of model testing: Overidentification (i.e., Falsifiability; degree of wrongness → Fit indices)",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#model-ident-3",
    "href": "material/measurement-models/cfa.html#model-ident-3",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification III",
    "text": "Model identification III\n\nCommon SEM (!) situation\n\nconstructs have multiple indicators,\nmost indicators load only on one construct (i.e., “simple structure”),\neach indicator has the same possible response scale (i.e., range)\n\nLittle et al. (2006) describe 3 methods\n\nReference-Group Method: fixing the latent mean and the latent variance\nMarker-Variable Method: fixing intercept to zero and loading of one indicator to 1\nEffects-Coding Method: indicator intercepts sum to 0 the set of loadings sum to average 1",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#model-ident-4",
    "href": "material/measurement-models/cfa.html#model-ident-4",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification IV",
    "text": "Model identification IV\nEffects-Coding Method: indicator intercepts sum to 0 the set of loadings sum to average 1\n\n\n\nloadings: \\[\\sum_{k=1}^{K} \\lambda_{k} = K\\]\nintercepts: \\[\\sum_{k=1}^{K} \\tau_{k} = 0\\]\n\n\n\n\n\n\n'\n# a measurement model with 3 items\n...\n# constraints\nlam1 == 3-lam2-lam3\nnu1 == 0-nu2-nu3\n'",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#model-ident-5",
    "href": "material/measurement-models/cfa.html#model-ident-5",
    "title": "Confirmatory Factor Analyses",
    "section": "Model identification V",
    "text": "Model identification V\n\nThis method uses the effects constraints to provide an optimal balance across the possible indicators to establish the scale for the estimated parameters, where the average intercept is zero, but no individual manifest intercept is fixed to be zero. Similarly, the loading parameters are estimated as an optimal balance around 1.0, but no individual loading is necessarily constrained to be 1.0. This method results in estimates of the latent variances that are the average of the indicators’ variances accounted for by the construct, and the latent means are estimated as optimally weighted averages of the set of indicator means for a given construct. In other words, the estimated latent variances and latent means reflect the observed metric of the indictors, optimally weighted by the degree to which each indicator represents the underlying latent construct. (Little et al., 2006, p. 63)",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#model-eval",
    "href": "material/measurement-models/cfa.html#model-eval",
    "title": "Confirmatory Factor Analyses",
    "section": "Model evaluation",
    "text": "Model evaluation\nCommon fit indices (Hu & Bentler, 1998, 1999) are …\n\n\\(\\chi^2\\) (Chi-square test statistic; cutoff: p &lt; .05)\nCFI (Comparative Fit Index; cutoff: &gt; .95)\nTLI (Tucker-Lewis Index; cutoff: &gt; .95)\nRMSEA (Root Mean Square Error of Approximation; cutoff: &lt; .06)\nSRMR (Standardized Root Mean Square Residual; cutoff: &lt; .08)\nSometimes: AIC (Akaike Information Criterion) & BIC (Bayesian Information Criterion); no cutoffs\n\n\n\nfor a critique see McNeish & Wolf (2021)",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#lavaan-mplus-syntax-overview",
    "href": "material/measurement-models/cfa.html#lavaan-mplus-syntax-overview",
    "title": "Confirmatory Factor Analyses",
    "section": "Lavaan & Mplus syntax overview",
    "text": "Lavaan & Mplus syntax overview\n\n\n\nFormula type\nLavaan Operator\nMplus statement\nMnemonic\n\n\n\n\nlatent variable definition\n=~\nby\nis measured by\n\n\nregression\n~\non\nis regressed on\n\n\n(residual) (co)variance\n~~\nwith\nis correlated with\n\n\nintercept\n~ 1\n[ ]\nintercept\n\n\n\n\n\n\n\n\n–\n:=\n=\ndefine functions\n\n\n–\n==\n==\nconstraints\n\n\n\n\n\nlavaan syntax see here\nMplus syntax see here",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#lavaan-cfa-1",
    "href": "material/measurement-models/cfa.html#lavaan-cfa-1",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation I",
    "text": "CFA: lavaan implementation I\n\n\n1CfaMod &lt;- '\n2eta1 =~ lam1*Y11 + lam2*Y21 + lam3*Y31\n\n3Y11 ~ nu1*1\nY21 ~ nu2*1\nY31 ~ nu3*1\n\n4Y11 ~~ theta1*Y11\nY21 ~~ theta2*Y21\nY31 ~~ theta3*Y31\n \n5eta1 ~ 0*1\n6eta1 ~~ 1*eta1 #psi\n\n7rel := (lam1+lam2+lam3)^2 /\n       ( (lam1+lam2+lam3)^2 +\n         theta1+theta2+theta3 )\n'\n\n\n1\n\nUse a string (i.e., ' ') to specify the model; provide a recognizable and meanigful name (here: CfaMod)\n\n2\n\nSpecifiy the measurement model using the is measured by operator: =~\n\n3\n\n(Optional) Specify the intercept of the item indicators using the intercept operatior: ~ 1\n\n4\n\n(Optional) Specify the residual variances of the item indicators using the is correlated with operator: ~~\n\n5\n\n(Optional) Specify the latent mean of the latent variable using the intercept operator: ~ 1\n\n6\n\n(Optional) Specify the variance of the latent variable using the is correlated with operator: ~~\n\n7\n\n(Optional) Use the model constraint option, to calculate the scale reliability (Raykov & Marcoulides, 2015)",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#lavaan-cfa-2",
    "href": "material/measurement-models/cfa.html#lavaan-cfa-2",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation II",
    "text": "CFA: lavaan implementation II\n\n1fitCfaMod &lt;- sem(\n2    model = CfaMod,\n3    data = wideLSdat,\n4    estimator = \"ML\",\n5    std.lv = TRUE\n    )\n\n\n1\n\nTo fit the model, you may want to use the sem (or cfa) function\n\n2\n\nIn the model argument, you need to provide the specified model as a string (here: CfaMod).\n\n3\n\nThe dataset is provided in the data argument.\n\n4\n\nChoose an estimator (default for continuous variable is ML); in realworld scenarios you may want to choose a robust variant (e.g., MLR).\n\n5\n\nTo fix the variance of the latent variabe to 1, we set the std.lv argument to TRUE.",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#lavaan-cfa-3-1",
    "href": "material/measurement-models/cfa.html#lavaan-cfa-3-1",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation III-I",
    "text": "CFA: lavaan implementation III-I\n\n1summary(\n    fitCfaMod,\n2    fit = TRUE,\n3    standardized = TRUE,\n4    rsq = TRUE\n    )\n\n\n1\n\nTo retrieve the results via the summary function (display only), you need to provide the object of the fitted model (here: fitCfaMod)\n\n2\n\nThe fit argument: Whether the typical fit indices should be printed.\n\n\n3\n\nThe standardized argument: Whether standardized solutions should be printed.\n\n4\n\nThe rsq argument: Whether \\(R^2\\) should be printed.\n\n\n\n\n\nThe results are printed on the next slide.",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#lavaan-cfa-3-2",
    "href": "material/measurement-models/cfa.html#lavaan-cfa-3-2",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation III-II",
    "text": "CFA: lavaan implementation III-II\n\n\nlavaan 0.6.15 ended normally after 17 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         9\n\n  Number of observations                          1000\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nModel Test Baseline Model:\n\n  Test statistic                               157.517\n  Degrees of freedom                                 3\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4604.807\n  Loglikelihood unrestricted model (H1)      -4604.807\n                                                      \n  Akaike (AIC)                                9227.615\n  Bayesian (BIC)                              9271.785\n  Sample-size adjusted Bayesian (SABIC)       9243.200\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  eta1 =~                                                               \n    Y11     (lam1)    0.563    0.059    9.460    0.000    0.563    0.488\n    Y21     (lam2)    0.576    0.061    9.500    0.000    0.576    0.494\n    Y31     (lam3)    0.558    0.059    9.470    0.000    0.558    0.490\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Y11      (nu1)   -0.048    0.036   -1.324    0.185   -0.048   -0.042\n   .Y21      (nu2)   -0.017    0.037   -0.461    0.644   -0.017   -0.015\n   .Y31      (nu3)   -0.011    0.036   -0.297    0.766   -0.011   -0.009\n    eta1              0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .Y11     (tht1)    1.012    0.071   14.246    0.000    1.012    0.762\n   .Y21     (tht2)    1.029    0.073   13.995    0.000    1.029    0.756\n   .Y31     (tht3)    0.988    0.070   14.183    0.000    0.988    0.760\n    eta1              1.000                               1.000    1.000\n\nR-Square:\n                   Estimate\n    Y11               0.238\n    Y21               0.244\n    Y31               0.240\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    rel               0.487    0.028   17.345    0.000    0.487    0.487",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#cfa-lavaan-implementation-iv",
    "href": "material/measurement-models/cfa.html#cfa-lavaan-implementation-iv",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation IV",
    "text": "CFA: lavaan implementation IV\nThere are other ways to inspect or extract the results of the fitted model object\n\nFit indices: fitMeasures function\nParameter: parameterEstimates function\nInspect/extraction function: lavInspect\n\nlavInspect(object, what = \"coef\")\nlavInspect(object, what = \"fit\")\nlavInspect(object, what = \"sampstat\")\nlavInspect(object, what = \"implied\")\n…",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#cfa-lavaan-implementation-parameterestimates",
    "href": "material/measurement-models/cfa.html#cfa-lavaan-implementation-parameterestimates",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation: parameterEstimates",
    "text": "CFA: lavaan implementation: parameterEstimates\nThe parameterEstimates is designed to extract the estimated parameters of the model.\n\ncfaParm &lt;- parameterEstimates(fitCfaMod,\n                              se = TRUE,\n                              zstat = TRUE,\n                              pvalue = TRUE,\n                              ci = TRUE,\n                              standardized = FALSE,\n                              rsquare = TRUE)\ncfaParm[cfaParm$label == \"rel\",\"rhs\"] &lt;- \"\" # just cosmetic\ncfaParm\n\n    lhs op  rhs  label    est    se      z pvalue ci.lower ci.upper\n1  eta1 =~  Y11   lam1  0.563 0.059  9.460  0.000    0.446    0.679\n2  eta1 =~  Y21   lam2  0.576 0.061  9.500  0.000    0.457    0.694\n3  eta1 =~  Y31   lam3  0.558 0.059  9.470  0.000    0.442    0.673\n4   Y11 ~1         nu1 -0.048 0.036 -1.324  0.185   -0.120    0.023\n5   Y21 ~1         nu2 -0.017 0.037 -0.461  0.644   -0.089    0.055\n6   Y31 ~1         nu3 -0.011 0.036 -0.297  0.766   -0.081    0.060\n7   Y11 ~~  Y11 theta1  1.012 0.071 14.246  0.000    0.873    1.152\n8   Y21 ~~  Y21 theta2  1.029 0.073 13.995  0.000    0.884    1.173\n9   Y31 ~~  Y31 theta3  0.988 0.070 14.183  0.000    0.851    1.124\n10 eta1 ~1              0.000 0.000     NA     NA    0.000    0.000\n11 eta1 ~~ eta1         1.000 0.000     NA     NA    1.000    1.000\n12  rel :=         rel  0.487 0.028 17.345  0.000    0.432    0.542\n13  Y11 r2  Y11         0.238    NA     NA     NA       NA       NA\n14  Y21 r2  Y21         0.244    NA     NA     NA       NA       NA\n15  Y31 r2  Y31         0.240    NA     NA     NA       NA       NA",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#cfa-lavaan-implementation-v-fit-indices",
    "href": "material/measurement-models/cfa.html#cfa-lavaan-implementation-v-fit-indices",
    "title": "Confirmatory Factor Analyses",
    "section": "CFA: lavaan implementation V: Fit indices",
    "text": "CFA: lavaan implementation V: Fit indices\nThe fitMeasures is designed to extract the fit indices of the model.\n\ncfaFit &lt;- fitMeasures(fitCfaMod)\n#names(cfaFit) get names\ncfaFit[c(\"npar\", \"chisq\", \"df\", \"pvalue\", \"cfi\", \"rmsea\")]\n\n        npar        chisq           df       pvalue          cfi        rmsea \n9.000000e+00 1.776357e-12 0.000000e+00           NA 1.000000e+00 0.000000e+00",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#make-a-cfa-table",
    "href": "material/measurement-models/cfa.html#make-a-cfa-table",
    "title": "Confirmatory Factor Analyses",
    "section": "Make a CFA Table",
    "text": "Make a CFA Table\n\ncfaResults &lt;- cfaParm |&gt;\n  subset(select = c(\"label\", \"est\", \"se\", \"pvalue\")) |&gt;\n  subset(subset = grepl(\"lam\", label) |\n                  grepl(\"rel\", label)) |&gt;  \n  within(label &lt;- c(paste0(\"\\\\lambda_\", 1:3),\n                    \"Rel.\")) |&gt;\n  within(pvalue &lt;- sprintf(\"%.3f\", pvalue)) |&gt;  \n  print()\n\n        label   est    se pvalue\n1  \\\\lambda_1 0.563 0.059  0.000\n2  \\\\lambda_2 0.576 0.061  0.000\n3  \\\\lambda_3 0.558 0.059  0.000\n12       Rel. 0.487 0.028  0.000\n\ncfaFN &lt;- paste0(c(\"CFI = \", \"TLI = \", \"RMSEA = \", \"SRMR = \"),\n                  sprintf(\"%.3f\",cfaFit[c(\"cfi\", \"tli\", \"rmsea\", \"srmr\")]),\n                  collapse = \", \")\ncfaFN\n\n[1] \"CFI = 1.000, TLI = 1.000, RMSEA = 0.000, SRMR = 0.000\"",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#print-the-cfa-table",
    "href": "material/measurement-models/cfa.html#print-the-cfa-table",
    "title": "Confirmatory Factor Analyses",
    "section": "Print the CFA Table",
    "text": "Print the CFA Table\ncfaResults |&gt;\n  flextable() |&gt;\n  theme_apa() |&gt;\n  set_header_labels(\n    \"label\" = \"Parameter\",\n    \"est\" = \"Estimate\",\n    \"se\" = \"SE\",\n    \"pvalue\" = \"p\") |&gt;\n  compose(j = \"label\", i = 1:3,\n          value = as_paragraph((as_equation(label)))) |&gt; \n  add_footer_lines(\n    as_paragraph(as_i(\"Note. \"),\n                 cfaFN)\n      ) |&gt;\n  align(align = \"left\", part = \"footer\")\n\n\n\nTable 1: Results of Confirmatory Factor Analyses\n\n\nParameterEstimateSEpNA0.560.060.000NA0.580.060.000NA0.560.060.000Rel.0.490.030.000Note. CFI = 1.000, TLI = 1.000, RMSEA = 0.000, SRMR = 0.000\n\n\n\n\n\n\n\nCode\ninstall.packages(\"equatags\")",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/measurement-models/cfa.html#cfa-ref",
    "href": "material/measurement-models/cfa.html#cfa-ref",
    "title": "Confirmatory Factor Analyses",
    "section": "References",
    "text": "References\n\n\nBrown, T. A., & Moore, M. T. (2012). Confirmatory factor analysis. In R. H. Hoyle (Ed.), Handbook of structural equation modeling. Guilford Press.\n\n\nCampbell, D. T., & Fiske, D. W. (1959). Convergent and discriminant validation by the multitrait-multimethod matrix. Psychological Bulletin, 56(2), 81–105. https://doi.org/10.1037/h0046016\n\n\nHoyle, R. H. (Ed.). (2012). Handbook of structural equation modeling. Guilford Press.\n\n\nHu, L., & Bentler, P. M. (1998). Fit indices in covariance structure modeling: Sensitivity to underparameterized model misspecification. Psychological Methods, 3(4), 424–453. https://doi.org/10.1037//1082-989X.3.4.424\n\n\nHu, L., & Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives. Structural Equation Modeling: A Multidisciplinary Journal, 6(1), 1–55. https://doi.org/10.1080/10705519909540118\n\n\nKenny, D. A., & Milan, S. (2012). Identification: A non-technical discussion of a technical issue. In R. H. Hoyle (Ed.), Handbook of structural equation modeling. Guilford Press.\n\n\nLittle, T. D., Slegers, D. W., & Card, N. A. (2006). A non-arbitrary method of identifying and scaling latent bariables in SEM and MACS models. Structural Equation Modeling: A Multidisciplinary Journal, 13(1), 59–72. https://doi.org/10.1207/s15328007sem1301‗ 3\n\n\nMcNeish, D. (2017). Thanks Coefficient Alpha, We’ll Take It From Here. Psychological Methods. https://doi.org/10.1037/met0000144\n\n\nMcNeish, D., & Wolf, M. G. (2021). Dynamic fit index cutoffs for confirmatory factor analysis models. Psychological Methods. https://doi.org/10.1037/met0000425\n\n\nRaykov, T., & Marcoulides, G. A. (2015). Scale reliability evaluation under multiple assumption violations. Structural Equation Modeling: A Multidisciplinary Journal, 23(2), 302–313. https://doi.org/10.1080/10705511.2014.938597\n\n\nRevelle, W., & Zinbarg, R. E. (2009). Coefficients Alpha, Beta, Omega, and the glb: Comments on Sijtsma. Psychometrika, 74(1), 145–154. https://doi.org/10.1007/s11336-008-9102-z\n\n\nRosseel, Y., Jorgensen, T. D., & De Wilde, L. (2023). Lavaan: Latent variable analysis. https://lavaan.ugent.be\n\n\nSavalei, V., & Reise, S. P. (2019). Don’t forget the model in your model-based reliability coefficients: A reply to McNeish (2018). Collabra: Psychology, 5(1), 36. https://doi.org/10.1525/collabra.247\n\n\nSijtsma, K. (2009). On the Use, the Misuse, and the Very Limited Usefulness of Cronbach’s Alpha. Psychometrika, 74(1), 107–120. https://doi.org/10.1007/s11336-008-9101-0",
    "crumbs": [
      "Compendium",
      "Measurement Models",
      "Confirmatory Factor Analyses"
    ]
  },
  {
    "objectID": "material/mlm/random-anova-reveal.html#preface-software-i",
    "href": "material/mlm/random-anova-reveal.html#preface-software-i",
    "title": "One-Way ANOVA with Random Effects",
    "section": "Preface: Software I",
    "text": "Preface: Software I\n\nThe following packages are used:\n\n\n\nmlmRaPkg &lt;- c(\"merTools\",\n              \"lme4\",\n              \"flextable\",\n              \"ggplot2\")\n\n\n\n\n\n\nInstall packages when not already installed:\n\n\nlapply(mlmRaPkg,\n        function(x) \n          if(!x %in% rownames(installed.packages())) {\n            install.packages(x)\n            }\n      )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\n\nlibrary(lme4)\nlibrary(ggplot2)\nlibrary(flextable)"
  },
  {
    "objectID": "material/mlm/random-anova-reveal.html#preface-software-ii",
    "href": "material/mlm/random-anova-reveal.html#preface-software-ii",
    "title": "One-Way ANOVA with Random Effects",
    "section": "Preface: Software II",
    "text": "Preface: Software II\nPrint list of packages and cite them via Pandoc citation.\n\nShow/hide fenced code```{r}\n#| label: write-mlmPkg\n#| code-fold: true\n#| code-summary: \"Show/hide fenced code\"\n#| output-location: fragment\n#| output: asis\n\nfor (i in 1:length(mlmRaPkg)) {\n  \n  cat(paste0(i, \". \",\n             mlmRaPkg[i],\n             \" [\", \"v\", utils::packageVersion(mlmRaPkg[i]),\", @R-\", mlmRaPkg[i],\n             \"]\\n\"))\n}\n```\n\n\n\n\nmerTools (v0.6.1, Knowles & Frederick, 2023)\n\nlme4 (v1.1.34, Bates et al., 2023)\n\nflextable (v0.9.2, Gohel & Skintzos, 2024)\n\nggplot2 (v3.4.3, Wickham et al., 2023)"
  },
  {
    "objectID": "material/mlm/random-anova-reveal.html#preface-dataset",
    "href": "material/mlm/random-anova-reveal.html#preface-dataset",
    "title": "One-Way ANOVA with Random Effects",
    "section": "Preface: Dataset",
    "text": "Preface: Dataset\nRecall, we use the HSB dataset from the merTools package (Knowles & Frederick, 2023). For a more detailed description see :\n\n\ndat &lt;- merTools::hsb\nhead(dat, 6)\n\n\n\n  schid minority female    ses mathach size schtype meanses\n1  1224        0      1 -1.528   5.876  842       0  -0.428\n2  1224        0      1 -0.588  19.708  842       0  -0.428\n3  1224        0      0 -0.528  20.349  842       0  -0.428\n4  1224        0      0 -0.668   8.781  842       0  -0.428\n5  1224        0      0 -0.158  17.898  842       0  -0.428\n6  1224        0      0  0.022   4.583  842       0  -0.428"
  },
  {
    "objectID": "material/mlm/random-anova-reveal.html#one-way-anova-with-random-effects-i",
    "href": "material/mlm/random-anova-reveal.html#one-way-anova-with-random-effects-i",
    "title": "One-Way ANOVA with Random Effects",
    "section": "One-Way ANOVA with Random Effects I",
    "text": "One-Way ANOVA with Random Effects I\nThe one-Way ANOVA with Random Effects Model is a model without predictors (often called the empty model [ger: “Nullmodell”]); the variance of a variable is decomposed into level 1 (within-) and level 2 (between-) variance components and it is the first step in (every?) multilevel analysis.\n\n\n\nLevel-specific equations\n\\[\n\\text{Level 1: } Y_{ij} = \\beta_{0j} + r_{ij}\n\\qquad(1)\\]\n\\[\n\\text{Level 2: } \\beta_{0j} = \\gamma_{00} + u_{0j}\n\\qquad(2)\\]\nCombined equation\nSubstituting Equation 2 into Equation 1 yields the combined model equation (see Equation 3):\n\\[\nY_{ij} = \\gamma_{00} + u_{0j} + r_{ij}\n\\qquad(3)\\]"
  },
  {
    "objectID": "material/mlm/random-anova-reveal.html#one-way-anova-with-random-effects-ii",
    "href": "material/mlm/random-anova-reveal.html#one-way-anova-with-random-effects-ii",
    "title": "One-Way ANOVA with Random Effects",
    "section": "One-Way ANOVA with Random Effects II",
    "text": "One-Way ANOVA with Random Effects II\n\n\n\nVariance decomposition of \\(Y_{ij}\\)\n\\[\n\\begin{aligned}\nVAR(Y_{ij}) &= VAR(u_{0j}) + VAR(r_{ij}) \\\\\n            &= \\tau_{00} + \\sigma^2\n\\end{aligned}\n\\qquad(4)\\]\n\nIntraclass correlation coefficient (ICC):\n\\[\nICC(\\rho) = \\frac{ \\tau_{00} } {\\tau_{00} + \\sigma^2 }\n\\qquad(5)\\]\n→ It measures the proportion of the variance in the outcome that is between level 2 units; if \\(ICC = 0\\) there is no need for multilevel modeling!"
  },
  {
    "objectID": "material/mlm/random-anova-reveal.html#one-way-anova-with-random-effects-in-r-i",
    "href": "material/mlm/random-anova-reveal.html#one-way-anova-with-random-effects-in-r-i",
    "title": "One-Way ANOVA with Random Effects",
    "section": "One-Way ANOVA with Random Effects in R I",
    "text": "One-Way ANOVA with Random Effects in R I\n\n\nPrint\nTable\nParameter Extraction\n\n\n\n\n\nraMod &lt;- dat |&gt;\n  lmer(formula = mathach ~ 1 + \n                  (1 | schid),\n       REML = FALSE)\n\nsummary(raMod)\n\n\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: mathach ~ 1 + (1 | schid)\n   Data: dat\n\n     AIC      BIC   logLik deviance df.resid \n 47121.8  47142.4 -23557.9  47115.8     7182 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-3.06262 -0.75365  0.02676  0.76070  2.74184 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n schid    (Intercept)  8.553   2.925   \n Residual             39.148   6.257   \nNumber of obs: 7185, groups:  schid, 160\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  12.6371     0.2436   51.87\n\n\n\n\n\n\n\ndat |&gt;\n  lmer(formula = mathach ~ 1 + \n        (1 | schid),\n       REML = FALSE) |&gt;\n  as_flextable()\n\n\n\n\nTable 1: Random ANOVA Table generated by the flextable package (Gohel & Skintzos, 2024)\n\n\n\n\n\n\ngroup\n\nEstimate\nStandard Error\n\nstatistic\n\n\nFixed effects\n\n\n(Intercept)\n12.637\n0.244\n\n51.873\n\nRandom effects\n\nschid\nsd__(Intercept)\n2.925\n\n\n\n\n\nResidual\nsd__Observation\n6.257\n\n\n\n\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\nsquare root of the estimated residual variance: 6.3\ndata's log-likelihood under the model: -23,557.9\nAkaike Information Criterion: 47,121.8\nBayesian Information Criterion: 47,142.4\n\n\n\n\n\n\n\n\n\n\n\n\n\nraFixedEff &lt;- summary(raMod) |&gt;\n  coefficients()\n\nraFixedEff\n\n\n\n            Estimate Std. Error  t value\n(Intercept) 12.63707  0.2436171 51.87266\n\n\n\n\n\nraRandomEff &lt;- raMod |&gt;\n  VarCorr() |&gt;\n  as.data.frame() |&gt;\n  subset(select = \"vcov\")\n  \nraRandomEff\n\n\n\n       vcov\n1  8.553464\n2 39.148400"
  },
  {
    "objectID": "material/mlm/random-anova-reveal.html#parameters",
    "href": "material/mlm/random-anova-reveal.html#parameters",
    "title": "One-Way ANOVA with Random Effects",
    "section": "Parameters",
    "text": "Parameters\nRecall the combined equation of the model (Equation 3): \\(Y_{ij} = \\gamma_{00} + u_{0j} + r_{ij}\\)\nFixed effects:\n\\(\\gamma_{00}\\) = 12.637\nRandom effects:\n\\(VAR(u_{0j}) = \\tau_{00}\\) = 8.553\n\\(VAR(r_{ij}) = \\sigma^2\\) = 39.148"
  },
  {
    "objectID": "material/mlm/random-anova-reveal.html#tbc",
    "href": "material/mlm/random-anova-reveal.html#tbc",
    "title": "One-Way ANOVA with Random Effects",
    "section": "TBC …",
    "text": "TBC …"
  },
  {
    "objectID": "material/mlm/random-anova-reveal.html#mlm-ra-ref",
    "href": "material/mlm/random-anova-reveal.html#mlm-ra-ref",
    "title": "One-Way ANOVA with Random Effects",
    "section": "References",
    "text": "References\n\n\nBates, D., Maechler, M., Bolker, B., & Walker, S. (2023). lme4: Linear mixed-effects models using eigen and S4. https://github.com/lme4/lme4/\n\n\nGohel, D., & Skintzos, P. (2024). Flextable: Functions for tabular reporting. https://ardata-fr.github.io/flextable-book/\n\n\nKnowles, J. E., & Frederick, C. (2023). merTools: Tools for analyzing mixed effect regression models. https://CRAN.R-project.org/package=merTools\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org\n\n\n\n\n\n[Back to website]"
  },
  {
    "objectID": "material/mlm/random-anova.html",
    "href": "material/mlm/random-anova.html",
    "title": "One-Way ANOVA with Random Effects",
    "section": "",
    "text": "If you want to see the presentation in full screen go to Other Formats on the right."
  },
  {
    "objectID": "material/mlm/random-anova.html#revealjs-presentation",
    "href": "material/mlm/random-anova.html#revealjs-presentation",
    "title": "One-Way ANOVA with Random Effects",
    "section": "",
    "text": "If you want to see the presentation in full screen go to Other Formats on the right."
  },
  {
    "objectID": "material/mlm/random-anova.html#preface-software-i",
    "href": "material/mlm/random-anova.html#preface-software-i",
    "title": "One-Way ANOVA with Random Effects",
    "section": "Preface: Software I",
    "text": "Preface: Software I\n\nThe following packages are used:\n\n\nmlmRaPkg &lt;- c(\"merTools\",\n              \"lme4\",\n              \"flextable\",\n              \"ggplot2\")\n\n\n\nInstall packages when not already installed:\n\n\nlapply(mlmRaPkg,\n        function(x) \n          if(!x %in% rownames(installed.packages())) {\n            install.packages(x)\n            }\n      )\n\n\n\n\nLoad (a subset of) the required package(s) into the R session.\n\n\nlibrary(lme4)\nlibrary(ggplot2)\nlibrary(flextable)"
  },
  {
    "objectID": "material/mlm/random-anova.html#preface-software-ii",
    "href": "material/mlm/random-anova.html#preface-software-ii",
    "title": "One-Way ANOVA with Random Effects",
    "section": "Preface: Software II",
    "text": "Preface: Software II\nPrint list of packages and cite them via Pandoc citation.\n\nShow/hide fenced code```{r}\n#| label: write-mlmPkg\n#| code-fold: true\n#| code-summary: \"Show/hide fenced code\"\n#| output-location: fragment\n#| output: asis\n\nfor (i in 1:length(mlmRaPkg)) {\n  \n  cat(paste0(i, \". \",\n             mlmRaPkg[i],\n             \" [\", \"v\", utils::packageVersion(mlmRaPkg[i]),\", @R-\", mlmRaPkg[i],\n             \"]\\n\"))\n}\n```\n\nmerTools (v0.6.1, Knowles & Frederick, 2023)\n\nlme4 (v1.1.34, Bates et al., 2023)\n\nflextable (v0.9.2, Gohel & Skintzos, 2024)\n\nggplot2 (v3.4.3, Wickham et al., 2023)"
  },
  {
    "objectID": "material/mlm/random-anova.html#preface-dataset",
    "href": "material/mlm/random-anova.html#preface-dataset",
    "title": "One-Way ANOVA with Random Effects",
    "section": "Preface: Dataset",
    "text": "Preface: Dataset\nRecall, we use the HSB dataset from the merTools package (Knowles & Frederick, 2023). For a more detailed description see :\n\ndat &lt;- merTools::hsb\nhead(dat, 6)\n\n  schid minority female    ses mathach size schtype meanses\n1  1224        0      1 -1.528   5.876  842       0  -0.428\n2  1224        0      1 -0.588  19.708  842       0  -0.428\n3  1224        0      0 -0.528  20.349  842       0  -0.428\n4  1224        0      0 -0.668   8.781  842       0  -0.428\n5  1224        0      0 -0.158  17.898  842       0  -0.428\n6  1224        0      0  0.022   4.583  842       0  -0.428"
  },
  {
    "objectID": "material/mlm/random-anova.html#one-way-anova-with-random-effects-i",
    "href": "material/mlm/random-anova.html#one-way-anova-with-random-effects-i",
    "title": "One-Way ANOVA with Random Effects",
    "section": "One-Way ANOVA with Random Effects I",
    "text": "One-Way ANOVA with Random Effects I\nThe one-Way ANOVA with Random Effects Model is a model without predictors (often called the empty model [ger: “Nullmodell”]); the variance of a variable is decomposed into level 1 (within-) and level 2 (between-) variance components and it is the first step in (every?) multilevel analysis.\n\n\n\n\n\n\nLevel-specific equations\n\\[\n\\text{Level 1: } Y_{ij} = \\beta_{0j} + r_{ij}\n\\qquad(1)\\]\n\\[\n\\text{Level 2: } \\beta_{0j} = \\gamma_{00} + u_{0j}\n\\qquad(2)\\]\nCombined equation\nSubstituting Equation 2 into Equation 1 yields the combined model equation (see Equation 3):\n\\[\nY_{ij} = \\gamma_{00} + u_{0j} + r_{ij}\n\\qquad(3)\\]"
  },
  {
    "objectID": "material/mlm/random-anova.html#one-way-anova-with-random-effects-ii",
    "href": "material/mlm/random-anova.html#one-way-anova-with-random-effects-ii",
    "title": "One-Way ANOVA with Random Effects",
    "section": "One-Way ANOVA with Random Effects II",
    "text": "One-Way ANOVA with Random Effects II\n\n\n\n\n\n\nVariance decomposition of \\(Y_{ij}\\)\n\\[\n\\begin{aligned}\nVAR(Y_{ij}) &= VAR(u_{0j}) + VAR(r_{ij}) \\\\\n            &= \\tau_{00} + \\sigma^2\n\\end{aligned}\n\\qquad(4)\\]\n\nIntraclass correlation coefficient (ICC):\n\\[\nICC(\\rho) = \\frac{ \\tau_{00} } {\\tau_{00} + \\sigma^2 }\n\\qquad(5)\\]\n→ It measures the proportion of the variance in the outcome that is between level 2 units; if \\(ICC = 0\\) there is no need for multilevel modeling!"
  },
  {
    "objectID": "material/mlm/random-anova.html#one-way-anova-with-random-effects-in-r-i",
    "href": "material/mlm/random-anova.html#one-way-anova-with-random-effects-in-r-i",
    "title": "One-Way ANOVA with Random Effects",
    "section": "One-Way ANOVA with Random Effects in R I",
    "text": "One-Way ANOVA with Random Effects in R I\n\n\nPrint\nTable\nParameter Extraction\n\n\n\n\nraMod &lt;- dat |&gt;\n  lmer(formula = mathach ~ 1 + \n                  (1 | schid),\n       REML = FALSE)\n\nsummary(raMod)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: mathach ~ 1 + (1 | schid)\n   Data: dat\n\n     AIC      BIC   logLik deviance df.resid \n 47121.8  47142.4 -23557.9  47115.8     7182 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-3.06262 -0.75365  0.02676  0.76070  2.74184 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n schid    (Intercept)  8.553   2.925   \n Residual             39.148   6.257   \nNumber of obs: 7185, groups:  schid, 160\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  12.6371     0.2436   51.87\n\n\n\n\n\ndat |&gt;\n  lmer(formula = mathach ~ 1 + \n        (1 | schid),\n       REML = FALSE) |&gt;\n  as_flextable()\n\n\nTable 1: Random ANOVA Table generated by the flextable package (Gohel & Skintzos, 2024)\n\n\n\n\n\n\ngroup\n\nEstimate\nStandard Error\n\nstatistic\n\n\nFixed effects\n\n\n(Intercept)\n12.637\n0.244\n\n51.873\n\nRandom effects\n\nschid\nsd__(Intercept)\n2.925\n\n\n\n\n\nResidual\nsd__Observation\n6.257\n\n\n\n\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\nsquare root of the estimated residual variance: 6.3\ndata's log-likelihood under the model: -23,557.9\nAkaike Information Criterion: 47,121.8\nBayesian Information Criterion: 47,142.4\n\n\n\n\n\n\n\n\n\n\n\nraFixedEff &lt;- summary(raMod) |&gt;\n  coefficients()\n\nraFixedEff\n\n            Estimate Std. Error  t value\n(Intercept) 12.63707  0.2436171 51.87266\n\n\n\nraRandomEff &lt;- raMod |&gt;\n  VarCorr() |&gt;\n  as.data.frame() |&gt;\n  subset(select = \"vcov\")\n  \nraRandomEff\n\n       vcov\n1  8.553464\n2 39.148400"
  },
  {
    "objectID": "material/mlm/random-anova.html#parameters",
    "href": "material/mlm/random-anova.html#parameters",
    "title": "One-Way ANOVA with Random Effects",
    "section": "Parameters",
    "text": "Parameters\nRecall the combined equation of the model (Equation 3): \\(Y_{ij} = \\gamma_{00} + u_{0j} + r_{ij}\\)\nFixed effects:\n\\(\\gamma_{00}\\) = 12.637\nRandom effects:\n\\(VAR(u_{0j}) = \\tau_{00}\\) = 8.553\n\\(VAR(r_{ij}) = \\sigma^2\\) = 39.148"
  },
  {
    "objectID": "material/mlm/random-anova.html#tbc",
    "href": "material/mlm/random-anova.html#tbc",
    "title": "One-Way ANOVA with Random Effects",
    "section": "TBC …",
    "text": "TBC …"
  },
  {
    "objectID": "material/mlm/random-anova.html#mlm-ra-ref",
    "href": "material/mlm/random-anova.html#mlm-ra-ref",
    "title": "One-Way ANOVA with Random Effects",
    "section": "References",
    "text": "References\n\n\nBates, D., Maechler, M., Bolker, B., & Walker, S. (2023). lme4: Linear mixed-effects models using eigen and S4. https://github.com/lme4/lme4/\n\n\nGohel, D., & Skintzos, P. (2024). Flextable: Functions for tabular reporting. https://ardata-fr.github.io/flextable-book/\n\n\nKnowles, J. E., & Frederick, C. (2023). merTools: Tools for analyzing mixed effect regression models. https://CRAN.R-project.org/package=merTools\n\n\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., & Dunnington, D. (2023). ggplot2: Create elegant data visualisations using the grammar of graphics. https://ggplot2.tidyverse.org"
  },
  {
    "objectID": "material/new-stuff/CACE.html#different-types-of-analyses",
    "href": "material/new-stuff/CACE.html#different-types-of-analyses",
    "title": " ",
    "section": "Different types of analyses",
    "text": "Different types of analyses\nDifferent types of analyses to analyze a randomized experiment (sagarin2014?)\n\nIntention-to-treat\nAs-treated analysis\nPer-protocol analysis\nComplier average causal effect\nDose–response estimation\nPropensity score analysis\nTreatment effect bounding"
  },
  {
    "objectID": "material/new-stuff/CACE.html#overview-complier-average-causal-effect-cace",
    "href": "material/new-stuff/CACE.html#overview-complier-average-causal-effect-cace",
    "title": " ",
    "section": "Overview Complier Average Causal Effect (CACE)",
    "text": "Overview Complier Average Causal Effect (CACE)"
  },
  {
    "objectID": "material/new-stuff/CACE.html#terminology",
    "href": "material/new-stuff/CACE.html#terminology",
    "title": " ",
    "section": "Terminology",
    "text": "Terminology\n\nOutcome: \\(Y_i\\)\nAssignment of treatment (and instrument): \\(Z_i\\)\nReceipt of treatment (compliance status): \\(W_i\\)"
  },
  {
    "objectID": "material/new-stuff/CACE.html#noncompliance",
    "href": "material/new-stuff/CACE.html#noncompliance",
    "title": " ",
    "section": "Noncompliance",
    "text": "Noncompliance\n\nBy noncompliance we refer to the situation where some units who are assigned to receive a particular treatment level do not comply with their assignment and instead receive an alternative treatment (imbens2015?)"
  },
  {
    "objectID": "material/new-stuff/CACE.html#one--and-two-sided-noncompliance",
    "href": "material/new-stuff/CACE.html#one--and-two-sided-noncompliance",
    "title": " ",
    "section": "One- and two-sided Noncompliance",
    "text": "One- and two-sided Noncompliance\nOne-sided noncompliance\nOne-sided noncompliance means that it is asymmetric. Only units that are assigned to receive a treatment can circumvent their assigned treatment. Units in the control condition comply with this assignment (imbens2015?).\nObserved outcome: \\(Y^{obs}_i = Y_i(Z_i,W^{obs}_i)= Y_i(Z_i,W_i(Z_i)) = \\begin{cases} Y_i(0,0), \\text{ if } Z_i = 0, W^{obs}_i = 0\\\\ Y_i(1,0), \\text{ if } Z_i = 1, W^{obs}_i = 0 \\\\ Y_i(1,1), \\text{ if } Z_i = 1, W^{obs}_i = 1 \\\\ \\end{cases}\\)\nExample: Data generation\n\nShow/hide functiongenOSNC &lt;- function( n = 1000,\n                     tau = .5,\n                     bu = 0, du = 0,\n                     compliance = \"one-sided\" ) {\n    \n    # treatment\n    Z &lt;- rbinom(n, size = 1, prob = .5)\n    n1 &lt;- sum(Z)\n    # unobserved confounder\n    U &lt;- rnorm(n, 0, 1)\n    \n    dat &lt;- as.data.frame(cbind(Z,U))\n    \n   \n    # compliance    \n        \n    if ( compliance == \"one-sided\") {\n\n      dat[dat$Z == 1, \"W\"] &lt;- rbinom(n1,\n                                     size = 1,\n                                     prob = 1 / (1 + exp(- du*U)))  # check prob\n      dat[dat$Z == 0, \"W\"] &lt;- 0                  \n      \n    } else if (compliance == \"two-sided\") {\n\n    } else {\n      stop(\"state either one-sided or two-sided compliance status\")\n    }\n    \n\n    # outcome\n    dat$Y &lt;- with(dat, 0 + 0*Z + tau*W + bu*U + rnorm(n, 0 ,1))\n\n    return(dat)\n\n} \n\n\nExecute the function with \\(N =\\) 10000.\n\nset.seed(987)\nexDat &lt;- genOSNC(n = 10000)\n\n\nexDat |&gt;\n  lm(formula = Y ~ Z + W) |&gt;\n  summary()\n\n\nCall:\nlm(formula = Y ~ Z + W, data = exDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7332 -0.6933  0.0130  0.6992  3.6143 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.001862   0.014188  -0.131    0.896    \nZ            0.003713   0.024807   0.150    0.881    \nW            0.480697   0.028557  16.833   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.006 on 9997 degrees of freedom\nMultiple R-squared:  0.04169,   Adjusted R-squared:  0.0415 \nF-statistic: 217.5 on 2 and 9997 DF,  p-value: &lt; 2.2e-16\n\n\nSample size: Treatment assignment\n\nwith(exDat, table(Z))\n\nZ\n   0    1 \n5031 4969 \n\n\nSample size: Treatment received\n\nwith(exDat, table(W))\n\nW\n   0    1 \n7477 2523 \n\n\nSample size: Treatment received\n\nwith(exDat, table(Z, W))\n\n   W\nZ      0    1\n  0 5031    0\n  1 2446 2523\n\n\nEstimating the ITT Effect for the Receipt of Treatment\n(needed for LATE effect)\n\nComplete randomization of the assignment implies that an unbaised estimator for the avarage causal effect \\(ITT_W\\) exists in the form of the average difference in treatment status by assigment status (imbens2015?, p, 520)\n\n\\(\\widehat{ITT_W}=\\overline{W}^{obs}_1-\\overline{W}^{obs}_0 = \\overline{W}^{obs}_1\\)\n\nITTw &lt;- mean(exDat[exDat$Z == 1, \"W\"])\nITTw\n\n[1] 0.507748\n\n\nEstimating the ITT Effect for the Outcome\n\nITTcomp &lt;- with(exDat, aggregate(Y ~ Z,\n                                 FUN = function(x) {\n                                  c(M = mean(x),\n                                    Var = var(x))\n                                    }\n                                )\n              )\nITTcomp\n\n  Z          Y.M        Y.Var\n1 0 -0.001861892  1.018743443\n2 1  0.245924519  1.064329908\n\n\n\\(\\widehat{ITT_Y} = \\overline{Y}^{obs}_1 - \\overline{Y}^{obs}_0\\) = 0.2459245 - -0.0018619 = 0.2477864\nWith the variance and sample sizes, we then caluclate the standard errors and confidence intervals…\nEstimating the ITT Effect for the Outcome by Compliance Status\n\nwith(exDat[exDat$Z == 1,], aggregate(Y ~ W,\n                                 FUN = function(x) {\n                                  c(M = mean(x),\n                                    Var = var(x))\n                                    }\n                                )\n              )\n\n  W         Y.M       Y.Var\n1 0 0.001851581 1.000415971\n2 1 0.482548541 1.012924939\n\n\nLocal Average Treatment Effects (LATE)\n\\(\\tau_{late} = ITT_{Y,co} = \\frac{ITT_Y}{ITT_W}\\)\n\nunname(ITTy)/ITTw\n\n[1] 0.4880106\n\n\nIV estimation\n\nivMod &lt;- lm(W ~ Z, data = exDat)\nexDat$What &lt;- predict(ivMod)\n\nlm(Y ~ What, data = exDat)\n\n\nCall:\nlm(formula = Y ~ What, data = exDat)\n\nCoefficients:\n(Intercept)         What  \n  -0.001862     0.488011  \n\n\n\nlibrary(ivreg)\nivreg(formula = Y ~ W | Z, data = exDat)\n\n\nCall:\nivreg(formula = Y ~ W | Z, data = exDat)\n\nCoefficients:\n(Intercept)            W  \n  -0.001862     0.488011  \n\n\n\nlibrary(lavaan)\n\nivLavMod &lt;- '\n\nY ~ W\nY ~ 1\nW ~ Z\nY ~~ W\n'\n\nfitivLavMod &lt;- sem(ivLavMod, data = exDat)\nsummary(fitivLavMod)"
  },
  {
    "objectID": "material/new-stuff/CACE.html#test",
    "href": "material/new-stuff/CACE.html#test",
    "title": " ",
    "section": "test",
    "text": "test\n\n\n\n\n\nflowchart LR\n    A[fa:fa-car] --&gt; R\n    R --&gt; Exp\n    R --&gt; Con\n    Exp --&gt; C[\"Compliance\\n\"]\n    Exp --&gt; NC[\"Non-\\nCompliance\"]\n\n\n\n\n\n\nfor (i in 1:3) {\n  print(i)\n}"
  },
  {
    "objectID": "material/new-stuff/CACE.html#cace-ref",
    "href": "material/new-stuff/CACE.html#cace-ref",
    "title": " ",
    "section": "References (CACE slides)",
    "text": "References (CACE slides)"
  },
  {
    "objectID": "material/software/intro-r-rstudio.html",
    "href": "material/software/intro-r-rstudio.html",
    "title": "Introduction to R & RStudio",
    "section": "",
    "text": "This part gives a short introduction to R and RStudio. If you are familiar with the programs and are not interested in the R vs tidyverse “distinction”, you can skip this section.\n\n\nR: R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows and MacOS (see https://www.r-project.org/).\nR Studio: Coding environment for R, built by Posit.\n\nSome advertisement from the Posit website:\n\nUsed by millions of people weekly, the RStudio integrated development environment (IDE) is a set of tools built to help you be more productive with R and Python. It includes a console, syntax-highlighting editor that supports direct code execution. It also features tools for plotting, viewing history, debugging and managing your workspace.\n\nOf course there are other IDEs (e.g., Visual Studio Code, but if you use R, RStudio is most likely the way to go.\n\n\n\n\n\n\n\nExercise: Open RStudio!\n\n\n\n\n\nThis should look like this, maybe or probably with a different appearance (this is the Dracula theme). You can change this via Tools &gt; Global Options &gt; Appearance\n\n\n\n\nIn RStudio there are different panes1:\n\n\n\nConsole\n\nHere you can access R\n\nE.g., ask R what is: 2 + 2\n\n\n\n\nSource/Script\n\nEditor to save scripts\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nYou should never work directly in the Console, but always use a R-script (e.g., script.R) or even better a Quarto document (e.g., script.qmd). It is important to understand and reproduce everything you did.\n\n\n\n\nEnvironment/History/…/Tutorial\n\nEnvironment: contains all objects that were created or loaded during an R session\nHistory:\n… e.g., the free and open source distributed version control system git\n\nTutorial: A tutorial to learn R with the learnr package (R-learnr?)\n\n\n\n\nFiles/Plots/Packages/Help/Viewer\n\nFiles: is kind of the file manager\nPlots: shows the generated plots\nPackages: overview of the (loaded &) installed packages\nHelp: When you ask for help (e.g., regarding a specific function in R: ?mean)\nViewer: E.g., previewing rendered Quarto documents\n\n\n\nIt is also reasonable to use the project option. This means, whenever you start a new project (e.g., a scale-manual), create an project: File &gt; New Project\n\n\n\n\n\n\nExercise: Create an project!\n\n\n\n\n\n\nChoose between:\n\n\nNew Directory (for today)\nExisting Directory\nVersion Control (this is recommended, but is beyond the scope of this workshop)\n\n\n\nChoose a project type (today a R project or Quarto project)\n\n\n\nProvide a short name, set the check mark Open in new session and click Create Project\n\n\n\n\n\n\n\nThis section gives a (very?) brief introduction to the R programming language.\n\n\n\n\n\n\nFor (more) comprehensive introductions…\n\n\n\n\n\n…or overviews of the language see (e.g.):\n\nR Manual on the CRAN website\nR for Data Science by Hadley Wickham and Garrett Grolemund\nHands-On Programming with R by Garrett Grolemund\nIntroduction to R by the IDRE Statistical Consulting Group\n…\n\n\n\n\n\nTo understand computations in R, two slogans are helpful:\n\nEverything that exists is an object.\n\nEverything that happens is a function call.\n\n\n– John Chambers (creator of the S programming language)\n\n\n\nBefore working with R, there are a few basics you need to know:\n\n\n\n\nR is a case-sensitive programming language. This means that R distinguishes whether a word is written in upper or lower case\n\n\n\n\n\n\"name\" == \"Name\"\n\n[1] FALSE\n\n\n\n\n\n\n\n\nValues are assigned to objects using &lt;-\n\n\n\n\n\n\na &lt;- \"Hello world!\"\n\n\n\n\n\n\n\nArguments within functions are assigned using =\n\n\n\n\n\n\ndf &lt;- data.frame(\n  x = 1:4,\n  y = 3:6\n)\n\n\n\n\n\n\n\n\n\nExercise: Create a new R script\n\n\n\n\n\nFile &gt; New File &gt; R Script or alternatively use the shortcut Ctrl + Shift + N\n\nThen save the file File &gt; Save or File &gt; Save As. Shortcut: Ctrl + s\n\n\n\n\nThe basic data types2 in R are depicted in Table 1.\n\n\nTable 1: Basic data types in R\n\n\n\n\n\n\n\n\nType\nDescription\nValue (example)\n\n\n\nNumeric\nNumbers with decimal value or fraction\n3.7\n\n\nInteger\nCounting numbers and their additive inverses\n\n2, -115\n\n\n\nCharacter\naka string. Letters enclosed by quotes in the output.\n\n\"Hello World!\",\"4\"\n\n\n\nLogical \nboolean\n\nTRUE, FALSE\n\n\n\nFactor\nCategorial data\n- Level: characteristic value as seen by R\n- Label: designation of the characteristic attributes\n\n0, 1male,female\n\n\n\nSpecial\n\n\nMissing values: unknown cell value\n\nImpossible values: not a number\n\nEmpty values: known empty cell value\n\n\nNANaNNULL\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise: Use the class function to check the data type of an object!\n\n\n\n\n\n\nx &lt;- 10\nclass(x)\n\n[1] \"numeric\"\n\ny &lt;- \"Hello World\"\nclass(y)\n\n[1] \"character\"\n\n\n\n\n\n\n\nR has a couple of different data structures3 which are briefly described in the following subsections.\n\n\n\n\none-dimensional array\n\nsame data type\ne.g., c(45, 6, -83, 23, 61)\n\n\n\n\n\n\n\n\n\n\n\nTips for handling vectors\n\n\n\n\n\nCreate a vector with the c function\n\nv &lt;- c(45, 6, -83, 23, 61)\nv\n\n[1]  45   6 -83  23  61\n\n\nOr a named vector…\n\nvNam &lt;- c(a = 45, b = 6, c = -83, d = 23, e = 61)\nvNam\n\n  a   b   c   d   e \n 45   6 -83  23  61 \n\n\nCount the amount of items contained in vector\n\nlength(v)\n\n[1] 5\n\n\nVector indexing (by position)\n\nv[1]\n\n[1] 45\n\nv[-3]\n\n[1] 45  6 23 61\n\n\nSlicing vectors\n\nv[3:5]\n\n[1] -83  23  61\n\n\nGenerate regular sequences using seq function\n\nseq(from = 0,\n    to = 20,\n    by = 2)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\n\n\n\n\n\n\n\n\n\n\ntwo-dimensional\n\nsame data type\nexample see on the right\n\n\n\n\n\n\n\n\n\n\n\nTip 1: Tips for handling matrices\n\n\n\n\n\nThe matrix function creates a matrix from the given set of values\n\nm &lt;- matrix(data = c(1, 2, 3, 45, 36, 52),\n            nrow = 2,\n            ncol = 3,\n            byrow = TRUE)\nm\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]   45   36   52\n\n\nSlicing works also on matrices: m[row , column]\n\nm[, 1:2]\n\n     [,1] [,2]\n[1,]    1    2\n[2,]   45   36\n\n\n\n\n\n\n\n\n\n\n\ncan contain elements of various data types\noften ordered collection of values\none-indexed (indexing starts with 1)\ne.g., list(\"hi\", 2, NULL)\n\n\n\n\n\n\n\n\n\n\n\nTips for handling lists\n\n\n\n\n\nCreate lists (with different elements, i.e., numbers and letters) with the list function\n\nl1 &lt;- list(1:5)\nl2 &lt;- list(letters[1:5])\nl3 &lt;- list(LETTERS[1:5])\n\nCreate a nested list…\n\nl4 &lt;- list(l1, l2, l3)\n\n…or a named (nested) list\n\nl4Nam &lt;- list(\"Numbers\" = l1,\n              \"SmallLetters\" = l2,\n              \"CaptialLetters\" = l3)\n\nAccess list or nested list elements\n\nl4[2]\n\n[[1]]\n[[1]][[1]]\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\nl4[[2]][3]\n\n[[1]]\nNULL\n\n\nUnlist the list to get vector which contains all the atomic components\n\nunlist(l1)\n\n[1] 1 2 3 4 5\n\nunlist(l4)\n\n [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"a\" \"b\" \"c\" \"d\" \"e\" \"A\" \"B\" \"C\" \"D\" \"E\"\n\n\nCount amount of items contained in list\n\nlength(l4)\n\n[1] 3\n\nlength(unlist(l4))\n\n[1] 15\n\n\n\n\n\n\n\n\n\n\n\nvarious columns\ndifferent data types\nvariables = columns\nobservations = rows\nexample see on the right\n\n\n\n\n\n\n\n\n\n\n\nTip 2: Tips for handling dataFrames\n\n\n\n\n\n\ndf &lt;- data.frame(\n  id = 1:4,\n  age = c(12, 13, 12, 14),\n  sex = c(1, 1, 2, 2)\n)\ndf\n\n  id age sex\n1  1  12   1\n2  2  13   1\n3  3  12   2\n4  4  14   2\n\n\nNumber of observations\n\nnrow(df)\n\n[1] 4\n\n\nShow dimension (rows, columns) of dataframe\n\ndim(df)\n\n[1] 4 3\n\n\nColumn names\n\ncolnames(df)\n\n[1] \"id\"  \"age\" \"sex\"\n\n\nShow the first two rows of the dataframe\n\nhead(df, 2)\n\n  id age sex\n1  1  12   1\n2  2  13   1\n\n\nStructure of dataframe object\n\nstr(df)\n\n'data.frame':   4 obs. of  3 variables:\n $ id : int  1 2 3 4\n $ age: num  12 13 12 14\n $ sex: num  1 1 2 2\n\n\nSome descriptive statistics using the summary function (for more see Section Descriptive statistics and item analysis\n\nsummary(df)\n\n       id            age             sex     \n Min.   :1.00   Min.   :12.00   Min.   :1.0  \n 1st Qu.:1.75   1st Qu.:12.00   1st Qu.:1.0  \n Median :2.50   Median :12.50   Median :1.5  \n Mean   :2.50   Mean   :12.75   Mean   :1.5  \n 3rd Qu.:3.25   3rd Qu.:13.25   3rd Qu.:2.0  \n Max.   :4.00   Max.   :14.00   Max.   :2.0  \n\n\n\n\n\n\n\n\n\n\nBesides the functionality of base R (R Core Team, 2023), there is the so-called tidyverse (R-tidyverse?) within R. The tidyverse is a collection of R packages (see Figure 1) that “share an underlying design philosophy, grammar, and data structures” and are (specifically) designed for data science (see https://www.tidyverse.org/).\n\n\n\n\n\n\n\n\nFigure 1: tidyverse package collection\n\n\n\n\nWithin the tidyverse package collection, the dplyr package (Wickham et al., 2023) provides a set of convenient functions for manipulating data. Together with the pipe operator %&gt;% from the magrittr package (R-magrittr?)), it is an extremely powerful approach to manipulate data in a clear and comprehensible way. The native4 R pipe |&gt; was introduced with R v4.1.0.\n\n\n\n\n\n\nWhat does the pipe operator |&gt;?\n\n\n\n\n\nThe tidyverse style guide suggests using the pipe operator “to emphasize a sequence of actions”. The pipe operator can be understood as “take the object and then” pass it to the next function. In the following, the use of the base R pipe operator is shown:\n\n\nTake the data frame exDat and then\n\nSelect the variables: msc1 and msc2 and then\n\nCalculate descriptive statistics using the describe function from the psych package (Revelle, 2024) and then\n\nCreate a table with the kable function from the knitr package (Xie, 2023)\n\n\n\nexDat |&gt; \n  dplyr::select(c(msc1, msc2)) |&gt;\n  psych::describe(fast=TRUE) |&gt; \n  knitr::kable(digits = 2) \n\n\n\n\nvars\nn\nmean\nsd\nmin\nmax\nrange\nse\n\n\n\nmsc1\n1\n750\n2.52\n0.74\n1\n4\n3\n0.03\n\n\nmsc2\n2\n680\n2.54\n0.72\n1\n4\n3\n0.03\n\n\n\n\n\nIn contrast, when we use a nested approach the code would look like this:\n\nknitr::kable(psych::describe(exDat,fast=TRUE),digits = 2) \n\n…or maybe a little bit more clear:\n\nknitr::kable(\n  psych::describe(exDat,\n                  fast=TRUE),\n  digits = 2) \n\nNevertheless, when there are many functions, it gets kind of messy and difficult to comprehend. For more information on how to use pipes, see Chapter 4 of the guide.",
    "crumbs": [
      "Compendium",
      "Software",
      "Introduction to R & RStudio"
    ]
  },
  {
    "objectID": "material/software/intro-r-rstudio.html#what-is-r-rstudio",
    "href": "material/software/intro-r-rstudio.html#what-is-r-rstudio",
    "title": "Introduction to R & RStudio",
    "section": "",
    "text": "R: R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows and MacOS (see https://www.r-project.org/).\nR Studio: Coding environment for R, built by Posit.\n\nSome advertisement from the Posit website:\n\nUsed by millions of people weekly, the RStudio integrated development environment (IDE) is a set of tools built to help you be more productive with R and Python. It includes a console, syntax-highlighting editor that supports direct code execution. It also features tools for plotting, viewing history, debugging and managing your workspace.\n\nOf course there are other IDEs (e.g., Visual Studio Code, but if you use R, RStudio is most likely the way to go.",
    "crumbs": [
      "Compendium",
      "Software",
      "Introduction to R & RStudio"
    ]
  },
  {
    "objectID": "material/software/intro-r-rstudio.html#how-to-work-with-r-and-rstudio",
    "href": "material/software/intro-r-rstudio.html#how-to-work-with-r-and-rstudio",
    "title": "Introduction to R & RStudio",
    "section": "",
    "text": "Exercise: Open RStudio!\n\n\n\n\n\nThis should look like this, maybe or probably with a different appearance (this is the Dracula theme). You can change this via Tools &gt; Global Options &gt; Appearance\n\n\n\n\nIn RStudio there are different panes1:\n\n\n\nConsole\n\nHere you can access R\n\nE.g., ask R what is: 2 + 2\n\n\n\n\nSource/Script\n\nEditor to save scripts\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nYou should never work directly in the Console, but always use a R-script (e.g., script.R) or even better a Quarto document (e.g., script.qmd). It is important to understand and reproduce everything you did.\n\n\n\n\nEnvironment/History/…/Tutorial\n\nEnvironment: contains all objects that were created or loaded during an R session\nHistory:\n… e.g., the free and open source distributed version control system git\n\nTutorial: A tutorial to learn R with the learnr package (R-learnr?)\n\n\n\n\nFiles/Plots/Packages/Help/Viewer\n\nFiles: is kind of the file manager\nPlots: shows the generated plots\nPackages: overview of the (loaded &) installed packages\nHelp: When you ask for help (e.g., regarding a specific function in R: ?mean)\nViewer: E.g., previewing rendered Quarto documents\n\n\n\nIt is also reasonable to use the project option. This means, whenever you start a new project (e.g., a scale-manual), create an project: File &gt; New Project\n\n\n\n\n\n\nExercise: Create an project!\n\n\n\n\n\n\nChoose between:\n\n\nNew Directory (for today)\nExisting Directory\nVersion Control (this is recommended, but is beyond the scope of this workshop)\n\n\n\nChoose a project type (today a R project or Quarto project)\n\n\n\nProvide a short name, set the check mark Open in new session and click Create Project",
    "crumbs": [
      "Compendium",
      "Software",
      "Introduction to R & RStudio"
    ]
  },
  {
    "objectID": "material/software/intro-r-rstudio.html#short-introduction-to-the-r-programming-language",
    "href": "material/software/intro-r-rstudio.html#short-introduction-to-the-r-programming-language",
    "title": "Introduction to R & RStudio",
    "section": "",
    "text": "This section gives a (very?) brief introduction to the R programming language.\n\n\n\n\n\n\nFor (more) comprehensive introductions…\n\n\n\n\n\n…or overviews of the language see (e.g.):\n\nR Manual on the CRAN website\nR for Data Science by Hadley Wickham and Garrett Grolemund\nHands-On Programming with R by Garrett Grolemund\nIntroduction to R by the IDRE Statistical Consulting Group\n…\n\n\n\n\n\nTo understand computations in R, two slogans are helpful:\n\nEverything that exists is an object.\n\nEverything that happens is a function call.\n\n\n– John Chambers (creator of the S programming language)\n\n\n\nBefore working with R, there are a few basics you need to know:\n\n\n\n\nR is a case-sensitive programming language. This means that R distinguishes whether a word is written in upper or lower case\n\n\n\n\n\n\"name\" == \"Name\"\n\n[1] FALSE\n\n\n\n\n\n\n\n\nValues are assigned to objects using &lt;-\n\n\n\n\n\n\na &lt;- \"Hello world!\"\n\n\n\n\n\n\n\nArguments within functions are assigned using =\n\n\n\n\n\n\ndf &lt;- data.frame(\n  x = 1:4,\n  y = 3:6\n)\n\n\n\n\n\n\n\n\n\nExercise: Create a new R script\n\n\n\n\n\nFile &gt; New File &gt; R Script or alternatively use the shortcut Ctrl + Shift + N\n\nThen save the file File &gt; Save or File &gt; Save As. Shortcut: Ctrl + s\n\n\n\n\nThe basic data types2 in R are depicted in Table 1.\n\n\nTable 1: Basic data types in R\n\n\n\n\n\n\n\n\nType\nDescription\nValue (example)\n\n\n\nNumeric\nNumbers with decimal value or fraction\n3.7\n\n\nInteger\nCounting numbers and their additive inverses\n\n2, -115\n\n\n\nCharacter\naka string. Letters enclosed by quotes in the output.\n\n\"Hello World!\",\"4\"\n\n\n\nLogical \nboolean\n\nTRUE, FALSE\n\n\n\nFactor\nCategorial data\n- Level: characteristic value as seen by R\n- Label: designation of the characteristic attributes\n\n0, 1male,female\n\n\n\nSpecial\n\n\nMissing values: unknown cell value\n\nImpossible values: not a number\n\nEmpty values: known empty cell value\n\n\nNANaNNULL\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise: Use the class function to check the data type of an object!\n\n\n\n\n\n\nx &lt;- 10\nclass(x)\n\n[1] \"numeric\"\n\ny &lt;- \"Hello World\"\nclass(y)\n\n[1] \"character\"\n\n\n\n\n\n\n\nR has a couple of different data structures3 which are briefly described in the following subsections.\n\n\n\n\none-dimensional array\n\nsame data type\ne.g., c(45, 6, -83, 23, 61)\n\n\n\n\n\n\n\n\n\n\n\nTips for handling vectors\n\n\n\n\n\nCreate a vector with the c function\n\nv &lt;- c(45, 6, -83, 23, 61)\nv\n\n[1]  45   6 -83  23  61\n\n\nOr a named vector…\n\nvNam &lt;- c(a = 45, b = 6, c = -83, d = 23, e = 61)\nvNam\n\n  a   b   c   d   e \n 45   6 -83  23  61 \n\n\nCount the amount of items contained in vector\n\nlength(v)\n\n[1] 5\n\n\nVector indexing (by position)\n\nv[1]\n\n[1] 45\n\nv[-3]\n\n[1] 45  6 23 61\n\n\nSlicing vectors\n\nv[3:5]\n\n[1] -83  23  61\n\n\nGenerate regular sequences using seq function\n\nseq(from = 0,\n    to = 20,\n    by = 2)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\n\n\n\n\n\n\n\n\n\n\ntwo-dimensional\n\nsame data type\nexample see on the right\n\n\n\n\n\n\n\n\n\n\n\nTip 1: Tips for handling matrices\n\n\n\n\n\nThe matrix function creates a matrix from the given set of values\n\nm &lt;- matrix(data = c(1, 2, 3, 45, 36, 52),\n            nrow = 2,\n            ncol = 3,\n            byrow = TRUE)\nm\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]   45   36   52\n\n\nSlicing works also on matrices: m[row , column]\n\nm[, 1:2]\n\n     [,1] [,2]\n[1,]    1    2\n[2,]   45   36\n\n\n\n\n\n\n\n\n\n\n\ncan contain elements of various data types\noften ordered collection of values\none-indexed (indexing starts with 1)\ne.g., list(\"hi\", 2, NULL)\n\n\n\n\n\n\n\n\n\n\n\nTips for handling lists\n\n\n\n\n\nCreate lists (with different elements, i.e., numbers and letters) with the list function\n\nl1 &lt;- list(1:5)\nl2 &lt;- list(letters[1:5])\nl3 &lt;- list(LETTERS[1:5])\n\nCreate a nested list…\n\nl4 &lt;- list(l1, l2, l3)\n\n…or a named (nested) list\n\nl4Nam &lt;- list(\"Numbers\" = l1,\n              \"SmallLetters\" = l2,\n              \"CaptialLetters\" = l3)\n\nAccess list or nested list elements\n\nl4[2]\n\n[[1]]\n[[1]][[1]]\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\nl4[[2]][3]\n\n[[1]]\nNULL\n\n\nUnlist the list to get vector which contains all the atomic components\n\nunlist(l1)\n\n[1] 1 2 3 4 5\n\nunlist(l4)\n\n [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"a\" \"b\" \"c\" \"d\" \"e\" \"A\" \"B\" \"C\" \"D\" \"E\"\n\n\nCount amount of items contained in list\n\nlength(l4)\n\n[1] 3\n\nlength(unlist(l4))\n\n[1] 15\n\n\n\n\n\n\n\n\n\n\n\nvarious columns\ndifferent data types\nvariables = columns\nobservations = rows\nexample see on the right\n\n\n\n\n\n\n\n\n\n\n\nTip 2: Tips for handling dataFrames\n\n\n\n\n\n\ndf &lt;- data.frame(\n  id = 1:4,\n  age = c(12, 13, 12, 14),\n  sex = c(1, 1, 2, 2)\n)\ndf\n\n  id age sex\n1  1  12   1\n2  2  13   1\n3  3  12   2\n4  4  14   2\n\n\nNumber of observations\n\nnrow(df)\n\n[1] 4\n\n\nShow dimension (rows, columns) of dataframe\n\ndim(df)\n\n[1] 4 3\n\n\nColumn names\n\ncolnames(df)\n\n[1] \"id\"  \"age\" \"sex\"\n\n\nShow the first two rows of the dataframe\n\nhead(df, 2)\n\n  id age sex\n1  1  12   1\n2  2  13   1\n\n\nStructure of dataframe object\n\nstr(df)\n\n'data.frame':   4 obs. of  3 variables:\n $ id : int  1 2 3 4\n $ age: num  12 13 12 14\n $ sex: num  1 1 2 2\n\n\nSome descriptive statistics using the summary function (for more see Section Descriptive statistics and item analysis\n\nsummary(df)\n\n       id            age             sex     \n Min.   :1.00   Min.   :12.00   Min.   :1.0  \n 1st Qu.:1.75   1st Qu.:12.00   1st Qu.:1.0  \n Median :2.50   Median :12.50   Median :1.5  \n Mean   :2.50   Mean   :12.75   Mean   :1.5  \n 3rd Qu.:3.25   3rd Qu.:13.25   3rd Qu.:2.0  \n Max.   :4.00   Max.   :14.00   Max.   :2.0",
    "crumbs": [
      "Compendium",
      "Software",
      "Introduction to R & RStudio"
    ]
  },
  {
    "objectID": "material/software/intro-r-rstudio.html#baseR-tidyverse",
    "href": "material/software/intro-r-rstudio.html#baseR-tidyverse",
    "title": "Introduction to R & RStudio",
    "section": "",
    "text": "Besides the functionality of base R (R Core Team, 2023), there is the so-called tidyverse (R-tidyverse?) within R. The tidyverse is a collection of R packages (see Figure 1) that “share an underlying design philosophy, grammar, and data structures” and are (specifically) designed for data science (see https://www.tidyverse.org/).\n\n\n\n\n\n\n\n\nFigure 1: tidyverse package collection\n\n\n\n\nWithin the tidyverse package collection, the dplyr package (Wickham et al., 2023) provides a set of convenient functions for manipulating data. Together with the pipe operator %&gt;% from the magrittr package (R-magrittr?)), it is an extremely powerful approach to manipulate data in a clear and comprehensible way. The native4 R pipe |&gt; was introduced with R v4.1.0.\n\n\n\n\n\n\nWhat does the pipe operator |&gt;?\n\n\n\n\n\nThe tidyverse style guide suggests using the pipe operator “to emphasize a sequence of actions”. The pipe operator can be understood as “take the object and then” pass it to the next function. In the following, the use of the base R pipe operator is shown:\n\n\nTake the data frame exDat and then\n\nSelect the variables: msc1 and msc2 and then\n\nCalculate descriptive statistics using the describe function from the psych package (Revelle, 2024) and then\n\nCreate a table with the kable function from the knitr package (Xie, 2023)\n\n\n\nexDat |&gt; \n  dplyr::select(c(msc1, msc2)) |&gt;\n  psych::describe(fast=TRUE) |&gt; \n  knitr::kable(digits = 2) \n\n\n\n\nvars\nn\nmean\nsd\nmin\nmax\nrange\nse\n\n\n\nmsc1\n1\n750\n2.52\n0.74\n1\n4\n3\n0.03\n\n\nmsc2\n2\n680\n2.54\n0.72\n1\n4\n3\n0.03\n\n\n\n\n\nIn contrast, when we use a nested approach the code would look like this:\n\nknitr::kable(psych::describe(exDat,fast=TRUE),digits = 2) \n\n…or maybe a little bit more clear:\n\nknitr::kable(\n  psych::describe(exDat,\n                  fast=TRUE),\n  digits = 2) \n\nNevertheless, when there are many functions, it gets kind of messy and difficult to comprehend. For more information on how to use pipes, see Chapter 4 of the guide.",
    "crumbs": [
      "Compendium",
      "Software",
      "Introduction to R & RStudio"
    ]
  },
  {
    "objectID": "material/software/intro-r-rstudio.html#footnotes",
    "href": "material/software/intro-r-rstudio.html#footnotes",
    "title": "Introduction to R & RStudio",
    "section": "Footnotes",
    "text": "Footnotes\n\nYou can customize them: Tools &gt; Global Options &gt; Pane Layout↩︎\nWe omitted the complex type.↩︎\nWe omitted arrays.↩︎\nfor the difference between |&gt; and %&gt;% see https://ivelasq.rbind.io/blog/understanding-the-r-pipe/↩︎",
    "crumbs": [
      "Compendium",
      "Software",
      "Introduction to R & RStudio"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": " ",
    "section": "",
    "text": "This site serves as a compendium of teaching and coding material that I developed along th last couple of years. The material is based on text books (references will be given), websites (e.g., https://stats.stackexchange.com/), AI tools (e.g., ChatGPT, Blackbox AI) . Many of the materials are also available as a Revealjs presentation that I usually use in teaching.\n\n\n\n\n\n\nWarning\n\n\n\nThis page is work in progress and under active development.",
    "crumbs": [
      "Compendium",
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#about-the-compendium",
    "href": "preface.html#about-the-compendium",
    "title": " ",
    "section": "",
    "text": "This site serves as a compendium of teaching and coding material that I developed along th last couple of years. The material is based on text books (references will be given), websites (e.g., https://stats.stackexchange.com/), AI tools (e.g., ChatGPT, Blackbox AI) . Many of the materials are also available as a Revealjs presentation that I usually use in teaching.\n\n\n\n\n\n\nWarning\n\n\n\nThis page is work in progress and under active development.",
    "crumbs": [
      "Compendium",
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#used-software",
    "href": "preface.html#used-software",
    "title": " ",
    "section": "Used Software",
    "text": "Used Software\nThe majority of the provided code is from the statistical software R (R Core Team, 2023). My most used packages are the following:\n\npkgList &lt;- c(\"base\",\n             \"haven\",\n             \"renv\",\n             \"stringr\",\n             \"dplyr\",\n             \"moments\",\n             \"psych\",\n             \"lme4\",\n             \"merTools\",\n             \"mice\",\n             \"lavaan\",\n             \"knitr\",\n             \"kableExtra\",\n             \"flextable\",\n             \"ggplot2\")\n\nYou can install them with the following code:\n\nlapply(pkgList,\n       function(x) \n        if(!x %in% rownames(installed.packages())) {\n            install.packages(x)\n            }\n        )",
    "crumbs": [
      "Compendium",
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#disclaimer",
    "href": "preface.html#disclaimer",
    "title": " ",
    "section": "Disclaimer",
    "text": "Disclaimer\nAll material is licensed under the MIT License (MIT) and comes with ABSOLUTELY NO WARRANTY.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nThe MIT License\nCopyright (c) 2023\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "crumbs": [
      "Compendium",
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#bugs-errors",
    "href": "preface.html#bugs-errors",
    "title": " ",
    "section": "Bugs & Errors",
    "text": "Bugs & Errors\nFound errors or any bugs? Please send me an email ✉ or report them directly to github.com. At every page, below the table of contents, there is link to the repository of the website. If you think your issue may important for others, please use this option.",
    "crumbs": [
      "Compendium",
      "Preface"
    ]
  }
]