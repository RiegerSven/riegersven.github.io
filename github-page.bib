@incollection{brown2012,
  title = {Confirmatory Factor Analysis},
  booktitle = {Handbook of Structural Equation Modeling},
  author = {Brown, Timothy A. and Moore, Michael T.},
  editor = {Hoyle, Rick H.},
  date = {2012},
  publisher = {Guilford Press},
  location = {New York},
  isbn = {1-60623-077-8}
}

@book{brown2015,
  title = {Confirmatory Factor Analysis for Applied Research},
  author = {Brown, Timothy A.},
  date = {2015},
  series = {Methodology in the Social Sciences},
  edition = {Second edition},
  publisher = {The Guilford Press},
  location = {New York ; London},
  abstract = {"With its emphasis on practical and conceptual aspects, rather than mathematics or formulas, this accessible book has established itself as the go-to resource on confirmatory factor analysis (CFA). Detailed, worked-through examples drawn from psychology, management, and sociology studies illustrate the procedures, pitfalls, and extensions of CFA methodology. The text shows how to formulate, program, and interpret CFA models using popular latent variable software packages (LISREL, Mplus, EQS, SAS/CALIS); understand the similarities and differences between CFA and exploratory factor analysis (EFA); and report results from a CFA study. It is filled with useful advice and tables that outline the procedures. The companion website offers data and program syntax files for most of the research examples, as well as links to CFA-related resources. New to This Edition *Updated throughout to incorporate important developments in latent variable modeling. *Chapter on Bayesian CFA and multilevel measurement models. *Addresses new topics (with examples): exploratory structural equation modeling, bifactor analysis, measurement invariance evaluation with categorical indicators, and a new method for scaling latent variables. *Utilizes the latest versions of major latent variable software packages"--},
  isbn = {978-1-4625-1779-4 978-1-4625-1536-3},
  pagetotal = {462},
  keywords = {BUSINESS & ECONOMICS / Statistics,EDUCATION / Statistics,Factor analysis,MEDICAL / Nursing / Research & Theory,PSYCHOLOGY / Statistics,SOCIAL SCIENCE / Statistics}
}

@article{campbell1959,
  title = {Convergent and Discriminant Validation by the Multitrait-Multimethod Matrix},
  author = {Campbell, Donald T. and Fiske, Donald W.},
  date = {1959},
  journaltitle = {Psychological Bulletin},
  volume = {56},
  number = {2},
  pages = {81--105},
  issn = {0033-2909},
  doi = {10.1037/h0046016}
}

@article{collins2001a,
  title = {A Comparison of Inclusive and Restrictive Strategies in Modern Missing Data Procedures},
  author = {Collins, Linda M. and Schafer, Joseph L. and Kam, Chi-Ming},
  date = {2001},
  journaltitle = {Psychological Methods},
  volume = {6},
  number = {4},
  pages = {330--351},
  issn = {1082-989X},
  doi = {10.1037/1082-989X.6.4.330}
}

@book{eid2013,
  title = {Statistik und Forschungsmethoden: Lehrbuch ; mit Online-Materialien},
  shorttitle = {Statistik und Forschungsmethoden},
  author = {Eid, Michael and Gollwitzer, Mario and Schmitt, Manfred},
  date = {2013},
  edition = {3., korrigierte Auflage},
  publisher = {Beltz},
  location = {Weinheim Basel},
  abstract = {Statistik und Forschungsmethoden zählen nicht zu den beliebtesten Fächern in der Psychologie, zu groß ist der Respekt vor ihnen. Jetzt liegt ein Lehrbuch vor, das Abhilfe schafft - anschaulich und nachvollziehbar werden die statistischen Verfahren dargestellt. Dabei sind viele Formeln notwendig, Rechenschritte werden aber immer in einzelnen Schritten erläutert und durch Beispiele und konkrete Anwendungen ergänzt. So leuchtet dem Leser ein, wozu Statistik gut ist - und wie sie funktioniert! Aus dem Inhalt Forschungsmethoden Messtheoretische und deskriptivstatistische Grundlagen Wahrscheinlichkeitstheorie und inferenzstatistische Grundlagen Methoden zum Vergleich von Gruppen Zusammenhangs- und Regressionsanalyse Modelle mit latenten Variablen Mit Online-Materialien: Kommentierte Links zu im Internet frei verfügbaren Computerprogrammen und Tabellen Lösungen der Übungsaufgaben Datensätze zum Selbst-Nachrechnen Häufig gestellte Fragen Neuigkeiten},
  isbn = {978-3-621-27524-8},
  langid = {german},
  pagetotal = {1024},
  file = {C:\Users\Rieger\Zotero\storage\6ZV267JR\Eid et al. - 2013 - Statistik und Forschungsmethoden Lehrbuch ; mit O.pdf}
}

@article{enders2023,
  title = {Missing Data: {{An}} Update on the State of the Art},
  author = {Enders, Craig K.},
  date = {2023},
  journaltitle = {Psychological Methods},
  issn = {1082-989X},
  doi = {10.1037/met0000563},
  abstract = {The year 2022 is the 20th anniversary of Joseph Schafer and John Graham's paper titled \textbackslash textquotedblMissing data: Our view of the state of the art,\textbackslash textquotedbl currently the most highly cited paper in the history of Psychological Methods. Much has changed since 2002, as missing data methodologies have continually evolved and improved; the range of applications that are possible with modern missing data techniques has increased dramatically, and software options are light years ahead of where they were. This article provides an update on the state of the art that catalogs important innovations from the past two decades of missing data research. The paper addresses topics described in the original paper, including developments related to missing data theory, full information maximum likelihood, Bayesian estimation, multiple imputation, and models for missing not at random processes. The paper also describes newer factored regression specifications and missing data handling for multilevel models, both of which have been a focus of recent research. The paper concludes with a summary of the current software landscape and a discussion of several practical issues. (PsycInfo Database Record (c) 2023 APA, all rights reserved).}
}

@book{hoyle2012,
  title = {Handbook of Structural Equation Modeling},
  editor = {Hoyle, Rick H.},
  date = {2012},
  publisher = {Guilford Press},
  location = {New York},
  isbn = {1-60623-077-8}
}

@article{hu1998,
  title = {Fit Indices in Covariance Structure Modeling: {{Sensitivity}} to Underparameterized Model Misspecification},
  author = {Hu, Li–tze and Bentler, Peter M.},
  date = {1998},
  journaltitle = {Psychological Methods},
  volume = {3},
  number = {4},
  pages = {424--453},
  issn = {1082-989X},
  doi = {10.1037//1082-989X.3.4.424}
}

@article{hu1999,
  title = {Cutoff Criteria for Fit Indexes in Covariance Structure Analysis: {{Conventional}} Criteria versus New Alternatives},
  author = {Hu, Li–tze and Bentler, Peter M.},
  date = {1999},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {6},
  number = {1},
  pages = {1--55},
  issn = {1070-5511},
  doi = {10.1080/10705519909540118}
}

@incollection{kenny2012,
  title = {Identification: {{A}} Non-Technical Discussion of a Technical Issue},
  booktitle = {Handbook of Structural Equation Modeling},
  author = {Kenny, David A. and Milan, S.},
  editor = {Hoyle, Rick H.},
  date = {2012},
  publisher = {Guilford Press},
  location = {New York},
  isbn = {1-60623-077-8}
}

@article{little2006,
  title = {A Non-Arbitrary Method of Identifying and Scaling Latent Variables in {{SEM}} and {{MACS}} Models},
  author = {Little, Todd D. and Slegers, David W. and Card, Noel A.},
  date = {2006},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {13},
  number = {1},
  pages = {59--72},
  issn = {1070-5511},
  doi = {10.1207/s15328007sem1301‗ 3}
}

@article{mcneish2017,
  title = {Thanks {{Coefficient Alpha}}, {{We}}'ll {{Take It From Here}}},
  author = {McNeish, Daniel},
  date = {2017},
  journaltitle = {Psychological Methods},
  issn = {1082-989X},
  doi = {10.1037/met0000144},
  abstract = {Empirical studies in psychology commonly report Cronbach's alpha as a measure of internal consistency reliability despite the fact that many methodological studies have shown that Cronbach's alpha is riddled with problems stemming from unrealistic assumptions. In many circumstances, violating these assumptions yields estimates of reliability that are too small, making measures look less reliable than they actually are. Although methodological critiques of Cronbach's alpha are being cited with increasing frequency in empirical studies, in this tutorial we discuss how the trend is not necessarily improving methodology used in the literature. That is, many studies continue to use Cronbach's alpha without regard for its assumptions or merely cite methodological articles advising against its use to rationalize unfavorable Cronbach's alpha estimates. This tutorial first provides evidence that recommendations against Cronbach's alpha have not appreciably changed how empirical studies report reliability. Then, we summarize the drawbacks of Cronbach's alpha conceptually without relying on mathematical or simulation-based arguments so that these arguments are accessible to a broad audience. We continue by discussing several alternative measures that make less rigid assumptions which provide justifiably higher estimates of reliability compared to Cronbach's alpha. We conclude with empirical examples to illustrate advantages of alternative measures of reliability including omega total, Revelle's omega total, the greatest lower bound, and Coefficient H. A detailed software appendix is also provided to help researchers implement alternative methods. (PsycINFO Database Record}
}

@article{mcneish2021,
  title = {Dynamic Fit Index Cutoffs for Confirmatory Factor Analysis Models},
  author = {McNeish, Daniel and Wolf, Melissa G.},
  date = {2021},
  journaltitle = {Psychological Methods},
  issn = {1082-989X},
  doi = {10.1037/met0000425},
  abstract = {Model fit assessment is a central component of evaluating confirmatory factor analysis models and the validity of psychological assessments. Fit indices remain popular and researchers often judge fit with fixed cutoffs derived by Hu and Bentler (1999). Despite their overwhelming popularity, methodological studies have cautioned against fixed cutoffs, noting that the meaning of fit indices varies based on a complex interaction of model characteristics like factor reliability, number of items, and number of factors. Criticism of fixed cutoffs stems primarily from the fact that they were derived from one specific confirmatory factor analysis model and lack generalizability. To address this, we propose a simulation-based method called dynamic fit index cutoffs such that derivation of cutoffs is adaptively tailored to the specific model and data characteristics being evaluated. Unlike previously proposed simulation-based techniques, our method removes existing barriers to implementation by providing an open-source, Web based Shiny software application that automates the entire process so that users neither need to manually write any software code nor be knowledgeable about foundations of Monte Carlo simulation. Additionally, we extend fit index cutoff derivations to include sets of cutoffs for multiple levels of misspecification. In doing so, fit indices can more closely resemble their originally intended purpose as effect sizes quantifying misfit rather than improperly functioning as ad hoc hypothesis tests. We also provide an approach specifically designed for the nuances of 1-factor models, which have received surprisingly little attention in the literature despite frequent substantive interests in unidimensionality. (PsycInfo Database Record (c) 2021 APA, all rights reserved).}
}

@software{R-merTools,
  title = {{{merTools}}: {{Tools}} for {{Analyzing Mixed Effect Regression Models}}},
  author = {Knowles, J. E. and Frederick, Carl and Whitworth, Alex},
  date = {2023},
  url = {https://github.com/jknowles/merTools}
}

@article{raykov2015,
  title = {Scale Reliability Evaluation under Multiple Assumption Violations},
  author = {Raykov, Tenko and Marcoulides, George A.},
  date = {2015},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {23},
  number = {2},
  pages = {302--313},
  issn = {1070-5511},
  doi = {10.1080/10705511.2014.938597}
}

@article{revelle2009a,
  title = {Coefficients {{Alpha}}, {{Beta}}, {{Omega}}, and the Glb: {{Comments}} on {{Sijtsma}}},
  author = {Revelle, William and Zinbarg, Richard E.},
  date = {2009},
  journaltitle = {Psychometrika},
  volume = {74},
  number = {1},
  pages = {145--154},
  issn = {0033-3123},
  doi = {10.1007/s11336-008-9102-z}
}

@article{savalei2019,
  title = {Don't Forget the Model in Your Model-Based Reliability Coefficients: {{A}} Reply to {{McNeish}} (2018)},
  author = {Savalei, Victoria and Reise, Steven P.},
  date = {2019},
  journaltitle = {Collabra: Psychology},
  volume = {5},
  number = {1},
  pages = {36},
  issn = {2474-7394},
  doi = {10.1525/collabra.247}
}

@article{schafer2002,
  title = {Missing Data: {{Our}} View of the State of the Art},
  author = {Schafer, Joseph L. and Graham, John W.},
  date = {2002},
  journaltitle = {Psychological Methods},
  volume = {7},
  number = {2},
  pages = {147--177},
  issn = {1082-989X},
  doi = {10.1037/1082-989X.7.2.147}
}

@article{schafer2008,
  title = {Average Causal Effects from Nonrandomized Studies: {{A}} Practical Guide and Simulated Example},
  author = {Schafer, Joseph L. and Kang, Joseph},
  date = {2008},
  journaltitle = {Psychological Methods},
  volume = {13},
  number = {4},
  pages = {279--313},
  issn = {1082-989X},
  doi = {10.1037/a0014268},
  abstract = {In a well-designed experiment, random assignment of participants to treatments makes causal inference straightforward. However, if participants are not randomized (as in observational study, quasi-experiment, or nonequivalent control-group designs), group comparisons may be biased by confounders that influence both the outcome and the alleged cause. Traditional analysis of covariance, which includes confounders as predictors in a regression model, often fails to eliminate this bias. In this article, the authors review Rubin's definition of an average causal effect (ACE) as the average difference between potential outcomes under different treatments. The authors distinguish an ACE and a regression coefficient. The authors review 9 strategies for estimating ACEs on the basis of regression, propensity scores, and doubly robust methods, providing formulas for standard errors not given elsewhere. To illustrate the methods, the authors simulate an observational study to assess the effects of dieting on emotional distress. Drawing repeated samples from a simulated population of adolescent girls, the authors assess each method in terms of bias, efficiency, and interval coverage. Throughout the article, the authors offer insights and practical guidance for researchers who attempt causal inference with observational data.}
}

@article{sijtsma2009,
  title = {On the {{Use}}, the {{Misuse}}, and the {{Very Limited Usefulness}} of {{Cronbach}}'s {{Alpha}}},
  author = {Sijtsma, Klaas},
  date = {2009},
  journaltitle = {Psychometrika},
  volume = {74},
  number = {1},
  pages = {107--120},
  issn = {0033-3123},
  doi = {10.1007/s11336-008-9101-0},
  abstract = {This discussion paper argues that both the use of Cronbach's alpha as a reliability estimate and as a measure of internal consistency suffer from major problems. First, alpha always has a value, which cannot be equal to the test score's reliability given the interitem covariance matrix and the usual assumptions about measurement error. Second, in practice, alpha is used more often as a measure of the test's internal consistency than as an estimate of reliability. However, it can be shown easily that alpha is unrelated to the internal structure of the test. It is further discussed that statistics based on a single test administration do not convey much information about the accuracy of individuals' test performance. The paper ends with a list of conclusions about the usefulness of alpha.}
}
