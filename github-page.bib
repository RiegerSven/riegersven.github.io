@incollection{brown2012,
  title = {Confirmatory Factor Analysis},
  booktitle = {Handbook of Structural Equation Modeling},
  author = {Brown, Timothy A. and Moore, Michael T.},
  editor = {Hoyle, Rick H.},
  date = {2012},
  publisher = {Guilford Press},
  location = {New York},
  isbn = {1-60623-077-8}
}

@book{brown2015,
  title = {Confirmatory Factor Analysis for Applied Research},
  author = {Brown, Timothy A.},
  date = {2015},
  series = {Methodology in the Social Sciences},
  edition = {Second edition},
  publisher = {The Guilford Press},
  location = {New York ; London},
  abstract = {"With its emphasis on practical and conceptual aspects, rather than mathematics or formulas, this accessible book has established itself as the go-to resource on confirmatory factor analysis (CFA). Detailed, worked-through examples drawn from psychology, management, and sociology studies illustrate the procedures, pitfalls, and extensions of CFA methodology. The text shows how to formulate, program, and interpret CFA models using popular latent variable software packages (LISREL, Mplus, EQS, SAS/CALIS); understand the similarities and differences between CFA and exploratory factor analysis (EFA); and report results from a CFA study. It is filled with useful advice and tables that outline the procedures. The companion website offers data and program syntax files for most of the research examples, as well as links to CFA-related resources. New to This Edition *Updated throughout to incorporate important developments in latent variable modeling. *Chapter on Bayesian CFA and multilevel measurement models. *Addresses new topics (with examples): exploratory structural equation modeling, bifactor analysis, measurement invariance evaluation with categorical indicators, and a new method for scaling latent variables. *Utilizes the latest versions of major latent variable software packages"--},
  isbn = {978-1-4625-1779-4 978-1-4625-1536-3},
  pagetotal = {462},
  keywords = {BUSINESS & ECONOMICS / Statistics,EDUCATION / Statistics,Factor analysis,MEDICAL / Nursing / Research & Theory,PSYCHOLOGY / Statistics,SOCIAL SCIENCE / Statistics}
}

@article{campbell1959,
  title = {Convergent and Discriminant Validation by the Multitrait-Multimethod Matrix},
  author = {Campbell, Donald T. and Fiske, Donald W.},
  date = {1959},
  journaltitle = {Psychological Bulletin},
  volume = {56},
  number = {2},
  pages = {81--105},
  issn = {0033-2909},
  doi = {10.1037/h0046016}
}

@book{eid2013,
  title = {Statistik und Forschungsmethoden: Lehrbuch ; mit Online-Materialien},
  shorttitle = {Statistik und Forschungsmethoden},
  author = {Eid, Michael and Gollwitzer, Mario and Schmitt, Manfred},
  date = {2013},
  edition = {3., korrigierte Auflage},
  publisher = {Beltz},
  location = {Weinheim Basel},
  abstract = {Statistik und Forschungsmethoden zählen nicht zu den beliebtesten Fächern in der Psychologie, zu groß ist der Respekt vor ihnen. Jetzt liegt ein Lehrbuch vor, das Abhilfe schafft - anschaulich und nachvollziehbar werden die statistischen Verfahren dargestellt. Dabei sind viele Formeln notwendig, Rechenschritte werden aber immer in einzelnen Schritten erläutert und durch Beispiele und konkrete Anwendungen ergänzt. So leuchtet dem Leser ein, wozu Statistik gut ist - und wie sie funktioniert! Aus dem Inhalt Forschungsmethoden Messtheoretische und deskriptivstatistische Grundlagen Wahrscheinlichkeitstheorie und inferenzstatistische Grundlagen Methoden zum Vergleich von Gruppen Zusammenhangs- und Regressionsanalyse Modelle mit latenten Variablen Mit Online-Materialien: Kommentierte Links zu im Internet frei verfügbaren Computerprogrammen und Tabellen Lösungen der Übungsaufgaben Datensätze zum Selbst-Nachrechnen Häufig gestellte Fragen Neuigkeiten},
  isbn = {978-3-621-27524-8},
  langid = {german},
  pagetotal = {1024},
  file = {/Users/svenrieger/Zotero/storage/6ZV267JR/Eid et al. - 2013 - Statistik und Forschungsmethoden Lehrbuch ; mit O.pdf}
}

@book{hoyle2012,
  title = {Handbook of Structural Equation Modeling},
  editor = {Hoyle, Rick H.},
  date = {2012},
  publisher = {Guilford Press},
  location = {New York},
  isbn = {1-60623-077-8}
}

@article{hu1998,
  title = {Fit Indices in Covariance Structure Modeling: {{Sensitivity}} to Underparameterized Model Misspecification},
  author = {Hu, Li–tze and Bentler, Peter M.},
  date = {1998},
  journaltitle = {Psychological Methods},
  volume = {3},
  number = {4},
  pages = {424--453},
  issn = {1082-989X},
  doi = {10.1037//1082-989X.3.4.424}
}

@article{hu1999,
  title = {Cutoff Criteria for Fit Indexes in Covariance Structure Analysis: {{Conventional}} Criteria versus New Alternatives},
  author = {Hu, Li–tze and Bentler, Peter M.},
  date = {1999},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {6},
  number = {1},
  pages = {1--55},
  issn = {1070-5511},
  doi = {10.1080/10705519909540118}
}

@incollection{kenny2012,
  title = {Identification: {{A}} Non-Technical Discussion of a Technical Issue},
  booktitle = {Handbook of Structural Equation Modeling},
  author = {Kenny, David A. and Milan, S.},
  editor = {Hoyle, Rick H.},
  date = {2012},
  publisher = {Guilford Press},
  location = {New York},
  isbn = {1-60623-077-8}
}

@article{little2006,
  title = {A Non-Arbitrary Method of Identifying and Scaling Latent Bariables in {{SEM}} and {{MACS}} Models},
  author = {Little, Todd D. and Slegers, David W. and Card, Noel A.},
  date = {2006},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {13},
  number = {1},
  pages = {59--72},
  issn = {1070-5511},
  doi = {10.1207/s15328007sem1301‗ 3}
}

@article{mcneish2017,
  title = {Thanks {{Coefficient Alpha}}, {{We}}'ll {{Take It From Here}}},
  author = {McNeish, Daniel},
  date = {2017},
  journaltitle = {Psychological Methods},
  issn = {1082-989X},
  doi = {10.1037/met0000144},
  abstract = {Empirical studies in psychology commonly report Cronbach's alpha as a measure of internal consistency reliability despite the fact that many methodological studies have shown that Cronbach's alpha is riddled with problems stemming from unrealistic assumptions. In many circumstances, violating these assumptions yields estimates of reliability that are too small, making measures look less reliable than they actually are. Although methodological critiques of Cronbach's alpha are being cited with increasing frequency in empirical studies, in this tutorial we discuss how the trend is not necessarily improving methodology used in the literature. That is, many studies continue to use Cronbach's alpha without regard for its assumptions or merely cite methodological articles advising against its use to rationalize unfavorable Cronbach's alpha estimates. This tutorial first provides evidence that recommendations against Cronbach's alpha have not appreciably changed how empirical studies report reliability. Then, we summarize the drawbacks of Cronbach's alpha conceptually without relying on mathematical or simulation-based arguments so that these arguments are accessible to a broad audience. We continue by discussing several alternative measures that make less rigid assumptions which provide justifiably higher estimates of reliability compared to Cronbach's alpha. We conclude with empirical examples to illustrate advantages of alternative measures of reliability including omega total, Revelle's omega total, the greatest lower bound, and Coefficient H. A detailed software appendix is also provided to help researchers implement alternative methods. (PsycINFO Database Record}
}

@article{mcneish2021,
  title = {Dynamic Fit Index Cutoffs for Confirmatory Factor Analysis Models},
  author = {McNeish, Daniel and Wolf, Melissa G.},
  date = {2021},
  journaltitle = {Psychological Methods},
  issn = {1082-989X},
  doi = {10.1037/met0000425},
  abstract = {Model fit assessment is a central component of evaluating confirmatory factor analysis models and the validity of psychological assessments. Fit indices remain popular and researchers often judge fit with fixed cutoffs derived by Hu and Bentler (1999). Despite their overwhelming popularity, methodological studies have cautioned against fixed cutoffs, noting that the meaning of fit indices varies based on a complex interaction of model characteristics like factor reliability, number of items, and number of factors. Criticism of fixed cutoffs stems primarily from the fact that they were derived from one specific confirmatory factor analysis model and lack generalizability. To address this, we propose a simulation-based method called dynamic fit index cutoffs such that derivation of cutoffs is adaptively tailored to the specific model and data characteristics being evaluated. Unlike previously proposed simulation-based techniques, our method removes existing barriers to implementation by providing an open-source, Web based Shiny software application that automates the entire process so that users neither need to manually write any software code nor be knowledgeable about foundations of Monte Carlo simulation. Additionally, we extend fit index cutoff derivations to include sets of cutoffs for multiple levels of misspecification. In doing so, fit indices can more closely resemble their originally intended purpose as effect sizes quantifying misfit rather than improperly functioning as ad hoc hypothesis tests. We also provide an approach specifically designed for the nuances of 1-factor models, which have received surprisingly little attention in the literature despite frequent substantive interests in unidimensionality. (PsycInfo Database Record (c) 2021 APA, all rights reserved).}
}

@article{raykov2015,
  title = {Scale Reliability Evaluation under Multiple Assumption Violations},
  author = {Raykov, Tenko and Marcoulides, George A.},
  date = {2015},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {23},
  number = {2},
  pages = {302--313},
  issn = {1070-5511},
  doi = {10.1080/10705511.2014.938597}
}

@article{revelle2009,
  title = {Coefficients {{Alpha}}, {{Beta}}, {{Omega}}, and the Glb: {{Comments}} on {{Sijtsma}}},
  author = {Revelle, William and Zinbarg, Richard E.},
  date = {2009},
  journaltitle = {Psychometrika},
  volume = {74},
  number = {1},
  pages = {145--154},
  issn = {0033-3123},
  doi = {10.1007/s11336-008-9102-z}
}

@article{savalei2019,
  title = {Don't Forget the Model in Your Model-Based Reliability Coefficients: {{A}} Reply to {{McNeish}} (2018)},
  author = {Savalei, Victoria and Reise, Steven P.},
  date = {2019},
  journaltitle = {Collabra: Psychology},
  volume = {5},
  number = {1},
  pages = {36},
  issn = {2474-7394},
  doi = {10.1525/collabra.247}
}

@article{sijtsma2009,
  title = {On the {{Use}}, the {{Misuse}}, and the {{Very Limited Usefulness}} of {{Cronbach}}'s {{Alpha}}},
  author = {Sijtsma, Klaas},
  date = {2009},
  journaltitle = {Psychometrika},
  volume = {74},
  number = {1},
  pages = {107--120},
  issn = {0033-3123},
  doi = {10.1007/s11336-008-9101-0},
  abstract = {This discussion paper argues that both the use of Cronbach's alpha as a reliability estimate and as a measure of internal consistency suffer from major problems. First, alpha always has a value, which cannot be equal to the test score's reliability given the interitem covariance matrix and the usual assumptions about measurement error. Second, in practice, alpha is used more often as a measure of the test's internal consistency than as an estimate of reliability. However, it can be shown easily that alpha is unrelated to the internal structure of the test. It is further discussed that statistics based on a single test administration do not convey much information about the accuracy of individuals' test performance. The paper ends with a list of conclusions about the usefulness of alpha.}
}
